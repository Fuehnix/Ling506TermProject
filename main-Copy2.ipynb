{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import regex as re\n",
    "import sys\n",
    "import os\n",
    "import json\n",
    "import random\n",
    "import math\n",
    "import operator as op\n",
    "import docopt\n",
    "import numpy as np\n",
    "import os.path\n",
    "import itertools\n",
    "from os import path\n",
    "from tqdm import tqdm\n",
    "from scipy.spatial.distance import jensenshannon, cosine\n",
    "from numpy import asarray\n",
    "import statistics \n",
    "from collections import Counter, defaultdict, namedtuple\n",
    "\n",
    "from sklearn.linear_model import LogisticRegressionCV\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, precision_recall_fscore_support\n",
    "from sklearn.metrics.pairwise import cosine_similarity, chi2_kernel\n",
    "from scipy.spatial import distance\n",
    "import joblib\n",
    "import shutil\n",
    "\n",
    "Report = namedtuple(\"Report\", [\"precision\", \"recall\", \"accuracy\", \"f1\", \"tp\", \"tn\", \"fp\", \"fn\"])\n",
    "JSON = \"unified-dataset.jsonl\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#this method is used to get the classifier mode and decide whether to single-label or multi-label classification\n",
    "#this method comes from the original authors and is kept to replicate their results\n",
    "def get_clf_mode(train, test):\n",
    "    first = \"single\"\n",
    "    for example in train:\n",
    "        if example.get(\"labeled\", \"multi\") == \"multi\":\n",
    "            first = \"multi\"\n",
    "    print(first)\n",
    "    for example in test:\n",
    "        if example.get(\"labeled\", \"multi\") == \"multi\":\n",
    "            return first, \"multi\"\n",
    "    print(\"oof\")\n",
    "    return first, \"single\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#This methods is used to extract the training and testing data from the unified corpus json.\n",
    "#The unified corpus json must be produced using the authors original code\n",
    "#this version is only used in getting the benchmarks for the previous paper\n",
    "#this version takes the jsonfile, the name of the train file and the name of the test file as parameters\n",
    "def get_train_test(jsonfile, train, test):\n",
    "    print(\"get_train_test param:\")\n",
    "    print(\"json \", jsonfile)\n",
    "    print(\"train \", train)\n",
    "    print(\"test \", test)\n",
    "    same = test in train.split(\",\") #used if train and test corpus are same\n",
    "    training, testing = [], []\n",
    "    count1 = 0\n",
    "    count2 = 0\n",
    "    count3 = 0\n",
    "    count4 = 0\n",
    "    with open(jsonfile) as f:\n",
    "        for line in f:\n",
    "            data = json.loads(line)\n",
    "            if(data[\"source\"] == test):\n",
    "                count1 += 1\n",
    "            if(data[\"source\"] != test):\n",
    "                count2 += 1\n",
    "            if((train == None or train == \"all-vs\") and data[\"source\"] != test):\n",
    "                count3 += 1\n",
    "                training.append(data)\n",
    "            elif data[\"source\"] == test:\n",
    "                count4 += 1\n",
    "                testing.append(data)\n",
    "            elif(data[\"source\"] in train.split(\",\")):\n",
    "                count3 += 1\n",
    "                training.append(data)\n",
    "    print(\"there were \", count1, \" entries that were in test and \", count2, \"that were not in test\",\n",
    "          \"and \", count3, \" that were in train\")\n",
    "    print(\"test was appended \", count4, \" times\")\n",
    "    if same:\n",
    "        training, testing = hacky_train_test_split(testing, train_size=0.8, first=train, second=test)\n",
    "        print(\"revised\", \"there were \", len(testing), \" entries that were in test and \", len(training), \" that were in train\")\n",
    "    return training, testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#this method stays as is from the original paper\n",
    "def get_labels(train, test, operation=op.and_, mode=\"multi\"):\n",
    "    \"\"\"Return a list of the emotional intersection of two sources.\"\"\"\n",
    "    emotions = set()\n",
    "    if mode == \"single\":\n",
    "        emotions.add(\"noemo\")\n",
    "    train_emotions = set(\n",
    "        emotion\n",
    "        for data in train\n",
    "        for emotion in data[\"emotions\"]\n",
    "        if data[\"emotions\"][emotion] is not None\n",
    "    )\n",
    "    # print(train_emotions)\n",
    "    test_emotions = set(\n",
    "        emotion\n",
    "        for emotion in test[0][\"emotions\"]\n",
    "        if test[0][\"emotions\"][emotion] is not None\n",
    "    )\n",
    "    # print(test_emotions)\n",
    "    return list(emotions | operation(train_emotions, test_emotions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#expects corpus list in data form\n",
    "#returns compatible labels\n",
    "def getMatchingLabels(corpora):\n",
    "    emotionSetList = []\n",
    "    for corpus in corpora:\n",
    "        emoSet = set()\n",
    "        for data in corpus:\n",
    "            for emotion in data[\"emotions\"]:\n",
    "                if data[\"emotions\"][emotion] == 1 or data[\"emotions\"][emotion] == 0:\n",
    "                    emoSet.add(emotion)\n",
    "#         emoSet = set(emotion for data in corpus for emotion in data[\"emotions\"] if data[\"emotions\"][emotion] is not None)\n",
    "        print(emoSet)\n",
    "        emotionSetList.append(emoSet)\n",
    "    intersectionSet = set.intersection(*emotionSetList)\n",
    "    print(\"matched Labels:\", intersectionSet)\n",
    "    return intersectionSet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#this method stays as is from the original paper\n",
    "def get_emotion(emovals, labels, emotions, mode=\"multi\"):\n",
    "#     print(\"get emotion mode \", mode)\n",
    "#     print(\"emovals \",emovals)\n",
    "#     print(\"labels \",labels)\n",
    "#     print(\"emotions \",emotions)\n",
    "    if mode == \"single\":\n",
    "        truthy = len(list(filter(bool, emovals.values())))\n",
    "        if truthy == 1:\n",
    "            emotion = [v for v in emovals if emovals[v]][0]\n",
    "        elif truthy == 0:\n",
    "            emotion = \"noemo\"\n",
    "        else:\n",
    "            raise ValueError(\"Dataset marked as 'single' contains multiple emotions\")\n",
    "        return emotions.get(emotion, emotions.get(\"noemo\"))\n",
    "    else:\n",
    "        el = [int((emovals[label] or 0) > 0.1) for label in labels]\n",
    "        return np.array(el)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#this method stays as is from the original paper\n",
    "def get_vector(text, wordlist):\n",
    "    tokens = set(tokenize(text))\n",
    "#     print(tokens)\n",
    "    return [1 if word in tokens else 0 for word in wordlist]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#The comment below was left by the original authors. As you can see, their results were unable to use the full bag of words\n",
    "# this is bad. memory error for all_vs (too many words...)\n",
    "def get_wordlist(dataset):\n",
    "    \"\"\"Get a bag of words from a dataset.\"\"\"\n",
    "    bag = set()\n",
    "    for data in dataset:\n",
    "        bag.update({token for token in tokenize(data[\"text\"])})\n",
    "    return list(bag)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#bag of word limit of 5000 is kept from the original authors to match their results\n",
    "def getTop5000Words(dataset):\n",
    "    \"\"\"Get a bag of words from a dataset.\"\"\"\n",
    "    bag = Counter()\n",
    "    for data in dataset:\n",
    "        bag.update({token for token in tokenize(data[\"text\"])})\n",
    "    print(\"bag size\", len(bag))\n",
    "#     print(\"bag\", bag)\n",
    "    out = list(map(op.itemgetter(0), bag.most_common(5000)))\n",
    "#     print(\"this is the output\", out)\n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Taken from my own Ling 413 final project, I was going to run trials with lemmatization and other tokenization\n",
    "#but by the time I was far enough in the project to do this, I didn't have time to run trials with this\n",
    "# def cleanDataLemma(dataset):\n",
    "#     taggedDataset = nltk.pos_tag(dataset)\n",
    "#     filteredString = []\n",
    "#     for token, tag in taggedDataset:\n",
    "#         for char in token:\n",
    "#             if char in string.punctuation:\n",
    "#                 token = token.replace(char,\"\") #remove punctuation\n",
    "#         if (token not in stopWords):\n",
    "#             lemmatizedToken = \"\"\n",
    "#             if tag[0] == 'N':\n",
    "#                 lemmatizedToken = lemmatizer.lemmatize(token, 'n')\n",
    "#             elif tag[0] == 'V':\n",
    "#                 lemmatizedToken = lemmatizer.lemmatize(token, 'v')\n",
    "#             else:\n",
    "#                 lemmatizedToken = token\n",
    "#             if len(lemmatizedToken) > 2:\n",
    "#                 filteredString.append(lemmatizedToken)\n",
    "#     return filteredString"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#tokenization is kept the same so that performance results match the ones used in the paper as closely as possible\n",
    "#if there is improvement, it should be because of my changes\n",
    "def tokenize(text):\n",
    "    return re.findall(r\"\\p{L}+\", text.lower())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getWordCountsByEmotion(dataset, emotionLabels):\n",
    "    emotionCounts = []\n",
    "    for emotion in emotionLabels:\n",
    "        emotionDict = Counter()\n",
    "        for data in dataset:\n",
    "#             if data[\"emotions\"][emotion] == 1:\n",
    "#                 print(emotion)\n",
    "#                 print(data)\n",
    "#                 print(data[\"emotions\"][emotion])\n",
    "            emotionDict.update({token for token in tokenize(data[\"text\"]) if data[\"emotions\"][emotion] == 1})\n",
    "#         print(\"emotionsWordCounts\", len(emotionDict))\n",
    "        emotionCounts.append(emotionDict)\n",
    "    return emotionCounts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getTokenFrequency(dataset):\n",
    "    token2DocFreq = {}\n",
    "    for data in dataset:\n",
    "        tempDict = {}\n",
    "        for word in data:\n",
    "            if word not in tempDict:\n",
    "                tempDict[word] = 1\n",
    "        for key, value in tempDict.items():\n",
    "            if key in token2DocFreq:\n",
    "                token2DocFreq[key] += value\n",
    "            else:\n",
    "                token2DocFreq[key] = value\n",
    "    return token2DocFreq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getTokenizedCorpusTextPair(corpus1, corpus2):\n",
    "    with open(JSON) as f:\n",
    "        for line in f:\n",
    "            data = json.loads(line)\n",
    "            if (data[\"source\"] in corpus1) or (corpus1 == None and data[\"source\"] != corpus2):\n",
    "                corpus1Text.append(tokenize(data[\"text\"]))\n",
    "                corpus1Data.append(data)\n",
    "            if data[\"source\"] in corpus2:\n",
    "                corpus2Text.append(tokenize(data[\"text\"]))\n",
    "                corpus2Data.append(data)\n",
    "    corporaData = [corpus1Data,corpus2Data]\n",
    "    return corpus1Text, corpus2Text, corporaData"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def getNormalizedFreq(tokenFreq):\n",
    "# def getNormalizedFreq(corpus):\n",
    "#     newCorpus = []\n",
    "#     for entry in corpus:\n",
    "#         newCorpus.append(tokenize(entry))\n",
    "#     tokenFreq = getTokenFrequency(newCorpus)\n",
    "#     print(tokenFreq.items())\n",
    "#     print(\"freq values\", tokenFreq)\n",
    "    newTokenFreq = tokenFreq.copy()\n",
    "    for item, freq in newTokenFreq.items():\n",
    "        if(freq == 0):\n",
    "            newTokenFreq[item] = 0\n",
    "        else:\n",
    "            newTokenFreq[item] = 1 + math.log10(freq)\n",
    "#     print(\"log weighted values\", tokenFreq)\n",
    "    docLength = 0\n",
    "    for freq in newTokenFreq.values():\n",
    "        docLength += freq*freq\n",
    "    docLength = math.sqrt(docLength)\n",
    "#     print(\"doclength\", docLength)\n",
    "    for item, freq in newTokenFreq.items():\n",
    "        newTokenFreq[item] = freq/docLength\n",
    "    # logFreq = freq for freq in math.log() \n",
    "#     print(\"normalized\")\n",
    "#     print(tokenFreq)\n",
    "    return newTokenFreq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getCosineSimilarityFromTokenFreq(tokenFreq1, tokenFreq2):\n",
    "    normFreq1 = getNormalizedFreq(tokenFreq1)\n",
    "    normFreq2 = getNormalizedFreq(tokenFreq2)\n",
    "    cosineSum = 0\n",
    "    normFreq1.items()\n",
    "#     print(\"tokenFrequency length 1\", len(normFreq1))\n",
    "#     print(\"tokenFrequency length 2\", len(normFreq2))\n",
    "    intersection = normFreq1.keys() & normFreq2.keys()\n",
    "    #only loop intersection because unshared values will be multiplied by 0 anyway\n",
    "    for item in intersection:\n",
    "#         if normFreq1[item] < 0 or normFreq2[item] < 0 :\n",
    "#             print(\"negative?\", item, normFreq1[item],normFreq2[item])\n",
    "#             sys.exit()\n",
    "#         print(item)\n",
    "#         print(normFreq1[item])\n",
    "#         print(normFreq2[item])\n",
    "        x = normFreq1[item] * normFreq2[item]\n",
    "        cosineSum += x\n",
    "    return cosineSum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getCosineSimilarityFromCorpus(corpus1,corpus2):\n",
    "    corpus1Text, corpus2Text, corporaData = getTokenizedCorpusTextPair(corpus1, corpus2)\n",
    "    corpus1Data,corpus2Data = corporaData\n",
    "    emotionLabels = getMatchingLabels(corporaData)\n",
    "    tokenFreq1 = getTokenFrequency(corpus1Text)\n",
    "    tokenFreq2 = getTokenFrequency(corpus2Text)\n",
    "    sim = getCosineSimilarityFromTokenFreq(tokenFreq1, tokenFreq2)\n",
    "    return sim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getCosineSimilarityFromCorpusEmotions(corpus1,corpus2):\n",
    "    corpus1Text, corpus2Text, corporaData = getTokenizedCorpusTextPair(corpus1, corpus2)\n",
    "    corpus1Data,corpus2Data = corporaData\n",
    "    emotionLabels = list(getMatchingLabels(corporaData))\n",
    "    emotionDicts1 = getWordCountsByEmotion(corpus1Data, emotionLabels)\n",
    "    emotionDicts2 = getWordCountsByEmotion(corpus2Data, emotionLabels)\n",
    "    emoSim = {}\n",
    "    for emotion in range(len(emotionLabels)):\n",
    "        sim = getCosineSimilarityFromTokenFreq(emotionDicts1[emotion], emotionDicts2[emotion])\n",
    "        emotion = emotionLabels[emotion]\n",
    "        emoSim[emotion] = sim\n",
    "    return emoSim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "#averages the values the come from jensenshannon into a single value\n",
    "def getJensenShannonFromNPArrays(np1,np2):\n",
    "    js_pq = jensenshannon(np1, np2)\n",
    "    print(js_pq)\n",
    "    sumJS = 0\n",
    "    length = len(js_pq)\n",
    "    for x in js_pq:\n",
    "        if math.isnan(x): #assume nan values should be interpretted as 0\n",
    "            sumJS += 0\n",
    "        else:\n",
    "            sumJS += x\n",
    "    js = sumJS/length\n",
    "    return js"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "False\n",
      "False\n",
      "False\n",
      "True\n",
      "False\n",
      "(4868, 5000)\n",
      "(4868, 5000)\n",
      "(4868, 5000)\n",
      "(7666, 5000)\n",
      "(4868, 5000)\n",
      "[0. 0. 0. ... 0. 0. 0.]\n",
      "0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\Anaconda3\\lib\\site-packages\\scipy\\spatial\\distance.py:1279: RuntimeWarning: invalid value encountered in true_divide\n",
      "  q = q / np.sum(q, axis=0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.65300289 0.71217394 0.65470119 ...        nan 0.83255461        nan]\n",
      "0.48101544698034715\n"
     ]
    }
   ],
   "source": [
    "#test code for understanding how NP arrays are distributed\n",
    "arr1 = np.load(\"ssec_emotion-causetrain_xNP.npy\")\n",
    "arr2 = np.load(\"ssec_grounded_emotionstrain_xNP.npy\")\n",
    "arr3 = np.load(\"isear_ssectest_xNP.npy\")\n",
    "arr4 = np.load(\"isear_ssectrain_xNP.npy\")\n",
    "arr5 = np.load(\"ssec_iseartest_xNP.npy\")\n",
    "arr5 = np.load(\"ssec_iseartrain_xNP.npy\")\n",
    "print(np.array_equal(arr1,arr2))\n",
    "print(np.array_equal(arr2,arr3))\n",
    "print(np.array_equal(arr3,arr4))\n",
    "print(np.array_equal(arr4,arr5))\n",
    "print(np.array_equal(arr1,arr5))\n",
    "print(np.array_equal(arr3,arr5))\n",
    "print(arr1.shape)\n",
    "print(arr2.shape)\n",
    "print(arr3.shape)\n",
    "print(arr4.shape)\n",
    "print(arr5.shape)\n",
    "print(getJensenShannonFromNPArrays(arr1,arr2))\n",
    "print(getJensenShannonFromNPArrays(arr2,arr3))\n",
    "# print(getJensenShannonFromNPArrays(arr4,arr5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def getChiSquare(observed,calculated):\n",
    "#     chiSquare = ((observed - calculated)**2)/calculated\n",
    "#     return chiSquare"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Calculates Chi Square, or at least it would have if I had finished implementing\n",
    "#see paper for details on why it was not implemented\n",
    "# def getChiSquareFromTokenFreq(tokenFreq1, tokenFreq2):\n",
    "# columnTotal1 = sum(tokenFreq1.values())\n",
    "# columnTotal2 = sum(tokenFreq2.values())\n",
    "# intersection = tokenFreq1.keys() & tokenFreq2.keys()\n",
    "# rowTotals = {key: tokenFreq1.get(key, 0) + tokenFreq2.get(key, 0)\n",
    "#           for key in set(dict1) | set(dict2)}\n",
    "# grandTotal = columnTotal1 + columnTotal2\n",
    "# chiSquareTotal = 0\n",
    "# calculated1 = []\n",
    "# calculated2 = []\n",
    "# for item, rowTotal in rowTotals.items():\n",
    "#     calculated1[item] = (rowTotal * columnTotal1) / grandTotal\n",
    "#     calculated2[item] = (rowTotal * columnTotal2) / grandTotal\n",
    "# for item, value in calculated.items():\n",
    "#     getChiSquare(observed,calculated[item])\n",
    "#     calculated[item]\n",
    "#     return js"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loaded data\n",
      "bag size 17756\n",
      "{'anger', 'surprise', 'trust', 'disgust', 'fear', 'sadness', 'joy'}\n",
      "{'anger', 'shame', 'disgust', 'fear', 'sadness', 'guilt', 'joy'}\n",
      "matched Labels: {'anger', 'fear', 'disgust', 'sadness', 'joy'}\n",
      "anger 0.46229743778369403\n",
      "fear 0.4368899238278968\n",
      "disgust 0.4516565863648767\n",
      "sadness 0.4538342791036561\n",
      "joy 0.4439890786057686\n",
      "0.5107359175632173\n",
      "0.5107359175632176\n"
     ]
    }
   ],
   "source": [
    "#This is a validation of my corpus similarity metrics\n",
    "corpus1 = \"ssec\"\n",
    "corpus1Data = []\n",
    "corpus1Text = []\n",
    "corpus2 = \"isear\"\n",
    "corpus2Data = []\n",
    "corpus2Text = []\n",
    "with open(JSON) as f:\n",
    "    for line in f:\n",
    "        data = json.loads(line)\n",
    "        if data[\"source\"] == corpus1:\n",
    "            corpus1Text.append(tokenize(data[\"text\"]))\n",
    "            corpus1Data.append(data)\n",
    "        if data[\"source\"] == corpus2:\n",
    "            corpus2Text.append(tokenize(data[\"text\"]))\n",
    "            corpus2Data.append(data)\n",
    "print(\"loaded data\")\n",
    "combinedCorpus = corpus1Data + corpus2Data\n",
    "combinedCorpusText = corpus1Text + corpus2Text\n",
    "# tokenFreq = getTokenFrequency(corpus1Text)\n",
    "# print(\"tokenFreq\", tokenFreq)\n",
    "words = getTop5000Words(combinedCorpus)\n",
    "corporaData = [corpus1Data,corpus2Data]\n",
    "emotionLabels = list(getMatchingLabels(corporaData))\n",
    "emotions1 = getWordCountsByEmotion(corpus1Data, emotionLabels)\n",
    "# print(emotions1)\n",
    "emotions2 = getWordCountsByEmotion(corpus2Data, emotionLabels)\n",
    "# print(emotions2)\n",
    "for emotion in range(len(emotionLabels)):\n",
    "    sim = getCosineSimilarityFromTokenFreq(emotions1[emotion], emotions2[emotion])\n",
    "    print(emotionLabels[emotion], sim)\n",
    "fullCorpus1Words = getTokenFrequency(corpus1Text)\n",
    "fullCorpus2Words = getTokenFrequency(corpus2Text)\n",
    "sim1 = getCosineSimilarityFromTokenFreq(fullCorpus1Words, fullCorpus2Words)\n",
    "sim2 = getCosineSimilarityFromTokenFreq(fullCorpus2Words, fullCorpus1Words)\n",
    "print(sim1)\n",
    "print(sim2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# import gensim\n",
    "# import numpy as np\n",
    "# from nltk.tokenize import word_tokenize\n",
    "# print(corpus1Text[:5])\n",
    "# gen_docs = corpus1Text[:5]\n",
    "# dictionary = gensim.corpora.Dictionary(gen_docs)\n",
    "# # print(dictionary.token2id)\n",
    "# corpus = [dictionary.doc2bow(gen_doc) for gen_doc in gen_docs]\n",
    "# tf_idf = gensim.models.TfidfModel(corpus)\n",
    "# for doc in tf_idf [corpus]:\n",
    "#     print([[dictionary[id], np.around(freq, decimals=2)] for id, freq in doc])\n",
    "# sims = gensim.similarities.Similarity(\"../Ling506TermProject/\",tf_idf[corpus],\n",
    "#                                         num_features=len(dictionary))\n",
    "\n",
    "\n",
    "\n",
    "# file2_docs = [\"Mars is the fourth planet in our solar system.\",\n",
    "#         \"It is second-smallest planet in the Solar System after Mercury.\",\n",
    "#         \"Saturn is yellow planet.\"]\n",
    "# tf_idf = gensim.models.TfidfModel(corpus)\n",
    "\n",
    "# print(\"Number of documents:\",len(file2_docs))  \n",
    "# for line in file2_docs:\n",
    "#     query_doc = [w.lower() for w in word_tokenize(line)]\n",
    "#     query_doc_bow = dictionary.doc2bow(query_doc) #update an existing dictionary and create bag of words\n",
    "\n",
    "# # perform a similarity query against the corpus\n",
    "# query_doc_tf_idf = tf_idf[query_doc_bow]\n",
    "# # print(document_number, document_similarity)\n",
    "# print('Comparing Result:', sims[query_doc_tf_idf]) \n",
    "\n",
    "# sum_of_sims =(np.sum(sims[query_doc_tf_idf], dtype=np.float32))\n",
    "# print(sum_of_sims)\n",
    "\n",
    "# avg_sims = [] # array of averages\n",
    "\n",
    "\n",
    "# # for line in query documents\n",
    "# for line in file2_docs:\n",
    "#     # tokenize words\n",
    "#     query_doc = [w.lower() for w in word_tokenize(line)]\n",
    "#     # create bag of words\n",
    "#     query_doc_bow = dictionary.doc2bow(query_doc)\n",
    "#     # find similarity for each document\n",
    "#     query_doc_tf_idf = tf_idf[query_doc_bow]\n",
    "#     # print (document_number, document_similarity)\n",
    "#     print('Comparing Result:', sims[query_doc_tf_idf]) \n",
    "#     # calculate sum of similarities for each query doc\n",
    "#     sum_of_sims =(np.sum(sims[query_doc_tf_idf], dtype=np.float32))\n",
    "#     # calculate average of similarity for each query doc\n",
    "#     avg = sum_of_sims / len(file_docs)\n",
    "#     # print average of similarity for each query doc\n",
    "#     print(f'avg: {sum_of_sims / len(file_docs)}')\n",
    "#     # add average values into array\n",
    "#     avg_sims.append(avg)  \n",
    "# # calculate total average\n",
    "# total_avg = np.sum(avg_sims, dtype=np.float)\n",
    "# # round the value and multiply by 100 to format it as percentage\n",
    "# percentage_of_similarity = round(float(total_avg) * 100)\n",
    "# # if percentage is greater than 100\n",
    "# # that means documents are almost same\n",
    "# if percentage_of_similarity >= 100:\n",
    "#     percentage_of_similarity = 100\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Bad attempt at using prebuilt functions for distancing\n",
    "# arr1 = np.load(\"ssec_emotion-causetrain_xNP.npy\")\n",
    "# arr2 = np.load(\"ssec_grounded_emotionstrain_xNP.npy\")\n",
    "# arr3 = np.load(\"isear_ssectest_xNP.npy\")\n",
    "# corpus1 = \"ssec\"\n",
    "# corpus1Data = []\n",
    "# corpus1Text = []\n",
    "# corpus2 = \"isear\"\n",
    "# corpus2Data = []\n",
    "# corpus2Text = []\n",
    "# with open(JSON) as f:\n",
    "#     for line in f:\n",
    "#         data = json.loads(line)\n",
    "#         if data[\"source\"] == corpus1:\n",
    "#             corpus1Data.append(data)\n",
    "#         if data[\"source\"] == corpus2:\n",
    "#             corpus2Data.append(data)\n",
    "# print(\"loaded data\")\n",
    "# words1 = getTop5000Words(corpus1Data)\n",
    "# print(words1)\n",
    "# words2 = getTop5000Words(corpus2Data)\n",
    "# for data in tqdm(corpus1Data):\n",
    "#     corpus1Text.append(get_vector(data[\"text\"], words1))\n",
    "# for data in tqdm(corpus1Data):\n",
    "#     corpus2Text.append(get_vector(data[\"text\"], words2))\n",
    "# # print(corpus1Text[:30])\n",
    "# print(np.array_equal(arr1,arr2))\n",
    "# print(np.array_equal(arr1,arr3))\n",
    "# print(cosine_similarity(arr1,arr3))\n",
    "# print(chi2_kernel(arr1,arr3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "#this method is modified to track \n",
    "def make_arrays(train, test, words, labels, mode=\"multi\", all_vs=False):\n",
    "    emotions = {label: x for x, label in enumerate(labels)}\n",
    "    print(\"emotions in make_arrays: \", emotions)\n",
    "    train_x, train_y, test_x, test_y = [], [], [], []\n",
    "    \n",
    "    print(\"train raw text: \", sys.getsizeof(train)/1000000)\n",
    "\n",
    "    for data in tqdm(train):\n",
    "        # Discard examples where we don't have all selected emotions\n",
    "        if (mode == \"single\" or all_vs or all(data[\"emotions\"][emo] is not None for emo in labels)):\n",
    "            train_y.append(get_emotion(data[\"emotions\"], labels, emotions, mode))\n",
    "            train_x.append(get_vector(data[\"text\"], words))\n",
    "    for data in tqdm(test):\n",
    "        test_y.append(get_emotion(data[\"emotions\"], labels, emotions, mode))\n",
    "        test_x.append(get_vector(data[\"text\"], words))\n",
    "\n",
    "    print(\"train_x length \", len(train_x))\n",
    "    print(\"train_x dimension of element \", len(train_x[0]))\n",
    "    train_xSize = sys.getsizeof(train_x)/1000000\n",
    "    train_ySize = sys.getsizeof(train_y)/1000000\n",
    "    train_xLength = len(train_x)\n",
    "    train_yLength = len(train_y)\n",
    "    print(\"train_x (text) size RAW:\", train_xSize,\"megabytes\")\n",
    "    print(\"train_y (labels) size RAW:\", train_ySize,\"megabytes\")\n",
    "    test_xSize = sys.getsizeof(test_x)/1000000\n",
    "    test_ySize = sys.getsizeof(test_y)/1000000\n",
    "    test_xLength = len(test_x)\n",
    "    test_yLength = len(test_y)\n",
    "    print(\"test_x (text) size RAW:\", test_xSize,\"megabytes\")\n",
    "    print(\"test_y (labels) size RAW:\", test_ySize,\"megabytes\")\n",
    "\n",
    "    train_x = np.array(train_x)\n",
    "    train_y = np.array(train_y)\n",
    "    test_x = np.array(test_x)\n",
    "    test_y = np.array(test_y)\n",
    "    train_xNPSize = (train_x.nbytes)/1000000\n",
    "    train_yNPSize = (train_y.nbytes)/1000000\n",
    "    test_xNPSize = (test_x.nbytes)/1000000\n",
    "    test_yNPSize = (test_y.nbytes)/1000000\n",
    "    \n",
    "    print(\"saved test_y\")\n",
    "    print(\"train_x Size stays the same\", train_xSize == train_xNPSize)\n",
    "    print(\"train_y Size stays the same\", train_ySize == train_yNPSize)\n",
    "    print(\"test_x Size stays the same\", test_xSize == test_xNPSize)\n",
    "    print(\"test_y Size stays the same\", test_ySize == test_yNPSize)\n",
    "    print(\"train_xNPSize (text) size:\", train_xNPSize,\"megabytes\")\n",
    "    print(\"train_yNPSize (labels) size:\", train_yNPSize,\"megabytes\")\n",
    "    print(\"test_xNPSize (text) size:\", test_xNPSize,\"megabytes\")\n",
    "    print(\"test_yNPSize (labels) size:\", test_yNPSize,\"megabytes\")\n",
    "    print(\"train_xNP length \", len(train_x))\n",
    "    print(\"train_xNP dimension of element \", train_x.ndim)\n",
    "    print(\"train_xNP size \", train_x.size)\n",
    "    sizes = train_xNPSize, train_yNPSize, test_xNPSize, test_yNPSize\n",
    "    return train_x, train_y, test_x, test_y, sizes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "#kept as part of classification definitions, prevents division by 0 errors\n",
    "def cheatydiv(x, y):\n",
    "    return math.nan if y == 0 else x / y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "#classification reporting is kept the same for simplicity (ie, no need to reinvent the wheel)\n",
    "def classification_report_own_single(test_y, predict_y, labels):\n",
    "    reports = {}\n",
    "    num2emo = {i: label for i, label in enumerate(labels)}\n",
    "    decisions = defaultdict(Counter)\n",
    "    for t, p in zip(test_y, predict_y):\n",
    "        decisions[t][p] += 1\n",
    "    for label in decisions:\n",
    "        tp = decisions[label][label]\n",
    "        fp = sum(decisions[x][label] for x in decisions if x != label)\n",
    "        tn = sum(\n",
    "            decisions[x][y]\n",
    "            for x in decisions\n",
    "            for y in decisions[x]\n",
    "            if x != label and y != label\n",
    "        )\n",
    "        fn = sum(decisions[label][y] for y in decisions[label] if y != label)\n",
    "        precision = tp / (tp + fp) if tp + fp else math.nan\n",
    "        recall = tp / (tp + fn) if tp + fn else math.nan\n",
    "        f1 = 2 * cheatydiv((precision * recall), (precision + recall))\n",
    "        accuracy = (tp + tn) / (tp + tn + fp + fn)\n",
    "        reports[num2emo[label]] = Report(precision, recall, accuracy, f1, tp, tn, fp, fn)\n",
    "    return reports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "#classification reporting is kept the same for simplicity (ie, no need to reinvent the wheel)\n",
    "def classification_report_own_multi(test_y, predict_y, labels):\n",
    "    reports = {}\n",
    "    num2emo = {i: label for i, label in enumerate(labels)}\n",
    "    emo2num = {label: i for i, label in enumerate(labels)}\n",
    "    decisions = defaultdict(Counter)\n",
    "    for label in labels:\n",
    "        tp = fp = tn = fn = 0\n",
    "        for t, p in zip(test_y, predict_y):\n",
    "            # decisions[t][p] += 1\n",
    "            tp += bool(t[emo2num[label]] and p[emo2num[label]])\n",
    "            fp += bool(p[emo2num[label]] and not t[emo2num[label]])\n",
    "            fn += bool(t[emo2num[label]] and not p[emo2num[label]])\n",
    "            tn += bool(not t[emo2num[label]] and not p[emo2num[label]])\n",
    "        precision = tp / (tp + fp) if tp + fp else math.nan\n",
    "        recall = tp / (tp + fn) if tp + fn else math.nan\n",
    "        f1 = 2 * cheatydiv((precision * recall), (precision + recall))\n",
    "        accuracy = (tp + tn) / (tp + tn + fp + fn)\n",
    "        reports[label] = Report(precision, recall, accuracy, f1, tp, tn, fp, fn)\n",
    "    return reports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "#classification reporting is kept the same for simplicity (ie, no need to reinvent the wheel)\n",
    "def analyse_results(test_y, predict_y, labels, test, first, second, output, mode):\n",
    "    print(\"analyse_results\")\n",
    "    prefix = f\"{first}_vs_{second}_{mode}\"\n",
    "    fprefix = output + \"/\" + prefix\n",
    "    with open(fprefix + \".txt\", \"w\", encoding=\"utf-8\") as f, open(fprefix + \".json\", \"w\") as g:\n",
    "        print(\"hello\")\n",
    "        prec, reca, f1, supp = precision_recall_fscore_support(\n",
    "            test_y, predict_y, pos_label=None, average=\"micro\"\n",
    "        )\n",
    "        accuracy = accuracy_score(test_y, predict_y)\n",
    "        scoreNameArray = [(prec, \"Precision\"),(reca, \"Recall\"),(f1, \"F1-score\"),(accuracy, \"Accuracy\")]\n",
    "        for score, name in scoreNameArray:\n",
    "            print(name, score, sep=\"\\t\", file=f)\n",
    "            print(name, score, sep=\"\\t\")\n",
    "            \n",
    "        # print(\"real:\", Counter(test_y), file=f)\n",
    "        # print(\"predicted:\", Counter(predict_y), file=f)\n",
    "        \n",
    "        print(test_y[:10], predict_y[:10], file=f)\n",
    "        emotions = {i: label for i, label in enumerate(labels)}\n",
    "        for text, real, predicted, _ in zip(test, test_y, predict_y, range(20)):\n",
    "            if mode == \"multi\" and np.array_equal(real, predicted):\n",
    "                continue\n",
    "            elif mode == \"single\" and real == predicted:\n",
    "                continue\n",
    "            print(text, \"=> predicted:\", predicted, \", truth:\", real, file=f)\n",
    "        if mode == \"multi\":\n",
    "            results = classification_report_own_multi(test_y, predict_y, labels)\n",
    "        elif mode == \"single\":\n",
    "            results = classification_report_own_single(test_y, predict_y, labels)\n",
    "        json.dump(\n",
    "            {\n",
    "                \"precision\": prec,\n",
    "                \"recall\": reca,\n",
    "                \"f1\": f1,\n",
    "                \"accuracy\": accuracy,\n",
    "                \"name\": prefix,\n",
    "                **{\n",
    "                    (emotion + \"_\" + metric): getattr(results[emotion], metric)\n",
    "                    for emotion in results\n",
    "                    for metric in Report._fields\n",
    "                },\n",
    "            },\n",
    "            g,\n",
    "        )\n",
    "        g.write(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "#used for benchmarking/validating the results of the authors, but not in the final version\n",
    "#method is kept here for documentation\n",
    "def hacky_train_test_split(training, train_size=0.8, first=None, second=None):\n",
    "    tra, tes = [], []\n",
    "    for example in training:\n",
    "        if example.get(\"split\") == \"train\" or example[\"source\"] != second:\n",
    "            tra.append(example)\n",
    "        elif example.get(\"split\") == \"test\":\n",
    "            tes.append(example)\n",
    "        else:\n",
    "            # don't try this at home\n",
    "            [tes, tra][random.random()<train_size].append(example)\n",
    "    return tra, tes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "#used for benchmarking/validating the results of the authors, but not in the final version\n",
    "#method is kept here for documentation\n",
    "def splitTrainAndTestData(training, train_size=0.8, first=None, second=None):\n",
    "    tra, tes = [], []\n",
    "    for example in training:\n",
    "        if example.get(\"split\") == \"train\" or example[\"source\"] != second:\n",
    "            tra.append(example)\n",
    "        elif example.get(\"split\") == \"test\":\n",
    "            tes.append(example)\n",
    "        else:\n",
    "            # don't try this at home\n",
    "            [tes, tra][random.random()<train_size].append(example)\n",
    "    return tra, tes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "#this method is used in my testing to generate the combinations that I use in my trials automation\n",
    "def getPowerset(s):\n",
    "    x = len(s)\n",
    "    masks = [1 << i for i in range(x)]\n",
    "    for i in range(1 << x):\n",
    "        yield [ss for mask, ss in zip(masks, s) if i & mask]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "#this method is used in my testing to generate the combinations that I use in my trials automation\n",
    "def getPermutations(s):\n",
    "    subsets = set()\n",
    "    for L in range(2, 3): #this \n",
    "        for subset in itertools.permutations(s, L):\n",
    "            subsets.add(subset)\n",
    "    return subsets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "#this method is simply in place to get a measure of hard drive space left on my computer\n",
    "def getHardDriveSpaceLeft():\n",
    "    total, used, free = shutil.disk_usage(\"/\")\n",
    "    total = (total // (2**30))\n",
    "    used = (used // (2**30))\n",
    "    free = (free // (2**30))\n",
    "    print(\"Total: %d GB\" % total)\n",
    "    print(\"Used: %d GB\" % used)\n",
    "    print(\"Free: %d GB\" % free)\n",
    "    return total, used, free"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getCrossCorpusValuesWithOrder(possibleChoices):\n",
    "    #gets the runtime values for cross corpus trials\n",
    "    #ordering will matter if using the original authors version\n",
    "    permutations = list(getPermutations(possibleChoices))\n",
    "    print(\"permutations length: \",len(permutations))\n",
    "#         print(permutations)\n",
    "    corporaSets = []\n",
    "    for choice in permutations:\n",
    "#         print(\"choice \", choice)\n",
    "        if(len(choice) == 2):\n",
    "#             print(\"pair\")\n",
    "            first, second = choice\n",
    "            firstCorpus, domain1 = first\n",
    "            secondCorpus, domain2 = second\n",
    "        corpusPairData = (firstCorpus, secondCorpus, domain1, domain2)\n",
    "        corporaSets.append(corpusPairData)\n",
    "    return(corporaSets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This method adds the combinations relating to the ALl-VS trials\n",
    "def getAllVsCorpusValues(possibleChoices):\n",
    "    corporaSets = []\n",
    "    for entry in possibleChoices:\n",
    "        firstCorpus, domain1 = (None, None)\n",
    "        secondCorpus, domain2 = entry\n",
    "        corpusPairData = (firstCorpus, secondCorpus, domain1, domain2)\n",
    "        corporaSets.append(corpusPairData)\n",
    "    return corporaSets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Gets the corpora pairs of the same domain\n",
    "#powerSet is specified because it is only used in the case with a powerSet where ordering does not matter\n",
    "#but hypothetically, you could put in any list of possible entries\n",
    "def getCorporaPairsOfSameDomain(powerSet, sizeBoundLower=1, sizeBoundUpper=3):\n",
    "    for entry in powerSet:\n",
    "#       if len(entry) < 3 and len(entry) > 0:\n",
    "        if len(entry) < sizeBoundUpper and len(entry) > sizeBoundLower:\n",
    "            domainMatch = entry[0][1]\n",
    "            shouldAppend = True\n",
    "            for corpus, domain in entry:\n",
    "                if domain != domainMatch:\n",
    "                    shouldAppend = False\n",
    "            if(shouldAppend):\n",
    "                powerSetCondensed.append(entry)\n",
    "    print(\"CorporaPairsOfSameDomain:\",len(powerSetCondensed))\n",
    "    return sameDomainCorporaPairs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "#this method adds the trials where the corpus is trained and tested on itself\n",
    "def getCorporaPairsWithItself(possibleChoices):\n",
    "    corporaSets = []\n",
    "    for entry in possibleChoices:\n",
    "        firstCorpus, domain1 = entry\n",
    "        secondCorpus, domain2 = entry\n",
    "        corpusPairData = (firstCorpus, secondCorpus, domain1, domain2)\n",
    "        corporaSets.append(corpusPairData)\n",
    "    return corporaSets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "def exampleLabel(x):\n",
    "    if x == 1:\n",
    "        return \"ssec train\"\n",
    "    if x == 2:\n",
    "        return \"ssec train\"\n",
    "    if x == 3:\n",
    "        return \"ssec test\"\n",
    "    if x == 4:\n",
    "        return \"grounded emotion test\"\n",
    "    if x == 5:\n",
    "        return \"grounded emotion train\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "False\n",
      "False\n",
      "False\n",
      "2\n",
      "True\n",
      "False\n",
      "False\n",
      "False\n",
      "3\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "4\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "5\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "ssec_emotion-causetrain_xNP.npy (4868, 5000)\n",
      "ssec_grounded_emotionstrain_xNP.npy (4868, 5000)\n",
      "grounded_emotions_ssectest_xNP.npy (4868, 5000)\n",
      "ssec_grounded_emotionstest_xNP.npy (2585, 5000)\n",
      "grounded_emotions_ssectrain_xNP.npy (2585, 5000)\n",
      "ssec train | ssec train\n",
      "[0. 0. 0. ... 0. 0. 0.]\n",
      "0.0\n",
      "ssec train | ssec test\n",
      "[0.70660613        nan 0.82713948 ... 0.83255461        nan 0.83255461]\n",
      "0.41554195650531944\n",
      "ssec train | grounded emotion test === different shapes\n",
      "ssec train | grounded emotion train === different shapes\n",
      "ssec train | ssec train\n",
      "[0. 0. 0. ... 0. 0. 0.]\n",
      "0.0\n",
      "ssec train | ssec test\n",
      "[0.70660613        nan 0.82713948 ... 0.83255461        nan 0.83255461]\n",
      "0.41554195650531944\n",
      "ssec train | grounded emotion test === different shapes\n",
      "ssec train | grounded emotion train === different shapes\n",
      "ssec test | ssec train\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\Anaconda3\\lib\\site-packages\\scipy\\spatial\\distance.py:1278: RuntimeWarning: invalid value encountered in true_divide\n",
      "  p = p / np.sum(p, axis=0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.70660613        nan 0.82713948 ... 0.83255461        nan 0.83255461]\n",
      "0.41554195650531944\n",
      "ssec test | ssec train\n",
      "[0.70660613        nan 0.82713948 ... 0.83255461        nan 0.83255461]\n",
      "0.41554195650531944\n",
      "ssec test | grounded emotion test === different shapes\n",
      "ssec test | grounded emotion train === different shapes\n",
      "grounded emotion test | ssec train === different shapes\n",
      "grounded emotion test | ssec train === different shapes\n",
      "grounded emotion test | ssec test === different shapes\n",
      "grounded emotion test | grounded emotion train\n",
      "[       nan 0.65382893 0.69251332 ...        nan        nan        nan]\n",
      "0.4374044772966029\n",
      "grounded emotion train | ssec train === different shapes\n",
      "grounded emotion train | ssec train === different shapes\n",
      "grounded emotion train | ssec test === different shapes\n",
      "grounded emotion train | grounded emotion test\n",
      "[       nan 0.65382893 0.69251332 ...        nan        nan        nan]\n",
      "0.4374044772966029\n"
     ]
    }
   ],
   "source": [
    "#test code for understanding how NP arrays are distributed\n",
    "#after testing this, I realized that while my NP arrays are useful for classifiers, I think they are useless\n",
    "#for comparing under the jensen shannon distance, as the only things I can compare are train and test of the same corpora\n",
    "arr1 = np.load(\"ssec_emotion-causetrain_xNP.npy\") #ssec\n",
    "arr2 = np.load(\"ssec_grounded_emotionstrain_xNP.npy\") #ssec\n",
    "arr3 = np.load(\"grounded_emotions_ssectest_xNP.npy\") #ssec\n",
    "arr4 = np.load(\"ssec_grounded_emotionstest_xNP.npy\") #ssec\n",
    "arr5 = np.load(\"grounded_emotions_ssectrain_xNP.npy\") #ssec\n",
    "# arr4 = np.load(\"isear_ssectrain_xNP.npy\")\n",
    "# arr5 = np.load(\"ssec_iseartest_xNP.npy\")\n",
    "# arr6 = np.load(\"ssec_iseartrain_xNP.npy\")\n",
    "print(np.array_equal(arr1,arr2))\n",
    "print(np.array_equal(arr1,arr3))\n",
    "print(np.array_equal(arr1,arr4))\n",
    "print(np.array_equal(arr1,arr5))\n",
    "print(\"2\")\n",
    "print(np.array_equal(arr2,arr1))\n",
    "print(np.array_equal(arr2,arr3))\n",
    "print(np.array_equal(arr2,arr4))\n",
    "print(np.array_equal(arr2,arr5))\n",
    "print(\"3\")\n",
    "print(np.array_equal(arr3,arr1))\n",
    "print(np.array_equal(arr3,arr2))\n",
    "print(np.array_equal(arr3,arr4))\n",
    "print(np.array_equal(arr3,arr5))\n",
    "print(\"4\")\n",
    "print(np.array_equal(arr4,arr1))\n",
    "print(np.array_equal(arr4,arr2))\n",
    "print(np.array_equal(arr4,arr3))\n",
    "print(np.array_equal(arr4,arr5))\n",
    "print(\"5\")\n",
    "print(np.array_equal(arr5,arr1))\n",
    "print(np.array_equal(arr5,arr2))\n",
    "print(np.array_equal(arr5,arr3))\n",
    "print(np.array_equal(arr5,arr4))\n",
    "\n",
    "print(\"ssec_emotion-causetrain_xNP.npy\", arr1.shape)\n",
    "print(\"ssec_grounded_emotionstrain_xNP.npy\",arr2.shape)\n",
    "print(\"grounded_emotions_ssectest_xNP.npy\", arr3.shape)\n",
    "print(\"ssec_grounded_emotionstest_xNP.npy\", arr4.shape)\n",
    "print(\"grounded_emotions_ssectrain_xNP.npy\", arr5.shape)\n",
    "# print(\"ssec_iseartrain_xNP.npy\", arr6.shape)\n",
    "arrList = [arr1,arr2,arr3,arr4,arr5]\n",
    "for i in range(5):\n",
    "    for j in range(5):\n",
    "        if i == j:\n",
    "            continue\n",
    "        if arrList[i].shape == arrList[j].shape:\n",
    "            print(exampleLabel(i+1),\"|\", exampleLabel(j+1))\n",
    "            print(getJensenShannonFromNPArrays(arrList[i],arrList[j]))\n",
    "        else:\n",
    "            print(exampleLabel(i+1),\"|\", exampleLabel(j+1), \"=== different shapes\")\n",
    "# print(getJensenShannonFromNPArrays(arr1,arr2))\n",
    "# print(getJensenShannonFromNPArrays(arr1,arr3))\n",
    "# print(getJensenShannonFromNPArrays(arr1,arr4))\n",
    "# print(getJensenShannonFromNPArrays(arr1,arr5))\n",
    "# print(\"2\")\n",
    "# print(getJensenShannonFromNPArrays(arr2,arr1))\n",
    "# print(getJensenShannonFromNPArrays(arr2,arr3))\n",
    "# print(getJensenShannonFromNPArrays(arr2,arr4))\n",
    "# print(getJensenShannonFromNPArrays(arr2,arr5))\n",
    "# print(\"3\")\n",
    "# print(getJensenShannonFromNPArrays(arr3,arr1))\n",
    "# print(getJensenShannonFromNPArrays(arr3,arr2))\n",
    "# print(getJensenShannonFromNPArrays(arr3,arr4))\n",
    "# print(getJensenShannonFromNPArrays(arr3,arr5))\n",
    "# print(\"4\")\n",
    "# print(getJensenShannonFromNPArrays(arr4,arr1))\n",
    "# print(getJensenShannonFromNPArrays(arr4,arr2))\n",
    "# print(getJensenShannonFromNPArrays(arr4,arr3))\n",
    "# print(getJensenShannonFromNPArrays(arr4,arr5))\n",
    "# print(\"5\")\n",
    "# print(getJensenShannonFromNPArrays(arr5,arr1))\n",
    "# print(getJensenShannonFromNPArrays(arr5,arr2))\n",
    "# print(getJensenShannonFromNPArrays(arr5,arr3))\n",
    "# print(getJensenShannonFromNPArrays(arr5,arr4))\n",
    "# print(getJensenShannonFromNPArrays(arr5,arr6))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getCorpusSimilarities(corpusPair):\n",
    "    print(\"------------------------------\",corpusPair,\"-------------------------------------------\")\n",
    "    (first, second, domain1, domain2) = corpusPair\n",
    "    print(\"Getting data\")\n",
    "    jsonfile = \"unified-dataset.jsonl\"\n",
    "    output = \".\"\n",
    "    debug = True\n",
    "    forceMulti = False\n",
    "    isAllVS = False\n",
    "    if first == None:\n",
    "        isAllVS = True\n",
    "    similaritiesFileName = first + \"_\" + second + \"Similarities\" +\".txt\"\n",
    "#     numPyFileName1 = first + \"_\" + second + \"train_xNP\" +\".npy\"\n",
    "#     numPyFileName2 = first + \"_\" + second + \"test_xNP\" +\".npy\"\n",
    "#     np1 = np.load(numPyFileName1)\n",
    "#     np2 = np.load(numPyFileName2)\n",
    "    cosineSim = getCosineSimilarityFromCorpus(first,second)\n",
    "    cosineSimEmotions = getCosineSimilarityFromCorpusEmotions(first,second)\n",
    "    print(\"creating file for corpus similarity\")\n",
    "    with open(similaritiesFileName, 'w', encoding=\"utf-8\") as f:\n",
    "        print(\"CosineSimilarity\", cosineSim)\n",
    "        print(\"CosineSimilarity\", cosineSim, file=f)\n",
    "        print(cosineSimEmotions)\n",
    "        for emotion, cosSim in cosineSimEmotions.items():\n",
    "            print(emotion, cosSim, file=f)\n",
    "#         if(np1.shape == np2.shape):\n",
    "#             print(np1.shape)\n",
    "#             print(np2.shape)\n",
    "#             js = getJensenShannonFromNPArrays(np1,np2)\n",
    "#             print(\"jensen Shannon\", js)\n",
    "#         else:\n",
    "#             print(np1.shape)\n",
    "#             print(np2.shape)\n",
    "#             print(\"jensenShannon\", math.nan)\n",
    "    print(\"file saved to \", similaritiesFileName)\n",
    "    \n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "def performTrialUsingCorpusPair(corpusPair, verifyResults):\n",
    "    print(\"------------------------------\",corpusPair,\"-------------------------------------------\")\n",
    "    (first, second, domain1, domain2) = corpusPair\n",
    "    print(\"Getting data\")\n",
    "    jsonfile = \"unified-dataset.jsonl\"\n",
    "    output = \".\"\n",
    "    debug = True\n",
    "    forceMulti = False\n",
    "    isAllVS = False\n",
    "    if first == None:\n",
    "        isAllVS = True\n",
    "    \n",
    "    if(verifyResults == False):\n",
    "        if(first == None):\n",
    "            first = \"all-vs\"\n",
    "        train_xNPFileName = first + \"_\" + second + \"train_xNP\" +\".npy\"\n",
    "        train_yNPFileName = first + \"_\" + second + \"train_yNP\" +\".npy\"\n",
    "        test_xNPFileName = first + \"_\" + second + \"test_xNP\" +\".npy\"\n",
    "        test_yNPFileName = first + \"_\" + second + \"test_yNP\" +\".npy\"\n",
    "        classifierName = \"RandomForestClassifier\"\n",
    "        classiferSaveFile = first+\"_\"+second+classifierName+\".pkl\"\n",
    "        filesValid = (path.exists(train_xNPFileName) \n",
    "                       and path.exists(train_yNPFileName)\n",
    "                       and path.exists(test_xNPFileName)\n",
    "                       and path.exists(test_yNPFileName)\n",
    "                       and path.exists(classiferSaveFile))\n",
    "        print(\"do pickle files exist?\", filesValid)\n",
    "        if(filesValid):\n",
    "            print(\"skipping trial\")\n",
    "            return\n",
    "    \n",
    "    \n",
    "    training_data, testing_data = get_train_test(jsonfile, first,second)\n",
    "    firstCLF, secondCLF = ([\"multi\", \"multi\"] if forceMulti else get_clf_mode(training_data, testing_data))\n",
    "    mode = \"multi\" if \"multi\" in [firstCLF, secondCLF] else \"single\"\n",
    "\n",
    "    print(\"Detected mode: {}...\".format(mode))\n",
    "    print(len(training_data), len(testing_data))\n",
    "    print(\"Getting wordlist...\")\n",
    "    if debug:\n",
    "        wordlist = getTop5000Words(training_data)\n",
    "    else:\n",
    "        wordlist = getTop5000Words(training_data)\n",
    "        # wordlist = get_wordlist(training_data)\n",
    "    print(\"Getting emotions\")\n",
    "    labels = get_labels(training_data, testing_data, mode=mode)\n",
    "    print(labels)\n",
    "    print(\"Making arrays\")\n",
    "    print(\"checking for save files\")\n",
    "    if(first == None):\n",
    "        first = \"all-vs\"\n",
    "    train_xNPFileName = first + \"_\" + second + \"train_xNP\" +\".npy\"\n",
    "    train_yNPFileName = first + \"_\" + second + \"train_yNP\" +\".npy\"\n",
    "    test_xNPFileName = first + \"_\" + second + \"test_xNP\" +\".npy\"\n",
    "    test_yNPFileName = first + \"_\" + second + \"test_yNP\" +\".npy\"\n",
    "\n",
    "    if(path.exists(train_xNPFileName) \n",
    "       and path.exists(train_yNPFileName)\n",
    "       and path.exists(test_xNPFileName)\n",
    "       and path.exists(test_yNPFileName)):\n",
    "        print(\"loading from np\")\n",
    "        train_x = np.load(train_xNPFileName)\n",
    "        train_y = np.load(train_yNPFileName)\n",
    "        test_x = np.load(test_xNPFileName)\n",
    "        test_y = np.load(test_yNPFileName)\n",
    "        train_xNPSize = (train_x.nbytes)/1000000\n",
    "        train_yNPSize = (train_y.nbytes)/1000000\n",
    "        test_xNPSize = (test_x.nbytes)/1000000\n",
    "        test_yNPSize = (test_y.nbytes)/1000000\n",
    "        print(\"loaded directly from NP.load\")\n",
    "        print(\"train_xNPSize (text) size loaded:\", train_xNPSize,\"megabytes\")\n",
    "        print(\"train_yNPSize (labels) size loaded:\", train_yNPSize,\"megabytes\")\n",
    "        print(\"test_xNPSize (text) size loaded:\", test_xNPSize,\"megabytes\")\n",
    "        print(\"test_yNPSize (labels) size loaded:\", test_yNPSize,\"megabytes\")\n",
    "    else:\n",
    "#         print(\"training_data\", training_data)\n",
    "#         print(\"testing_data\", testing_data)\n",
    "        train_x, train_y, test_x, test_y, sizes = make_arrays(training_data, testing_data, wordlist, labels, mode, isAllVS)\n",
    "        train_xSize, train_ySize, test_xSize, test_ySize = sizes\n",
    "        if any(not part.size for part in [train_x, train_y, test_x, test_y]):\n",
    "            print(\"Train or test empty. Did you misspell the dataset name?\")\n",
    "            return\n",
    "        #             sys.exit(1)\n",
    "        print(\"saving NP arrays\")\n",
    "        np.save(train_xNPFileName, train_x)\n",
    "        np.save(train_yNPFileName, train_y)\n",
    "        np.save(test_xNPFileName, test_x)\n",
    "        np.save(test_yNPFileName, test_y)\n",
    "        print(\"NP arrays saved\")\n",
    "\n",
    "    print(\"Initializing classifier\")\n",
    "    trainClassifier = True\n",
    "    if debug:\n",
    "        classifierName = \"RandomForestClassifier\"\n",
    "        print(\"Searching for a \", classifierName)\n",
    "        classiferSaveFile = first+\"_\"+second+classifierName+\".pkl\"\n",
    "        print(path.exists(classiferSaveFile))\n",
    "        if(path.exists(classiferSaveFile)):\n",
    "            trainClassifier = False\n",
    "            print(\"Loading classifier from file\")\n",
    "            classifier = joblib.load(classiferSaveFile)\n",
    "            print(\"classifier loaded successfully\")\n",
    "        else:\n",
    "            print(\"file not found, creating new classifier\")\n",
    "            classifier = RandomForestClassifier()\n",
    "    elif mode == \"single\":\n",
    "        classifierName = \"LogisticRegressionCV\"\n",
    "        print(\"Searching for a \", classifierName)\n",
    "        classiferSaveFile = first+\"_\"+second+classifierName+\".pkl\"\n",
    "        print(path.exists(classiferSaveFile))\n",
    "        if(path.exists(classiferSaveFile)):\n",
    "            trainClassifier = False\n",
    "            print(\"Loading classifier from file\")\n",
    "            classifier = joblib.load(classiferSaveFile)\n",
    "            print(\"classifier loaded successfully\")\n",
    "        else:\n",
    "            print(\"file not found, creating new classifier\")\n",
    "            classifier = LogisticRegressionCV(\n",
    "                cv=10,\n",
    "                penalty=\"l2\",\n",
    "                fit_intercept=True,\n",
    "                solver=\"sag\",\n",
    "                scoring=\"f1\",\n",
    "                refit=True,\n",
    "                # n_jobs=-1,\n",
    "                class_weight=\"balanced\",\n",
    "            )\n",
    "    else:\n",
    "        classifierName = \"OneVsRestClassifier\"\n",
    "        print(\"Searching for a \", classifierName)\n",
    "        classiferSaveFile = first+\"_\"+second+classifierName+\".pkl\"\n",
    "        print(path.exists(classiferSaveFile))\n",
    "        if(path.exists(classiferSaveFile)):\n",
    "            trainClassifier = False\n",
    "            print(\"Loading classifier from file\")\n",
    "            classifier = joblib.load(classiferSaveFile)\n",
    "            print(\"classifier loaded successfully\")\n",
    "        else:\n",
    "            print(\"file not found, creating new classifier\")\n",
    "            classifier = OneVsRestClassifier(\n",
    "                LogisticRegressionCV(\n",
    "                    cv=10,\n",
    "                    penalty=\"l2\",\n",
    "                    fit_intercept=True,\n",
    "                    solver=\"sag\",\n",
    "                    scoring=\"f1\",\n",
    "                    refit=True,\n",
    "                    class_weight=\"balanced\",\n",
    "                    tol = 0.1,\n",
    "                ),\n",
    "                n_jobs=-1,\n",
    "            )\n",
    "    if(trainClassifier):\n",
    "        print(\"this is the classifierName: \", classifierName)\n",
    "        print(\"Training...\")\n",
    "        print(\"train_x (text) size:\", (train_x.nbytes)/1000000,\"megabytes\")\n",
    "        print(\"train_y (labels) size:\", (train_y.nbytes)/1000000,\"megabytes\")\n",
    "        print(\"train_x (text) length:\", len(train_x))\n",
    "        print(\"train_y (labels) length:\", len(train_y))\n",
    "        print(train_x[:5])\n",
    "        print(train_y[:5])\n",
    "\n",
    "        classifier.fit(train_x, train_y)\n",
    "        print(\"finished training, classifier size:\", sys.getsizeof(classifier)/1000000,\"megabytes\")\n",
    "    print(\"Predicting...\")\n",
    "    if first == \"multi\" and second == \"single\":\n",
    "        predict_y = classifier.predict_proba(test_x)\n",
    "        helper = np.zeros_like(predict_y)\n",
    "        helper[range(len(predict_y)), predict_y.argmax(1)] = 1\n",
    "        predict_y = helper\n",
    "    else:\n",
    "        predict_y = classifier.predict(test_x)\n",
    "\n",
    "    print(\"Analysing...\")\n",
    "\n",
    "    analyse_results(\n",
    "        test_y,\n",
    "        predict_y,\n",
    "        labels,\n",
    "        testing_data,\n",
    "        first,\n",
    "        second,\n",
    "        output,\n",
    "        mode,  # TODO\n",
    "    )\n",
    "    if(path.exists(classiferSaveFile)):\n",
    "        print(\"classifier already saved\")\n",
    "    else:\n",
    "#         classiferSaveFile = first+\"_\"+second+classifierName+\".pkl\"\n",
    "        print(\"classiferSaveFile: \", classiferSaveFile)\n",
    "        joblib.dump(classifier, classiferSaveFile)\n",
    "        print(\"Saved Successfully\")\n",
    "    total, used, free = getHardDriveSpaceLeft()\n",
    "    if(free < 10):\n",
    "        sys.exit(\"Error: less than 10 gb remaining on disk\")\n",
    "    print(\"-----------------------------------------------------------------------------------------\")\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "def runTrials(version, verifyResults, classifierTrials, similarityTrials, crossCorpus=True, sameCorpus=True, allVs=False):\n",
    "    possibleChoices = [('affectivetext','headlines'), ('crowdflower','tweets'), ('dailydialog','conversations'), \n",
    "                       ('emoint','tweets'), ('emotion-cause','paragraphs'), ('grounded_emotions','tweets'), \n",
    "                       ('isear','descriptions'), ('ssec','tweets'),('tales-emotion','tales'), ('tec','tweets')]\n",
    "                        #excluded ('emobank','headlines') because it is isn't emotion annotated\n",
    "                        #and ('electoraltweets','tweets') because it has incompatible annotation\n",
    "                        #and  ('fb-valence-arousal-anon','tweets') because it isn't emotion annotated\n",
    "    corporaSets = []\n",
    "    if version == \"previous\":\n",
    "        corporaSets = []\n",
    "        if crossCorpus:\n",
    "            corporaSets = (getCrossCorpusValuesWithOrder(possibleChoices))\n",
    "            #this was added to sort the lists by domain of the first, then by the first corpus name, then the second.\n",
    "            #it is placed in reverse order simply because if it was put in regular order, the largest of the trials would be first\n",
    "            #sorting in reverse will (loosely) make the smaller trials run first, while having no impact on the ability to obtain all results\n",
    "            sortedPermutations = sorted(corporaSets, key = lambda x: (x[2], x[0], x[1]), reverse = True)\n",
    "        if sameCorpus:\n",
    "            sortedPermutations += (getCorporaPairsWithItself(possibleChoices))\n",
    "        if allVs:\n",
    "            sortedPermutations += (getAllVsCorpusValues(possibleChoices))\n",
    "        for corpusPair in sortedPermutations:\n",
    "            if(classifierTrials):\n",
    "                performTrialUsingCorpusPair(corpusPair, verifyResults)\n",
    "            if(similarityTrials):\n",
    "                getCorpusSimilarities(corpusPair)\n",
    "    else: #version == \"myTrials\"\n",
    "        powerSet = list(getPowerset(possibleChoices))\n",
    "    \n",
    "    print(\"End of program!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "permutations length:  90\n",
      "------------------------------ ('tec', 'tales-emotion', 'tweets', 'tales') -------------------------------------------\n",
      "Getting data\n",
      "{'anger', 'surprise', 'trust', 'disgust', 'fear', 'sadness', 'joy'}\n",
      "{'anger', 'surprise', 'trust', 'shame', 'disgust', 'fear', 'noemo', 'sadness', 'guilt', 'joy'}\n",
      "matched Labels: {'anger', 'surprise', 'trust', 'disgust', 'fear', 'sadness', 'joy'}\n",
      "{'anger', 'surprise', 'trust', 'disgust', 'fear', 'sadness', 'joy'}\n",
      "{'anger', 'surprise', 'trust', 'shame', 'disgust', 'fear', 'noemo', 'sadness', 'guilt', 'joy'}\n",
      "matched Labels: {'anger', 'surprise', 'trust', 'disgust', 'fear', 'sadness', 'joy'}\n",
      "creating file for corpus similarity\n",
      "CosineSimilarity 0.5208380734001562\n",
      "{'anger': 0.6949168102796758, 'surprise': 0.469556995823313, 'trust': 0.998182774928435, 'disgust': 0.7252183955756708, 'fear': 0.6000328385623378, 'sadness': 0.594206163179562, 'joy': 0.5461644236745259}\n",
      "file saved to  tec_tales-emotionSimilarities.txt\n",
      "------------------------------ ('tec', 'ssec', 'tweets', 'tweets') -------------------------------------------\n",
      "Getting data\n",
      "{'anger', 'surprise', 'trust', 'disgust', 'fear', 'sadness', 'joy'}\n",
      "{'anger', 'surprise', 'trust', 'shame', 'disgust', 'fear', 'noemo', 'sadness', 'guilt', 'joy'}\n",
      "matched Labels: {'anger', 'surprise', 'trust', 'disgust', 'fear', 'sadness', 'joy'}\n",
      "{'anger', 'surprise', 'trust', 'disgust', 'fear', 'sadness', 'joy'}\n",
      "{'anger', 'surprise', 'trust', 'shame', 'disgust', 'fear', 'noemo', 'sadness', 'guilt', 'joy'}\n",
      "matched Labels: {'anger', 'surprise', 'trust', 'disgust', 'fear', 'sadness', 'joy'}\n",
      "creating file for corpus similarity\n",
      "CosineSimilarity 0.5226664725136427\n",
      "{'anger': 0.7039652986529049, 'surprise': 0.4764965071859645, 'trust': 0.9948006378543295, 'disgust': 0.7349252762260817, 'fear': 0.6068357754548268, 'sadness': 0.6013606576364068, 'joy': 0.5517641256699333}\n",
      "file saved to  tec_ssecSimilarities.txt\n",
      "------------------------------ ('tec', 'isear', 'tweets', 'descriptions') -------------------------------------------\n",
      "Getting data\n",
      "{'anger', 'surprise', 'trust', 'disgust', 'fear', 'sadness', 'joy'}\n",
      "{'anger', 'surprise', 'trust', 'shame', 'disgust', 'fear', 'noemo', 'sadness', 'guilt', 'joy'}\n",
      "matched Labels: {'anger', 'surprise', 'trust', 'disgust', 'fear', 'sadness', 'joy'}\n",
      "{'anger', 'surprise', 'trust', 'disgust', 'fear', 'sadness', 'joy'}\n",
      "{'anger', 'surprise', 'trust', 'shame', 'disgust', 'fear', 'noemo', 'sadness', 'guilt', 'joy'}\n",
      "matched Labels: {'anger', 'surprise', 'trust', 'disgust', 'fear', 'sadness', 'joy'}\n",
      "creating file for corpus similarity\n",
      "CosineSimilarity 0.5234330747280243\n",
      "{'anger': 0.6976336380074538, 'surprise': 0.47457930336580156, 'trust': 0.9948006378543295, 'disgust': 0.7250489219481213, 'fear': 0.6019336882999944, 'sadness': 0.5983307926695821, 'joy': 0.5503813819303277}\n",
      "file saved to  tec_isearSimilarities.txt\n",
      "------------------------------ ('tec', 'grounded_emotions', 'tweets', 'tweets') -------------------------------------------\n",
      "Getting data\n",
      "{'anger', 'surprise', 'trust', 'disgust', 'fear', 'sadness', 'joy'}\n",
      "{'anger', 'surprise', 'trust', 'shame', 'disgust', 'fear', 'noemo', 'sadness', 'guilt', 'joy'}\n",
      "matched Labels: {'anger', 'surprise', 'trust', 'disgust', 'fear', 'sadness', 'joy'}\n",
      "{'anger', 'surprise', 'trust', 'disgust', 'fear', 'sadness', 'joy'}\n",
      "{'anger', 'surprise', 'trust', 'shame', 'disgust', 'fear', 'noemo', 'sadness', 'guilt', 'joy'}\n",
      "matched Labels: {'anger', 'surprise', 'trust', 'disgust', 'fear', 'sadness', 'joy'}\n",
      "creating file for corpus similarity\n",
      "CosineSimilarity 0.5195512896814706\n",
      "{'anger': 0.6953299056223214, 'surprise': 0.47284536558189716, 'trust': 0.9948006378543295, 'disgust': 0.7226877403436016, 'fear': 0.5999624228539517, 'sadness': 0.5865648000792304, 'joy': 0.5401012454740652}\n",
      "file saved to  tec_grounded_emotionsSimilarities.txt\n",
      "------------------------------ ('tec', 'emotion-cause', 'tweets', 'paragraphs') -------------------------------------------\n",
      "Getting data\n",
      "{'anger', 'surprise', 'trust', 'disgust', 'fear', 'sadness', 'joy'}\n",
      "{'anger', 'surprise', 'trust', 'shame', 'disgust', 'fear', 'noemo', 'sadness', 'guilt', 'joy'}\n",
      "matched Labels: {'anger', 'surprise', 'trust', 'disgust', 'fear', 'sadness', 'joy'}\n",
      "{'anger', 'surprise', 'trust', 'disgust', 'fear', 'sadness', 'joy'}\n",
      "{'anger', 'surprise', 'trust', 'shame', 'disgust', 'fear', 'noemo', 'sadness', 'guilt', 'joy'}\n",
      "matched Labels: {'anger', 'surprise', 'trust', 'disgust', 'fear', 'sadness', 'joy'}\n",
      "creating file for corpus similarity\n",
      "CosineSimilarity 0.5196824398271198\n",
      "{'anger': 0.6869513972031539, 'surprise': 0.4740020168582144, 'trust': 0.9948006378543295, 'disgust': 0.7171940940538325, 'fear': 0.5951083412958446, 'sadness': 0.5844996006832802, 'joy': 0.5411157188885544}\n",
      "file saved to  tec_emotion-causeSimilarities.txt\n",
      "------------------------------ ('tec', 'emoint', 'tweets', 'tweets') -------------------------------------------\n",
      "Getting data\n",
      "{'anger', 'surprise', 'trust', 'disgust', 'fear', 'sadness', 'joy'}\n",
      "{'anger', 'surprise', 'trust', 'shame', 'disgust', 'fear', 'noemo', 'sadness', 'guilt', 'joy'}\n",
      "matched Labels: {'anger', 'surprise', 'trust', 'disgust', 'fear', 'sadness', 'joy'}\n",
      "{'anger', 'surprise', 'trust', 'disgust', 'fear', 'sadness', 'joy'}\n",
      "{'anger', 'surprise', 'trust', 'shame', 'disgust', 'fear', 'noemo', 'sadness', 'guilt', 'joy'}\n",
      "matched Labels: {'anger', 'surprise', 'trust', 'disgust', 'fear', 'sadness', 'joy'}\n",
      "creating file for corpus similarity\n",
      "CosineSimilarity 0.5232293311355566\n",
      "{'anger': 0.6724914544095342, 'surprise': 0.47258675249447096, 'trust': 0.9948006378543295, 'disgust': 0.7151950762663617, 'fear': 0.5848890260601501, 'sadness': 0.5808893761128391, 'joy': 0.5416742666964923}\n",
      "file saved to  tec_emointSimilarities.txt\n",
      "------------------------------ ('tec', 'dailydialog', 'tweets', 'conversations') -------------------------------------------\n",
      "Getting data\n",
      "{'anger', 'surprise', 'trust', 'disgust', 'fear', 'sadness', 'joy'}\n",
      "{'anger', 'surprise', 'trust', 'shame', 'disgust', 'fear', 'noemo', 'sadness', 'guilt', 'joy'}\n",
      "matched Labels: {'anger', 'surprise', 'trust', 'disgust', 'fear', 'sadness', 'joy'}\n",
      "{'anger', 'surprise', 'trust', 'disgust', 'fear', 'sadness', 'joy'}\n",
      "{'anger', 'surprise', 'trust', 'shame', 'disgust', 'fear', 'noemo', 'sadness', 'guilt', 'joy'}\n",
      "matched Labels: {'anger', 'surprise', 'trust', 'disgust', 'fear', 'sadness', 'joy'}\n",
      "creating file for corpus similarity\n",
      "CosineSimilarity 0.5316400468149156\n",
      "{'anger': 0.6716001346412821, 'surprise': 0.48608122443043617, 'trust': 0.9948006378543295, 'disgust': 0.7136869524180277, 'fear': 0.5836042069661299, 'sadness': 0.5813187777338752, 'joy': 0.5560750673370198}\n",
      "file saved to  tec_dailydialogSimilarities.txt\n",
      "------------------------------ ('tec', 'crowdflower', 'tweets', 'tweets') -------------------------------------------\n",
      "Getting data\n",
      "{'anger', 'surprise', 'trust', 'disgust', 'fear', 'sadness', 'joy'}\n",
      "{'anger', 'surprise', 'trust', 'shame', 'love', 'disgust', 'fear', 'noemo', 'sadness', 'guilt', 'joy'}\n",
      "matched Labels: {'anger', 'surprise', 'trust', 'disgust', 'fear', 'sadness', 'joy'}\n",
      "{'anger', 'surprise', 'trust', 'disgust', 'fear', 'sadness', 'joy'}\n",
      "{'anger', 'surprise', 'trust', 'shame', 'love', 'disgust', 'fear', 'noemo', 'sadness', 'guilt', 'joy'}\n",
      "matched Labels: {'anger', 'surprise', 'trust', 'disgust', 'fear', 'sadness', 'joy'}\n",
      "creating file for corpus similarity\n",
      "CosineSimilarity 0.5265197105850198\n",
      "{'anger': 0.6634138049340643, 'surprise': 0.49935761887930835, 'trust': 0.9948006378543295, 'disgust': 0.7121894475242337, 'fear': 0.5503051817379745, 'sadness': 0.5812842370590138, 'joy': 0.5479576921400462}\n",
      "file saved to  tec_crowdflowerSimilarities.txt\n",
      "------------------------------ ('tec', 'affectivetext', 'tweets', 'headlines') -------------------------------------------\n",
      "Getting data\n",
      "{'anger', 'surprise', 'trust', 'disgust', 'fear', 'sadness', 'joy'}\n",
      "{'anger', 'surprise', 'trust', 'shame', 'love', 'disgust', 'fear', 'noemo', 'sadness', 'guilt', 'joy'}\n",
      "matched Labels: {'anger', 'surprise', 'trust', 'disgust', 'fear', 'sadness', 'joy'}\n",
      "{'anger', 'surprise', 'trust', 'disgust', 'fear', 'sadness', 'joy'}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'anger', 'surprise', 'trust', 'shame', 'love', 'disgust', 'fear', 'noemo', 'sadness', 'guilt', 'joy'}\n",
      "matched Labels: {'anger', 'surprise', 'trust', 'disgust', 'fear', 'sadness', 'joy'}\n",
      "creating file for corpus similarity\n",
      "CosineSimilarity 0.5136445512583515\n",
      "{'anger': 0.6621017981730385, 'surprise': 0.4983905604641875, 'trust': 0.9948006378543295, 'disgust': 0.7106004598283716, 'fear': 0.5493963173972677, 'sadness': 0.5801998644819535, 'joy': 0.5472453009778845}\n",
      "file saved to  tec_affectivetextSimilarities.txt\n",
      "------------------------------ ('ssec', 'tec', 'tweets', 'tweets') -------------------------------------------\n",
      "Getting data\n",
      "{'anger', 'surprise', 'trust', 'disgust', 'fear', 'sadness', 'joy'}\n",
      "{'anger', 'surprise', 'trust', 'shame', 'love', 'disgust', 'fear', 'noemo', 'sadness', 'guilt', 'joy'}\n",
      "matched Labels: {'anger', 'surprise', 'trust', 'disgust', 'fear', 'sadness', 'joy'}\n",
      "{'anger', 'surprise', 'trust', 'disgust', 'fear', 'sadness', 'joy'}\n",
      "{'anger', 'surprise', 'trust', 'shame', 'love', 'disgust', 'fear', 'noemo', 'sadness', 'guilt', 'joy'}\n",
      "matched Labels: {'anger', 'surprise', 'trust', 'disgust', 'fear', 'sadness', 'joy'}\n",
      "creating file for corpus similarity\n",
      "CosineSimilarity 0.6650259193985947\n",
      "{'anger': 0.7998928140275687, 'surprise': 0.8388940981393507, 'trust': 0.999877726332576, 'disgust': 0.8565885008127602, 'fear': 0.7234900144195807, 'sadness': 0.7658950532520483, 'joy': 0.7365813501139095}\n",
      "file saved to  ssec_tecSimilarities.txt\n",
      "------------------------------ ('ssec', 'tales-emotion', 'tweets', 'tales') -------------------------------------------\n",
      "Getting data\n",
      "{'anger', 'surprise', 'trust', 'disgust', 'fear', 'sadness', 'joy'}\n",
      "{'anger', 'surprise', 'trust', 'shame', 'love', 'disgust', 'fear', 'noemo', 'sadness', 'guilt', 'joy'}\n",
      "matched Labels: {'anger', 'surprise', 'trust', 'disgust', 'fear', 'sadness', 'joy'}\n",
      "{'anger', 'surprise', 'trust', 'disgust', 'fear', 'sadness', 'joy'}\n",
      "{'anger', 'surprise', 'trust', 'shame', 'love', 'disgust', 'fear', 'noemo', 'sadness', 'guilt', 'joy'}\n",
      "matched Labels: {'anger', 'surprise', 'trust', 'disgust', 'fear', 'sadness', 'joy'}\n",
      "creating file for corpus similarity\n",
      "CosineSimilarity 0.7040322521141175\n",
      "{'anger': 0.8073788721415153, 'surprise': 0.8427565101920598, 'trust': 0.9999416274599928, 'disgust': 0.8650574342473067, 'fear': 0.7294819793041516, 'sadness': 0.7726325741851322, 'joy': 0.7401751339464648}\n",
      "file saved to  ssec_tales-emotionSimilarities.txt\n",
      "------------------------------ ('ssec', 'isear', 'tweets', 'descriptions') -------------------------------------------\n",
      "Getting data\n",
      "{'anger', 'surprise', 'trust', 'disgust', 'fear', 'sadness', 'joy'}\n",
      "{'anger', 'surprise', 'trust', 'shame', 'love', 'disgust', 'fear', 'noemo', 'sadness', 'guilt', 'joy'}\n",
      "matched Labels: {'anger', 'surprise', 'trust', 'disgust', 'fear', 'sadness', 'joy'}\n",
      "{'anger', 'surprise', 'trust', 'disgust', 'fear', 'sadness', 'joy'}\n",
      "{'anger', 'surprise', 'trust', 'shame', 'love', 'disgust', 'fear', 'noemo', 'sadness', 'guilt', 'joy'}\n",
      "matched Labels: {'anger', 'surprise', 'trust', 'disgust', 'fear', 'sadness', 'joy'}\n",
      "creating file for corpus similarity\n",
      "CosineSimilarity 0.705608982066213\n",
      "{'anger': 0.8085770180821288, 'surprise': 0.8458830490526941, 'trust': 0.9996806401267039, 'disgust': 0.8623313488343841, 'fear': 0.7313153601612666, 'sadness': 0.7754206227772629, 'joy': 0.7419220127411794}\n",
      "file saved to  ssec_isearSimilarities.txt\n",
      "------------------------------ ('ssec', 'grounded_emotions', 'tweets', 'tweets') -------------------------------------------\n",
      "Getting data\n",
      "{'anger', 'surprise', 'trust', 'disgust', 'fear', 'sadness', 'joy'}\n",
      "{'anger', 'surprise', 'trust', 'shame', 'love', 'disgust', 'fear', 'noemo', 'sadness', 'guilt', 'joy'}\n",
      "matched Labels: {'anger', 'surprise', 'trust', 'disgust', 'fear', 'sadness', 'joy'}\n",
      "{'anger', 'surprise', 'trust', 'disgust', 'fear', 'sadness', 'joy'}\n",
      "{'anger', 'surprise', 'trust', 'shame', 'love', 'disgust', 'fear', 'noemo', 'sadness', 'guilt', 'joy'}\n",
      "matched Labels: {'anger', 'surprise', 'trust', 'disgust', 'fear', 'sadness', 'joy'}\n",
      "creating file for corpus similarity\n",
      "CosineSimilarity 0.7051686708244552\n",
      "{'anger': 0.8107722192709224, 'surprise': 0.8479134202324058, 'trust': 0.9993921769300302, 'disgust': 0.8646586124074661, 'fear': 0.7332800824603077, 'sadness': 0.7714535657387402, 'joy': 0.737595965574766}\n",
      "file saved to  ssec_grounded_emotionsSimilarities.txt\n",
      "------------------------------ ('ssec', 'emotion-cause', 'tweets', 'paragraphs') -------------------------------------------\n",
      "Getting data\n",
      "{'anger', 'surprise', 'trust', 'disgust', 'fear', 'sadness', 'joy'}\n",
      "{'anger', 'surprise', 'trust', 'shame', 'love', 'disgust', 'fear', 'noemo', 'sadness', 'guilt', 'joy'}\n",
      "matched Labels: {'anger', 'surprise', 'trust', 'disgust', 'fear', 'sadness', 'joy'}\n",
      "{'anger', 'surprise', 'trust', 'disgust', 'fear', 'sadness', 'joy'}\n",
      "{'anger', 'surprise', 'trust', 'shame', 'love', 'disgust', 'fear', 'noemo', 'sadness', 'guilt', 'joy'}\n",
      "matched Labels: {'anger', 'surprise', 'trust', 'disgust', 'fear', 'sadness', 'joy'}\n",
      "creating file for corpus similarity\n",
      "CosineSimilarity 0.7041962790590754\n",
      "{'anger': 0.8080828947767561, 'surprise': 0.8467354107933948, 'trust': 0.9991226994899142, 'disgust': 0.8637646809542504, 'fear': 0.7323774822550635, 'sadness': 0.7704929053155323, 'joy': 0.7371900588259063}\n",
      "file saved to  ssec_emotion-causeSimilarities.txt\n",
      "------------------------------ ('ssec', 'emoint', 'tweets', 'tweets') -------------------------------------------\n",
      "Getting data\n",
      "{'anger', 'surprise', 'trust', 'disgust', 'fear', 'sadness', 'joy'}\n",
      "{'anger', 'surprise', 'trust', 'shame', 'love', 'disgust', 'fear', 'noemo', 'sadness', 'guilt', 'joy'}\n",
      "matched Labels: {'anger', 'surprise', 'trust', 'disgust', 'fear', 'sadness', 'joy'}\n",
      "{'anger', 'surprise', 'trust', 'disgust', 'fear', 'sadness', 'joy'}\n",
      "{'anger', 'surprise', 'trust', 'shame', 'love', 'disgust', 'fear', 'noemo', 'sadness', 'guilt', 'joy'}\n",
      "matched Labels: {'anger', 'surprise', 'trust', 'disgust', 'fear', 'sadness', 'joy'}\n",
      "creating file for corpus similarity\n",
      "CosineSimilarity 0.7012395375889949\n",
      "{'anger': 0.7972996857213807, 'surprise': 0.8478189837371325, 'trust': 0.9988790580379272, 'disgust': 0.8647310660055152, 'fear': 0.7233529266792257, 'sadness': 0.7642683365674316, 'joy': 0.733181675826926}\n",
      "file saved to  ssec_emointSimilarities.txt\n",
      "------------------------------ ('ssec', 'dailydialog', 'tweets', 'conversations') -------------------------------------------\n",
      "Getting data\n",
      "{'anger', 'surprise', 'trust', 'disgust', 'fear', 'sadness', 'joy'}\n",
      "{'anger', 'surprise', 'trust', 'shame', 'love', 'disgust', 'fear', 'noemo', 'sadness', 'guilt', 'joy'}\n",
      "matched Labels: {'anger', 'surprise', 'trust', 'disgust', 'fear', 'sadness', 'joy'}\n",
      "{'anger', 'surprise', 'trust', 'disgust', 'fear', 'sadness', 'joy'}\n",
      "{'anger', 'surprise', 'trust', 'shame', 'love', 'disgust', 'fear', 'noemo', 'sadness', 'guilt', 'joy'}\n",
      "matched Labels: {'anger', 'surprise', 'trust', 'disgust', 'fear', 'sadness', 'joy'}\n",
      "creating file for corpus similarity\n",
      "CosineSimilarity 0.6978623392442822\n",
      "{'anger': 0.7968142845837164, 'surprise': 0.8460327264193168, 'trust': 0.9986598018689526, 'disgust': 0.8641702691129636, 'fear': 0.7238896414608814, 'sadness': 0.764556749134237, 'joy': 0.7315352434875745}\n",
      "file saved to  ssec_dailydialogSimilarities.txt\n",
      "------------------------------ ('ssec', 'crowdflower', 'tweets', 'tweets') -------------------------------------------\n",
      "Getting data\n",
      "{'anger', 'surprise', 'trust', 'disgust', 'fear', 'sadness', 'joy'}\n",
      "{'anger', 'surprise', 'trust', 'shame', 'love', 'disgust', 'fear', 'noemo', 'sadness', 'guilt', 'joy'}\n",
      "matched Labels: {'anger', 'surprise', 'trust', 'disgust', 'fear', 'sadness', 'joy'}\n",
      "{'anger', 'surprise', 'trust', 'disgust', 'fear', 'sadness', 'joy'}\n",
      "{'anger', 'surprise', 'trust', 'shame', 'love', 'disgust', 'fear', 'noemo', 'sadness', 'guilt', 'joy'}\n",
      "matched Labels: {'anger', 'surprise', 'trust', 'disgust', 'fear', 'sadness', 'joy'}\n",
      "creating file for corpus similarity\n",
      "CosineSimilarity 0.6846521972795995\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'anger': 0.7888190079571392, 'surprise': 0.8283091705098922, 'trust': 0.9984618567238803, 'disgust': 0.8623413227532574, 'fear': 0.6970371966192173, 'sadness': 0.7506316042606068, 'joy': 0.71263927126315}\n",
      "file saved to  ssec_crowdflowerSimilarities.txt\n",
      "------------------------------ ('ssec', 'affectivetext', 'tweets', 'headlines') -------------------------------------------\n",
      "Getting data\n",
      "{'anger', 'surprise', 'trust', 'disgust', 'fear', 'sadness', 'joy'}\n",
      "{'anger', 'surprise', 'trust', 'shame', 'love', 'disgust', 'fear', 'noemo', 'sadness', 'guilt', 'joy'}\n",
      "matched Labels: {'anger', 'surprise', 'trust', 'disgust', 'fear', 'sadness', 'joy'}\n",
      "{'anger', 'surprise', 'trust', 'disgust', 'fear', 'sadness', 'joy'}\n",
      "{'anger', 'surprise', 'trust', 'shame', 'love', 'disgust', 'fear', 'noemo', 'sadness', 'guilt', 'joy'}\n",
      "matched Labels: {'anger', 'surprise', 'trust', 'disgust', 'fear', 'sadness', 'joy'}\n",
      "creating file for corpus similarity\n",
      "CosineSimilarity 0.6757430597349495\n",
      "{'anger': 0.7891071400378197, 'surprise': 0.8288401253002473, 'trust': 0.9982821675524235, 'disgust': 0.8626912394734155, 'fear': 0.6973844244590054, 'sadness': 0.751055313895824, 'joy': 0.7129092370790057}\n",
      "file saved to  ssec_affectivetextSimilarities.txt\n",
      "------------------------------ ('grounded_emotions', 'tec', 'tweets', 'tweets') -------------------------------------------\n",
      "Getting data\n",
      "{'anger', 'surprise', 'trust', 'disgust', 'fear', 'sadness', 'joy'}\n",
      "{'anger', 'surprise', 'trust', 'shame', 'love', 'disgust', 'fear', 'noemo', 'sadness', 'guilt', 'joy'}\n",
      "matched Labels: {'anger', 'surprise', 'trust', 'disgust', 'fear', 'sadness', 'joy'}\n",
      "{'anger', 'surprise', 'trust', 'disgust', 'fear', 'sadness', 'joy'}\n",
      "{'anger', 'surprise', 'trust', 'shame', 'love', 'disgust', 'fear', 'noemo', 'sadness', 'guilt', 'joy'}\n",
      "matched Labels: {'anger', 'surprise', 'trust', 'disgust', 'fear', 'sadness', 'joy'}\n",
      "creating file for corpus similarity\n",
      "CosineSimilarity 0.7169297036130563\n",
      "{'anger': 0.8012155490062808, 'surprise': 0.8589462374668445, 'trust': 0.9982821675524235, 'disgust': 0.8722388132449453, 'fear': 0.7184017247117953, 'sadness': 0.8205198213552682, 'joy': 0.789712470366829}\n",
      "file saved to  grounded_emotions_tecSimilarities.txt\n",
      "------------------------------ ('grounded_emotions', 'tales-emotion', 'tweets', 'tales') -------------------------------------------\n",
      "Getting data\n",
      "{'anger', 'surprise', 'trust', 'disgust', 'fear', 'sadness', 'joy'}\n",
      "{'anger', 'surprise', 'trust', 'shame', 'love', 'disgust', 'fear', 'noemo', 'sadness', 'guilt', 'joy'}\n",
      "matched Labels: {'anger', 'surprise', 'trust', 'disgust', 'fear', 'sadness', 'joy'}\n",
      "{'anger', 'surprise', 'trust', 'disgust', 'fear', 'sadness', 'joy'}\n",
      "{'anger', 'surprise', 'trust', 'shame', 'love', 'disgust', 'fear', 'noemo', 'sadness', 'guilt', 'joy'}\n",
      "matched Labels: {'anger', 'surprise', 'trust', 'disgust', 'fear', 'sadness', 'joy'}\n",
      "creating file for corpus similarity\n",
      "CosineSimilarity 0.73338349005831\n",
      "{'anger': 0.8003636284044108, 'surprise': 0.8576256815460928, 'trust': 0.9982821675524235, 'disgust': 0.8712633618458971, 'fear': 0.7180608985582436, 'sadness': 0.8252254006682762, 'joy': 0.7945840211017863}\n",
      "file saved to  grounded_emotions_tales-emotionSimilarities.txt\n",
      "------------------------------ ('grounded_emotions', 'ssec', 'tweets', 'tweets') -------------------------------------------\n",
      "Getting data\n",
      "{'anger', 'surprise', 'trust', 'disgust', 'fear', 'sadness', 'joy'}\n",
      "{'anger', 'surprise', 'trust', 'shame', 'love', 'disgust', 'fear', 'noemo', 'sadness', 'guilt', 'joy'}\n",
      "matched Labels: {'anger', 'surprise', 'trust', 'disgust', 'fear', 'sadness', 'joy'}\n",
      "{'anger', 'surprise', 'trust', 'disgust', 'fear', 'sadness', 'joy'}\n",
      "{'anger', 'surprise', 'trust', 'shame', 'love', 'disgust', 'fear', 'noemo', 'sadness', 'guilt', 'joy'}\n",
      "matched Labels: {'anger', 'surprise', 'trust', 'disgust', 'fear', 'sadness', 'joy'}\n",
      "creating file for corpus similarity\n",
      "CosineSimilarity 0.737105547934393\n",
      "{'anger': 0.8128222104797834, 'surprise': 0.8610551721773149, 'trust': 0.9992109372442328, 'disgust': 0.8825403173559123, 'fear': 0.7269559094441636, 'sadness': 0.8342611989245926, 'joy': 0.8010225673242738}\n",
      "file saved to  grounded_emotions_ssecSimilarities.txt\n",
      "------------------------------ ('grounded_emotions', 'isear', 'tweets', 'descriptions') -------------------------------------------\n",
      "Getting data\n",
      "{'anger', 'surprise', 'trust', 'disgust', 'fear', 'sadness', 'joy'}\n",
      "{'anger', 'surprise', 'trust', 'shame', 'love', 'disgust', 'fear', 'noemo', 'sadness', 'guilt', 'joy'}\n",
      "matched Labels: {'anger', 'surprise', 'trust', 'disgust', 'fear', 'sadness', 'joy'}\n",
      "{'anger', 'surprise', 'trust', 'disgust', 'fear', 'sadness', 'joy'}\n",
      "{'anger', 'surprise', 'trust', 'shame', 'love', 'disgust', 'fear', 'noemo', 'sadness', 'guilt', 'joy'}\n",
      "matched Labels: {'anger', 'surprise', 'trust', 'disgust', 'fear', 'sadness', 'joy'}\n",
      "creating file for corpus similarity\n",
      "CosineSimilarity 0.739388777186134\n",
      "{'anger': 0.8110455066627847, 'surprise': 0.8610551721773149, 'trust': 0.9992109372442328, 'disgust': 0.8776026758367425, 'fear': 0.7261000570668029, 'sadness': 0.834640136605461, 'joy': 0.8018480695821156}\n",
      "file saved to  grounded_emotions_isearSimilarities.txt\n",
      "------------------------------ ('grounded_emotions', 'emotion-cause', 'tweets', 'paragraphs') -------------------------------------------\n",
      "Getting data\n",
      "{'anger', 'surprise', 'trust', 'disgust', 'fear', 'sadness', 'joy'}\n",
      "{'anger', 'surprise', 'trust', 'shame', 'love', 'disgust', 'fear', 'noemo', 'sadness', 'guilt', 'joy'}\n",
      "matched Labels: {'anger', 'surprise', 'trust', 'disgust', 'fear', 'sadness', 'joy'}\n",
      "{'anger', 'surprise', 'trust', 'disgust', 'fear', 'sadness', 'joy'}\n",
      "{'anger', 'surprise', 'trust', 'shame', 'love', 'disgust', 'fear', 'noemo', 'sadness', 'guilt', 'joy'}\n",
      "matched Labels: {'anger', 'surprise', 'trust', 'disgust', 'fear', 'sadness', 'joy'}\n",
      "creating file for corpus similarity\n",
      "CosineSimilarity 0.7392995631721556\n",
      "{'anger': 0.8087818350613083, 'surprise': 0.8596339731775847, 'trust': 0.9992109372442328, 'disgust': 0.8762049360050296, 'fear': 0.7249755895448106, 'sadness': 0.8337616851411627, 'joy': 0.8017504077804629}\n",
      "file saved to  grounded_emotions_emotion-causeSimilarities.txt\n",
      "------------------------------ ('grounded_emotions', 'emoint', 'tweets', 'tweets') -------------------------------------------\n",
      "Getting data\n",
      "{'anger', 'surprise', 'trust', 'disgust', 'fear', 'sadness', 'joy'}\n",
      "{'anger', 'surprise', 'trust', 'shame', 'love', 'disgust', 'fear', 'noemo', 'sadness', 'guilt', 'joy'}\n",
      "matched Labels: {'anger', 'surprise', 'trust', 'disgust', 'fear', 'sadness', 'joy'}\n",
      "{'anger', 'surprise', 'trust', 'disgust', 'fear', 'sadness', 'joy'}\n",
      "{'anger', 'surprise', 'trust', 'shame', 'love', 'disgust', 'fear', 'noemo', 'sadness', 'guilt', 'joy'}\n",
      "matched Labels: {'anger', 'surprise', 'trust', 'disgust', 'fear', 'sadness', 'joy'}\n",
      "creating file for corpus similarity\n",
      "CosineSimilarity 0.7376157635030671\n",
      "{'anger': 0.8021519847337535, 'surprise': 0.8596339731775847, 'trust': 0.9992109372442328, 'disgust': 0.8762049360050296, 'fear': 0.7198140064279844, 'sadness': 0.8295594657242434, 'joy': 0.7993138084199243}\n",
      "file saved to  grounded_emotions_emointSimilarities.txt\n",
      "------------------------------ ('grounded_emotions', 'dailydialog', 'tweets', 'conversations') -------------------------------------------\n",
      "Getting data\n",
      "{'anger', 'surprise', 'trust', 'disgust', 'fear', 'sadness', 'joy'}\n",
      "{'anger', 'surprise', 'trust', 'shame', 'love', 'disgust', 'fear', 'noemo', 'sadness', 'guilt', 'joy'}\n",
      "matched Labels: {'anger', 'surprise', 'trust', 'disgust', 'fear', 'sadness', 'joy'}\n",
      "{'anger', 'surprise', 'trust', 'disgust', 'fear', 'sadness', 'joy'}\n",
      "{'anger', 'surprise', 'trust', 'shame', 'love', 'disgust', 'fear', 'noemo', 'sadness', 'guilt', 'joy'}\n",
      "matched Labels: {'anger', 'surprise', 'trust', 'disgust', 'fear', 'sadness', 'joy'}\n",
      "creating file for corpus similarity\n",
      "CosineSimilarity 0.7354753313141431\n",
      "{'anger': 0.8015172795667558, 'surprise': 0.8582105929769587, 'trust': 0.9992109372442328, 'disgust': 0.8754472125361681, 'fear': 0.7197469365600154, 'sadness': 0.8294715191483666, 'joy': 0.7979705023534626}\n",
      "file saved to  grounded_emotions_dailydialogSimilarities.txt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------ ('grounded_emotions', 'crowdflower', 'tweets', 'tweets') -------------------------------------------\n",
      "Getting data\n",
      "{'anger', 'surprise', 'trust', 'disgust', 'fear', 'sadness', 'joy'}\n",
      "{'anger', 'surprise', 'trust', 'shame', 'love', 'disgust', 'fear', 'noemo', 'sadness', 'guilt', 'joy'}\n",
      "matched Labels: {'anger', 'surprise', 'trust', 'disgust', 'fear', 'sadness', 'joy'}\n",
      "{'anger', 'surprise', 'trust', 'disgust', 'fear', 'sadness', 'joy'}\n",
      "{'anger', 'surprise', 'trust', 'shame', 'love', 'disgust', 'fear', 'noemo', 'sadness', 'guilt', 'joy'}\n",
      "matched Labels: {'anger', 'surprise', 'trust', 'disgust', 'fear', 'sadness', 'joy'}\n",
      "creating file for corpus similarity\n",
      "CosineSimilarity 0.7274802793669567\n",
      "{'anger': 0.7965467665284212, 'surprise': 0.8478462714383751, 'trust': 0.9992109372442328, 'disgust': 0.8740437964092731, 'fear': 0.7044793929382163, 'sadness': 0.8198515985961012, 'joy': 0.7853285374225585}\n",
      "file saved to  grounded_emotions_crowdflowerSimilarities.txt\n",
      "------------------------------ ('grounded_emotions', 'affectivetext', 'tweets', 'headlines') -------------------------------------------\n",
      "Getting data\n",
      "{'anger', 'surprise', 'trust', 'disgust', 'fear', 'sadness', 'joy'}\n",
      "{'anger', 'surprise', 'trust', 'shame', 'love', 'disgust', 'fear', 'noemo', 'sadness', 'guilt', 'joy'}\n",
      "matched Labels: {'anger', 'surprise', 'trust', 'disgust', 'fear', 'sadness', 'joy'}\n",
      "{'anger', 'surprise', 'trust', 'disgust', 'fear', 'sadness', 'joy'}\n",
      "{'anger', 'surprise', 'trust', 'shame', 'love', 'disgust', 'fear', 'noemo', 'sadness', 'guilt', 'joy'}\n",
      "matched Labels: {'anger', 'surprise', 'trust', 'disgust', 'fear', 'sadness', 'joy'}\n",
      "creating file for corpus similarity\n",
      "CosineSimilarity 0.7214242282546135\n",
      "{'anger': 0.7965467665284212, 'surprise': 0.8478462714383751, 'trust': 0.9992109372442328, 'disgust': 0.8740437964092731, 'fear': 0.7044793929382163, 'sadness': 0.8199643115292489, 'joy': 0.785467745343351}\n",
      "file saved to  grounded_emotions_affectivetextSimilarities.txt\n",
      "------------------------------ ('emoint', 'tec', 'tweets', 'tweets') -------------------------------------------\n",
      "Getting data\n",
      "{'anger', 'surprise', 'trust', 'disgust', 'fear', 'sadness', 'joy'}\n",
      "{'anger', 'surprise', 'trust', 'shame', 'love', 'disgust', 'fear', 'noemo', 'sadness', 'guilt', 'joy'}\n",
      "matched Labels: {'anger', 'surprise', 'trust', 'disgust', 'fear', 'sadness', 'joy'}\n",
      "{'anger', 'surprise', 'trust', 'disgust', 'fear', 'sadness', 'joy'}\n",
      "{'anger', 'surprise', 'trust', 'shame', 'love', 'disgust', 'fear', 'noemo', 'sadness', 'guilt', 'joy'}\n",
      "matched Labels: {'anger', 'surprise', 'trust', 'disgust', 'fear', 'sadness', 'joy'}\n",
      "creating file for corpus similarity\n",
      "CosineSimilarity 0.7626868529131502\n",
      "{'anger': 0.8661207443028287, 'surprise': 0.8625421330579052, 'trust': 0.9992109372442328, 'disgust': 0.8787862473167638, 'fear': 0.7846364305248207, 'sadness': 0.8660566368979368, 'joy': 0.8231266156742969}\n",
      "file saved to  emoint_tecSimilarities.txt\n",
      "------------------------------ ('emoint', 'tales-emotion', 'tweets', 'tales') -------------------------------------------\n",
      "Getting data\n",
      "{'anger', 'surprise', 'trust', 'disgust', 'fear', 'sadness', 'joy'}\n",
      "{'anger', 'surprise', 'trust', 'shame', 'love', 'disgust', 'fear', 'noemo', 'sadness', 'guilt', 'joy'}\n",
      "matched Labels: {'anger', 'surprise', 'trust', 'disgust', 'fear', 'sadness', 'joy'}\n",
      "{'anger', 'surprise', 'trust', 'disgust', 'fear', 'sadness', 'joy'}\n",
      "{'anger', 'surprise', 'trust', 'shame', 'love', 'disgust', 'fear', 'noemo', 'sadness', 'guilt', 'joy'}\n",
      "matched Labels: {'anger', 'surprise', 'trust', 'disgust', 'fear', 'sadness', 'joy'}\n",
      "creating file for corpus similarity\n",
      "CosineSimilarity 0.7755207663001586\n",
      "{'anger': 0.8712566429148434, 'surprise': 0.8615324409614685, 'trust': 0.9992109372442328, 'disgust': 0.8780210271359123, 'fear': 0.79057116664861, 'sadness': 0.8694480447541801, 'joy': 0.825386498239128}\n",
      "file saved to  emoint_tales-emotionSimilarities.txt\n",
      "------------------------------ ('emoint', 'ssec', 'tweets', 'tweets') -------------------------------------------\n",
      "Getting data\n",
      "{'anger', 'surprise', 'trust', 'disgust', 'fear', 'sadness', 'joy'}\n",
      "{'anger', 'surprise', 'trust', 'shame', 'love', 'disgust', 'fear', 'noemo', 'sadness', 'guilt', 'joy'}\n",
      "matched Labels: {'anger', 'surprise', 'trust', 'disgust', 'fear', 'sadness', 'joy'}\n",
      "{'anger', 'surprise', 'trust', 'disgust', 'fear', 'sadness', 'joy'}\n",
      "{'anger', 'surprise', 'trust', 'shame', 'love', 'disgust', 'fear', 'noemo', 'sadness', 'guilt', 'joy'}\n",
      "matched Labels: {'anger', 'surprise', 'trust', 'disgust', 'fear', 'sadness', 'joy'}\n",
      "creating file for corpus similarity\n",
      "CosineSimilarity 0.7787176650297116\n",
      "{'anger': 0.879195838633032, 'surprise': 0.8637273492193988, 'trust': 0.9996042593756155, 'disgust': 0.885149723585695, 'fear': 0.7974902562161607, 'sadness': 0.8742659575646575, 'joy': 0.828735088225433}\n",
      "file saved to  emoint_ssecSimilarities.txt\n",
      "------------------------------ ('emoint', 'isear', 'tweets', 'descriptions') -------------------------------------------\n",
      "Getting data\n",
      "{'anger', 'surprise', 'trust', 'disgust', 'fear', 'sadness', 'joy'}\n",
      "{'anger', 'surprise', 'trust', 'shame', 'love', 'disgust', 'fear', 'noemo', 'sadness', 'guilt', 'joy'}\n",
      "matched Labels: {'anger', 'surprise', 'trust', 'disgust', 'fear', 'sadness', 'joy'}\n",
      "{'anger', 'surprise', 'trust', 'disgust', 'fear', 'sadness', 'joy'}\n",
      "{'anger', 'surprise', 'trust', 'shame', 'love', 'disgust', 'fear', 'noemo', 'sadness', 'guilt', 'joy'}\n",
      "matched Labels: {'anger', 'surprise', 'trust', 'disgust', 'fear', 'sadness', 'joy'}\n",
      "creating file for corpus similarity\n",
      "CosineSimilarity 0.7805127711228902\n",
      "{'anger': 0.8787561524220538, 'surprise': 0.8637273492193988, 'trust': 0.9996042593756155, 'disgust': 0.881443579095609, 'fear': 0.7979909650258766, 'sadness': 0.8744632904322922, 'joy': 0.8290184432098}\n",
      "file saved to  emoint_isearSimilarities.txt\n",
      "------------------------------ ('emoint', 'grounded_emotions', 'tweets', 'tweets') -------------------------------------------\n",
      "Getting data\n",
      "{'anger', 'surprise', 'trust', 'disgust', 'fear', 'sadness', 'joy'}\n",
      "{'anger', 'surprise', 'trust', 'shame', 'love', 'disgust', 'fear', 'noemo', 'sadness', 'guilt', 'joy'}\n",
      "matched Labels: {'anger', 'surprise', 'trust', 'disgust', 'fear', 'sadness', 'joy'}\n",
      "{'anger', 'surprise', 'trust', 'disgust', 'fear', 'sadness', 'joy'}\n",
      "{'anger', 'surprise', 'trust', 'shame', 'love', 'disgust', 'fear', 'noemo', 'sadness', 'guilt', 'joy'}\n",
      "matched Labels: {'anger', 'surprise', 'trust', 'disgust', 'fear', 'sadness', 'joy'}\n",
      "creating file for corpus similarity\n",
      "CosineSimilarity 0.7817595245564045\n",
      "{'anger': 0.8793193947796055, 'surprise': 0.8637273492193988, 'trust': 0.9996042593756155, 'disgust': 0.881443579095609, 'fear': 0.7987152372691672, 'sadness': 0.8766738167327734, 'joy': 0.8316543392051358}\n",
      "file saved to  emoint_grounded_emotionsSimilarities.txt\n",
      "------------------------------ ('emoint', 'emotion-cause', 'tweets', 'paragraphs') -------------------------------------------\n",
      "Getting data\n",
      "{'anger', 'surprise', 'trust', 'disgust', 'fear', 'sadness', 'joy'}\n",
      "{'anger', 'surprise', 'trust', 'shame', 'love', 'disgust', 'fear', 'noemo', 'sadness', 'guilt', 'joy'}\n",
      "matched Labels: {'anger', 'surprise', 'trust', 'disgust', 'fear', 'sadness', 'joy'}\n",
      "{'anger', 'surprise', 'trust', 'disgust', 'fear', 'sadness', 'joy'}\n",
      "{'anger', 'surprise', 'trust', 'shame', 'love', 'disgust', 'fear', 'noemo', 'sadness', 'guilt', 'joy'}\n",
      "matched Labels: {'anger', 'surprise', 'trust', 'disgust', 'fear', 'sadness', 'joy'}\n",
      "creating file for corpus similarity\n",
      "CosineSimilarity 0.7825841937066685\n",
      "{'anger': 0.8779584075602703, 'surprise': 0.8627706105039643, 'trust': 0.9996042593756155, 'disgust': 0.8804613522982687, 'fear': 0.7983277731969657, 'sadness': 0.8758414307356481, 'joy': 0.8312659559097074}\n",
      "file saved to  emoint_emotion-causeSimilarities.txt\n",
      "------------------------------ ('emoint', 'dailydialog', 'tweets', 'conversations') -------------------------------------------\n",
      "Getting data\n",
      "{'anger', 'surprise', 'trust', 'disgust', 'fear', 'sadness', 'joy'}\n",
      "{'anger', 'surprise', 'trust', 'shame', 'love', 'disgust', 'fear', 'noemo', 'sadness', 'guilt', 'joy'}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "matched Labels: {'anger', 'surprise', 'trust', 'disgust', 'fear', 'sadness', 'joy'}\n",
      "{'anger', 'surprise', 'trust', 'disgust', 'fear', 'sadness', 'joy'}\n",
      "{'anger', 'surprise', 'trust', 'shame', 'love', 'disgust', 'fear', 'noemo', 'sadness', 'guilt', 'joy'}\n",
      "matched Labels: {'anger', 'surprise', 'trust', 'disgust', 'fear', 'sadness', 'joy'}\n",
      "creating file for corpus similarity\n",
      "CosineSimilarity 0.7818541173870399\n",
      "{'anger': 0.8775650469732952, 'surprise': 0.8618189343665197, 'trust': 0.9996042593756155, 'disgust': 0.8799270018747395, 'fear': 0.7985546528726704, 'sadness': 0.875715991644953, 'joy': 0.8301310650112523}\n",
      "file saved to  emoint_dailydialogSimilarities.txt\n",
      "------------------------------ ('emoint', 'crowdflower', 'tweets', 'tweets') -------------------------------------------\n",
      "Getting data\n",
      "{'anger', 'surprise', 'trust', 'disgust', 'fear', 'sadness', 'joy'}\n",
      "{'anger', 'surprise', 'trust', 'shame', 'love', 'disgust', 'fear', 'noemo', 'sadness', 'guilt', 'joy'}\n",
      "matched Labels: {'anger', 'surprise', 'trust', 'disgust', 'fear', 'sadness', 'joy'}\n",
      "{'anger', 'surprise', 'trust', 'disgust', 'fear', 'sadness', 'joy'}\n",
      "{'anger', 'surprise', 'trust', 'shame', 'love', 'disgust', 'fear', 'noemo', 'sadness', 'guilt', 'joy'}\n",
      "matched Labels: {'anger', 'surprise', 'trust', 'disgust', 'fear', 'sadness', 'joy'}\n",
      "creating file for corpus similarity\n",
      "CosineSimilarity 0.7759228565945052\n",
      "{'anger': 0.8736708136628016, 'surprise': 0.8547374786372236, 'trust': 0.9996042593756155, 'disgust': 0.8789359226917426, 'fear': 0.7866389810100197, 'sadness': 0.8684556830200972, 'joy': 0.8207991670462608}\n",
      "file saved to  emoint_crowdflowerSimilarities.txt\n",
      "------------------------------ ('emoint', 'affectivetext', 'tweets', 'headlines') -------------------------------------------\n",
      "Getting data\n",
      "{'anger', 'surprise', 'trust', 'disgust', 'fear', 'sadness', 'joy'}\n",
      "{'anger', 'surprise', 'trust', 'shame', 'love', 'disgust', 'fear', 'noemo', 'sadness', 'guilt', 'joy'}\n",
      "matched Labels: {'anger', 'surprise', 'trust', 'disgust', 'fear', 'sadness', 'joy'}\n",
      "{'anger', 'surprise', 'trust', 'disgust', 'fear', 'sadness', 'joy'}\n",
      "{'anger', 'surprise', 'trust', 'shame', 'love', 'disgust', 'fear', 'noemo', 'sadness', 'guilt', 'joy'}\n",
      "matched Labels: {'anger', 'surprise', 'trust', 'disgust', 'fear', 'sadness', 'joy'}\n",
      "creating file for corpus similarity\n",
      "CosineSimilarity 0.7712280965105774\n",
      "{'anger': 0.8736800431761711, 'surprise': 0.8547374786372236, 'trust': 0.9996042593756155, 'disgust': 0.8789359226917426, 'fear': 0.7867381724229381, 'sadness': 0.8684955876137334, 'joy': 0.820835045843929}\n",
      "file saved to  emoint_affectivetextSimilarities.txt\n",
      "------------------------------ ('crowdflower', 'tec', 'tweets', 'tweets') -------------------------------------------\n",
      "Getting data\n",
      "{'anger', 'surprise', 'trust', 'love', 'disgust', 'fear', 'noemo', 'sadness', 'joy'}\n",
      "{'anger', 'surprise', 'trust', 'shame', 'love', 'disgust', 'fear', 'noemo', 'sadness', 'guilt', 'joy'}\n",
      "matched Labels: {'anger', 'surprise', 'trust', 'love', 'disgust', 'fear', 'noemo', 'sadness', 'joy'}\n",
      "{'anger', 'surprise', 'trust', 'love', 'disgust', 'fear', 'noemo', 'sadness', 'joy'}\n",
      "{'anger', 'surprise', 'trust', 'shame', 'love', 'disgust', 'fear', 'noemo', 'sadness', 'guilt', 'joy'}\n",
      "matched Labels: {'anger', 'surprise', 'trust', 'love', 'disgust', 'fear', 'noemo', 'sadness', 'joy'}\n",
      "creating file for corpus similarity\n",
      "CosineSimilarity 0.8897478741209086\n",
      "{'anger': 0.9167918320547745, 'surprise': 0.9307969183188279, 'trust': 0.9996042593756155, 'love': 0.9971305517217354, 'disgust': 0.8924562014106824, 'fear': 0.9382809946304662, 'noemo': 0.7396433244889732, 'sadness': 0.9431221315246664, 'joy': 0.9299195903742805}\n",
      "file saved to  crowdflower_tecSimilarities.txt\n",
      "------------------------------ ('crowdflower', 'tales-emotion', 'tweets', 'tales') -------------------------------------------\n",
      "Getting data\n",
      "{'anger', 'surprise', 'trust', 'love', 'disgust', 'fear', 'noemo', 'sadness', 'joy'}\n",
      "{'anger', 'surprise', 'trust', 'shame', 'love', 'disgust', 'fear', 'noemo', 'sadness', 'guilt', 'joy'}\n",
      "matched Labels: {'anger', 'surprise', 'trust', 'love', 'disgust', 'fear', 'noemo', 'sadness', 'joy'}\n",
      "{'anger', 'surprise', 'trust', 'love', 'disgust', 'fear', 'noemo', 'sadness', 'joy'}\n",
      "{'anger', 'surprise', 'trust', 'shame', 'love', 'disgust', 'fear', 'noemo', 'sadness', 'guilt', 'joy'}\n",
      "matched Labels: {'anger', 'surprise', 'trust', 'love', 'disgust', 'fear', 'noemo', 'sadness', 'joy'}\n",
      "creating file for corpus similarity\n",
      "CosineSimilarity 0.9161885013326818\n",
      "{'anger': 0.9204434236375605, 'surprise': 0.9372467947244139, 'trust': 0.9996042593756155, 'love': 0.9994895348472392, 'disgust': 0.8930106100492277, 'fear': 0.9504002904152298, 'noemo': 0.7381194773770509, 'sadness': 0.9498177824964787, 'joy': 0.9391563060014887}\n",
      "file saved to  crowdflower_tales-emotionSimilarities.txt\n",
      "------------------------------ ('crowdflower', 'ssec', 'tweets', 'tweets') -------------------------------------------\n",
      "Getting data\n",
      "{'anger', 'surprise', 'trust', 'love', 'disgust', 'fear', 'noemo', 'sadness', 'joy'}\n",
      "{'anger', 'surprise', 'trust', 'shame', 'love', 'disgust', 'fear', 'noemo', 'sadness', 'guilt', 'joy'}\n",
      "matched Labels: {'anger', 'surprise', 'trust', 'love', 'disgust', 'fear', 'noemo', 'sadness', 'joy'}\n",
      "{'anger', 'surprise', 'trust', 'love', 'disgust', 'fear', 'noemo', 'sadness', 'joy'}\n",
      "{'anger', 'surprise', 'trust', 'shame', 'love', 'disgust', 'fear', 'noemo', 'sadness', 'guilt', 'joy'}\n",
      "matched Labels: {'anger', 'surprise', 'trust', 'love', 'disgust', 'fear', 'noemo', 'sadness', 'joy'}\n",
      "creating file for corpus similarity\n",
      "CosineSimilarity 0.9228217751815407\n",
      "{'anger': 0.9245846379259949, 'surprise': 0.9410595437661922, 'trust': 0.9997999732552842, 'love': 0.9999262653561406, 'disgust': 0.8981939062428425, 'fear': 0.9560928486416169, 'noemo': 0.737627554538462, 'sadness': 0.953642621040735, 'joy': 0.9436394361128194}\n",
      "file saved to  crowdflower_ssecSimilarities.txt\n",
      "------------------------------ ('crowdflower', 'isear', 'tweets', 'descriptions') -------------------------------------------\n",
      "Getting data\n",
      "{'anger', 'surprise', 'trust', 'love', 'disgust', 'fear', 'noemo', 'sadness', 'joy'}\n",
      "{'anger', 'surprise', 'trust', 'shame', 'love', 'disgust', 'fear', 'noemo', 'sadness', 'guilt', 'joy'}\n",
      "matched Labels: {'anger', 'surprise', 'trust', 'love', 'disgust', 'fear', 'noemo', 'sadness', 'joy'}\n",
      "{'anger', 'surprise', 'trust', 'love', 'disgust', 'fear', 'noemo', 'sadness', 'joy'}\n",
      "{'anger', 'surprise', 'trust', 'shame', 'love', 'disgust', 'fear', 'noemo', 'sadness', 'guilt', 'joy'}\n",
      "matched Labels: {'anger', 'surprise', 'trust', 'love', 'disgust', 'fear', 'noemo', 'sadness', 'joy'}\n",
      "creating file for corpus similarity\n",
      "CosineSimilarity 0.9257522062683498\n",
      "{'anger': 0.9241508988136647, 'surprise': 0.9427378709358016, 'trust': 0.9997999732552842, 'love': 1.0000000000001408, 'disgust': 0.8954260067173385, 'fear': 0.9575785624966514, 'noemo': 0.73718698295716, 'sadness': 0.9545228058634078, 'joy': 0.9452319423502096}\n",
      "file saved to  crowdflower_isearSimilarities.txt\n",
      "------------------------------ ('crowdflower', 'grounded_emotions', 'tweets', 'tweets') -------------------------------------------\n",
      "Getting data\n",
      "{'anger', 'surprise', 'trust', 'love', 'disgust', 'fear', 'noemo', 'sadness', 'joy'}\n",
      "{'anger', 'surprise', 'trust', 'shame', 'love', 'disgust', 'fear', 'noemo', 'sadness', 'guilt', 'joy'}\n",
      "matched Labels: {'anger', 'surprise', 'trust', 'love', 'disgust', 'fear', 'noemo', 'sadness', 'joy'}\n",
      "{'anger', 'surprise', 'trust', 'love', 'disgust', 'fear', 'noemo', 'sadness', 'joy'}\n",
      "{'anger', 'surprise', 'trust', 'shame', 'love', 'disgust', 'fear', 'noemo', 'sadness', 'guilt', 'joy'}\n",
      "matched Labels: {'anger', 'surprise', 'trust', 'love', 'disgust', 'fear', 'noemo', 'sadness', 'joy'}\n",
      "creating file for corpus similarity\n",
      "CosineSimilarity 0.9272718209345384\n",
      "{'anger': 0.9246409142688232, 'surprise': 0.9437752614354334, 'trust': 0.9997999732552842, 'love': 0.9999637676729823, 'disgust': 0.8955591050152916, 'fear': 0.9588922271042244, 'noemo': 0.7368153747558727, 'sadness': 0.9557907268999493, 'joy': 0.9468678521923519}\n",
      "file saved to  crowdflower_grounded_emotionsSimilarities.txt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------ ('crowdflower', 'emotion-cause', 'tweets', 'paragraphs') -------------------------------------------\n",
      "Getting data\n",
      "{'anger', 'surprise', 'trust', 'love', 'disgust', 'fear', 'noemo', 'sadness', 'joy'}\n",
      "{'anger', 'surprise', 'trust', 'shame', 'love', 'disgust', 'fear', 'noemo', 'sadness', 'guilt', 'joy'}\n",
      "matched Labels: {'anger', 'surprise', 'trust', 'love', 'disgust', 'fear', 'noemo', 'sadness', 'joy'}\n",
      "{'anger', 'surprise', 'trust', 'love', 'disgust', 'fear', 'noemo', 'sadness', 'joy'}\n",
      "{'anger', 'surprise', 'trust', 'shame', 'love', 'disgust', 'fear', 'noemo', 'sadness', 'guilt', 'joy'}\n",
      "matched Labels: {'anger', 'surprise', 'trust', 'love', 'disgust', 'fear', 'noemo', 'sadness', 'joy'}\n",
      "creating file for corpus similarity\n",
      "CosineSimilarity 0.928070723206218\n",
      "{'anger': 0.9235721716828474, 'surprise': 0.9436728670640441, 'trust': 0.9997999732552842, 'love': 0.9998882016677906, 'disgust': 0.8948712030963768, 'fear': 0.9588458250848761, 'noemo': 0.7364999196475945, 'sadness': 0.9553372051079544, 'joy': 0.946958189196514}\n",
      "file saved to  crowdflower_emotion-causeSimilarities.txt\n",
      "------------------------------ ('crowdflower', 'emoint', 'tweets', 'tweets') -------------------------------------------\n",
      "Getting data\n",
      "{'anger', 'surprise', 'trust', 'love', 'disgust', 'fear', 'noemo', 'sadness', 'joy'}\n",
      "{'anger', 'surprise', 'trust', 'shame', 'love', 'disgust', 'fear', 'noemo', 'sadness', 'guilt', 'joy'}\n",
      "matched Labels: {'anger', 'surprise', 'trust', 'love', 'disgust', 'fear', 'noemo', 'sadness', 'joy'}\n",
      "{'anger', 'surprise', 'trust', 'love', 'disgust', 'fear', 'noemo', 'sadness', 'joy'}\n",
      "{'anger', 'surprise', 'trust', 'shame', 'love', 'disgust', 'fear', 'noemo', 'sadness', 'guilt', 'joy'}\n",
      "matched Labels: {'anger', 'surprise', 'trust', 'love', 'disgust', 'fear', 'noemo', 'sadness', 'joy'}\n",
      "creating file for corpus similarity\n",
      "CosineSimilarity 0.9288151625225204\n",
      "{'anger': 0.9254096196424332, 'surprise': 0.9441397578206956, 'trust': 0.9997999732552842, 'love': 0.9997985413956972, 'disgust': 0.8949133875108185, 'fear': 0.9601802895101471, 'noemo': 0.736228116643706, 'sadness': 0.9562725314709568, 'joy': 0.9478269045195902}\n",
      "file saved to  crowdflower_emointSimilarities.txt\n",
      "------------------------------ ('crowdflower', 'dailydialog', 'tweets', 'conversations') -------------------------------------------\n",
      "Getting data\n",
      "{'anger', 'surprise', 'trust', 'love', 'disgust', 'fear', 'noemo', 'sadness', 'joy'}\n",
      "{'anger', 'surprise', 'trust', 'shame', 'love', 'disgust', 'fear', 'noemo', 'sadness', 'guilt', 'joy'}\n",
      "matched Labels: {'anger', 'surprise', 'trust', 'love', 'disgust', 'fear', 'noemo', 'sadness', 'joy'}\n",
      "{'anger', 'surprise', 'trust', 'love', 'disgust', 'fear', 'noemo', 'sadness', 'joy'}\n",
      "{'anger', 'surprise', 'trust', 'shame', 'love', 'disgust', 'fear', 'noemo', 'sadness', 'guilt', 'joy'}\n",
      "matched Labels: {'anger', 'surprise', 'trust', 'love', 'disgust', 'fear', 'noemo', 'sadness', 'joy'}\n",
      "creating file for corpus similarity\n",
      "CosineSimilarity 0.9285267177996777\n",
      "{'anger': 0.9250070951847955, 'surprise': 0.9436308381827223, 'trust': 0.9997999732552842, 'love': 0.9997050989122384, 'disgust': 0.8945238677280176, 'fear': 0.9603451449551565, 'noemo': 0.7307885528241891, 'sadness': 0.9561618069529361, 'joy': 0.9466981628778082}\n",
      "file saved to  crowdflower_dailydialogSimilarities.txt\n",
      "------------------------------ ('crowdflower', 'affectivetext', 'tweets', 'headlines') -------------------------------------------\n",
      "Getting data\n",
      "{'anger', 'surprise', 'trust', 'love', 'disgust', 'fear', 'noemo', 'sadness', 'joy'}\n",
      "{'anger', 'surprise', 'trust', 'shame', 'love', 'disgust', 'fear', 'noemo', 'sadness', 'guilt', 'joy'}\n",
      "matched Labels: {'anger', 'surprise', 'trust', 'love', 'disgust', 'fear', 'noemo', 'sadness', 'joy'}\n",
      "{'anger', 'surprise', 'trust', 'love', 'disgust', 'fear', 'noemo', 'sadness', 'joy'}\n",
      "{'anger', 'surprise', 'trust', 'shame', 'love', 'disgust', 'fear', 'noemo', 'sadness', 'guilt', 'joy'}\n",
      "matched Labels: {'anger', 'surprise', 'trust', 'love', 'disgust', 'fear', 'noemo', 'sadness', 'joy'}\n",
      "creating file for corpus similarity\n",
      "CosineSimilarity 0.9277260646544502\n",
      "{'anger': 0.9250197054811342, 'surprise': 0.9438579630349563, 'trust': 0.9997999732552842, 'love': 0.9996123898611282, 'disgust': 0.8945287306099445, 'fear': 0.9604469446711915, 'noemo': 0.7305723767825208, 'sadness': 0.9562175340229654, 'joy': 0.9467859676920727}\n",
      "file saved to  crowdflower_affectivetextSimilarities.txt\n",
      "------------------------------ ('tales-emotion', 'tec', 'tales', 'tweets') -------------------------------------------\n",
      "Getting data\n",
      "{'anger', 'surprise', 'trust', 'love', 'disgust', 'fear', 'noemo', 'sadness', 'joy'}\n",
      "{'anger', 'surprise', 'trust', 'shame', 'love', 'disgust', 'fear', 'noemo', 'sadness', 'guilt', 'joy'}\n",
      "matched Labels: {'anger', 'surprise', 'trust', 'love', 'disgust', 'fear', 'noemo', 'sadness', 'joy'}\n",
      "{'anger', 'surprise', 'trust', 'love', 'disgust', 'fear', 'noemo', 'sadness', 'joy'}\n",
      "{'anger', 'surprise', 'trust', 'shame', 'love', 'disgust', 'fear', 'noemo', 'sadness', 'guilt', 'joy'}\n",
      "matched Labels: {'anger', 'surprise', 'trust', 'love', 'disgust', 'fear', 'noemo', 'sadness', 'joy'}\n",
      "creating file for corpus similarity\n",
      "CosineSimilarity 0.9470513095080527\n",
      "{'anger': 0.9470003805293009, 'surprise': 0.9709764851489975, 'trust': 0.9997999732552842, 'love': 0.9996123898611282, 'disgust': 0.918878198170252, 'fear': 0.9721744813338139, 'noemo': 0.8478429180676457, 'sadness': 0.9714361866442919, 'joy': 0.9649762424042384}\n",
      "file saved to  tales-emotion_tecSimilarities.txt\n",
      "------------------------------ ('tales-emotion', 'ssec', 'tales', 'tweets') -------------------------------------------\n",
      "Getting data\n",
      "{'anger', 'surprise', 'trust', 'love', 'disgust', 'fear', 'noemo', 'sadness', 'joy'}\n",
      "{'anger', 'surprise', 'trust', 'shame', 'love', 'disgust', 'fear', 'noemo', 'sadness', 'guilt', 'joy'}\n",
      "matched Labels: {'anger', 'surprise', 'trust', 'love', 'disgust', 'fear', 'noemo', 'sadness', 'joy'}\n",
      "{'anger', 'surprise', 'trust', 'love', 'disgust', 'fear', 'noemo', 'sadness', 'joy'}\n",
      "{'anger', 'surprise', 'trust', 'shame', 'love', 'disgust', 'fear', 'noemo', 'sadness', 'guilt', 'joy'}\n",
      "matched Labels: {'anger', 'surprise', 'trust', 'love', 'disgust', 'fear', 'noemo', 'sadness', 'joy'}\n",
      "creating file for corpus similarity\n",
      "CosineSimilarity 0.9525526876755502\n",
      "{'anger': 0.9507983525345415, 'surprise': 0.9741337665464938, 'trust': 0.9999041502920539, 'love': 0.9996123898611282, 'disgust': 0.9246896768845226, 'fear': 0.9737321643034355, 'noemo': 0.8577174148749506, 'sadness': 0.9734638978694622, 'joy': 0.9672514278423013}\n",
      "file saved to  tales-emotion_ssecSimilarities.txt\n",
      "------------------------------ ('tales-emotion', 'isear', 'tales', 'descriptions') -------------------------------------------\n",
      "Getting data\n",
      "{'anger', 'surprise', 'trust', 'love', 'disgust', 'fear', 'noemo', 'sadness', 'joy'}\n",
      "{'anger', 'surprise', 'trust', 'shame', 'love', 'disgust', 'fear', 'noemo', 'sadness', 'guilt', 'joy'}\n",
      "matched Labels: {'anger', 'surprise', 'trust', 'love', 'disgust', 'fear', 'noemo', 'sadness', 'joy'}\n",
      "{'anger', 'surprise', 'trust', 'love', 'disgust', 'fear', 'noemo', 'sadness', 'joy'}\n",
      "{'anger', 'surprise', 'trust', 'shame', 'love', 'disgust', 'fear', 'noemo', 'sadness', 'guilt', 'joy'}\n",
      "matched Labels: {'anger', 'surprise', 'trust', 'love', 'disgust', 'fear', 'noemo', 'sadness', 'joy'}\n",
      "creating file for corpus similarity\n",
      "CosineSimilarity 0.9541277567361398\n",
      "{'anger': 0.9509591277585862, 'surprise': 0.9756598366074158, 'trust': 0.9999041502920539, 'love': 0.9996123898611282, 'disgust': 0.9234806352154736, 'fear': 0.9737080414065286, 'noemo': 0.8621164247152275, 'sadness': 0.9738523044404608, 'joy': 0.9679927470405534}\n",
      "file saved to  tales-emotion_isearSimilarities.txt\n",
      "------------------------------ ('tales-emotion', 'grounded_emotions', 'tales', 'tweets') -------------------------------------------\n",
      "Getting data\n",
      "{'anger', 'surprise', 'trust', 'love', 'disgust', 'fear', 'noemo', 'sadness', 'joy'}\n",
      "{'anger', 'surprise', 'trust', 'shame', 'love', 'disgust', 'fear', 'noemo', 'sadness', 'guilt', 'joy'}\n",
      "matched Labels: {'anger', 'surprise', 'trust', 'love', 'disgust', 'fear', 'noemo', 'sadness', 'joy'}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'anger', 'surprise', 'trust', 'love', 'disgust', 'fear', 'noemo', 'sadness', 'joy'}\n",
      "{'anger', 'surprise', 'trust', 'shame', 'love', 'disgust', 'fear', 'noemo', 'sadness', 'guilt', 'joy'}\n",
      "matched Labels: {'anger', 'surprise', 'trust', 'love', 'disgust', 'fear', 'noemo', 'sadness', 'joy'}\n",
      "creating file for corpus similarity\n",
      "CosineSimilarity 0.9549971931565993\n",
      "{'anger': 0.9517538398972355, 'surprise': 0.9766259535526319, 'trust': 0.9999041502920539, 'love': 0.9996123898611282, 'disgust': 0.9243191821933393, 'fear': 0.9741589473964044, 'noemo': 0.8646747692702178, 'sadness': 0.9745199557225721, 'joy': 0.9687974343661813}\n",
      "file saved to  tales-emotion_grounded_emotionsSimilarities.txt\n",
      "------------------------------ ('tales-emotion', 'emotion-cause', 'tales', 'paragraphs') -------------------------------------------\n",
      "Getting data\n",
      "{'anger', 'surprise', 'trust', 'love', 'disgust', 'fear', 'noemo', 'sadness', 'joy'}\n",
      "{'anger', 'surprise', 'trust', 'shame', 'love', 'disgust', 'fear', 'noemo', 'sadness', 'guilt', 'joy'}\n",
      "matched Labels: {'anger', 'surprise', 'trust', 'love', 'disgust', 'fear', 'noemo', 'sadness', 'joy'}\n",
      "{'anger', 'surprise', 'trust', 'love', 'disgust', 'fear', 'noemo', 'sadness', 'joy'}\n",
      "{'anger', 'surprise', 'trust', 'shame', 'love', 'disgust', 'fear', 'noemo', 'sadness', 'guilt', 'joy'}\n",
      "matched Labels: {'anger', 'surprise', 'trust', 'love', 'disgust', 'fear', 'noemo', 'sadness', 'joy'}\n",
      "creating file for corpus similarity\n",
      "CosineSimilarity 0.9555426098573799\n",
      "{'anger': 0.951179204975788, 'surprise': 0.9766550999228115, 'trust': 0.9999041502920539, 'love': 0.9996123898611282, 'disgust': 0.9242558451447115, 'fear': 0.9737837938383267, 'noemo': 0.8663581636873806, 'sadness': 0.9741447408223649, 'joy': 0.9688150465555161}\n",
      "file saved to  tales-emotion_emotion-causeSimilarities.txt\n",
      "------------------------------ ('tales-emotion', 'emoint', 'tales', 'tweets') -------------------------------------------\n",
      "Getting data\n",
      "{'anger', 'surprise', 'trust', 'love', 'disgust', 'fear', 'noemo', 'sadness', 'joy'}\n",
      "{'anger', 'surprise', 'trust', 'shame', 'love', 'disgust', 'fear', 'noemo', 'sadness', 'guilt', 'joy'}\n",
      "matched Labels: {'anger', 'surprise', 'trust', 'love', 'disgust', 'fear', 'noemo', 'sadness', 'joy'}\n",
      "{'anger', 'surprise', 'trust', 'love', 'disgust', 'fear', 'noemo', 'sadness', 'joy'}\n",
      "{'anger', 'surprise', 'trust', 'shame', 'love', 'disgust', 'fear', 'noemo', 'sadness', 'guilt', 'joy'}\n",
      "matched Labels: {'anger', 'surprise', 'trust', 'love', 'disgust', 'fear', 'noemo', 'sadness', 'joy'}\n",
      "creating file for corpus similarity\n",
      "CosineSimilarity 0.9560551614116466\n",
      "{'anger': 0.9524064209724755, 'surprise': 0.9771706015006084, 'trust': 0.9999041502920539, 'love': 0.9996123898611282, 'disgust': 0.9246783253626584, 'fear': 0.974320061566336, 'noemo': 0.8675485595263296, 'sadness': 0.9746885190655454, 'joy': 0.9693497908024914}\n",
      "file saved to  tales-emotion_emointSimilarities.txt\n",
      "------------------------------ ('tales-emotion', 'dailydialog', 'tales', 'conversations') -------------------------------------------\n",
      "Getting data\n",
      "{'anger', 'surprise', 'trust', 'love', 'disgust', 'fear', 'noemo', 'sadness', 'joy'}\n",
      "{'anger', 'surprise', 'trust', 'shame', 'love', 'disgust', 'fear', 'noemo', 'sadness', 'guilt', 'joy'}\n",
      "matched Labels: {'anger', 'surprise', 'trust', 'love', 'disgust', 'fear', 'noemo', 'sadness', 'joy'}\n",
      "{'anger', 'surprise', 'trust', 'love', 'disgust', 'fear', 'noemo', 'sadness', 'joy'}\n",
      "{'anger', 'surprise', 'trust', 'shame', 'love', 'disgust', 'fear', 'noemo', 'sadness', 'guilt', 'joy'}\n",
      "matched Labels: {'anger', 'surprise', 'trust', 'love', 'disgust', 'fear', 'noemo', 'sadness', 'joy'}\n",
      "creating file for corpus similarity\n",
      "CosineSimilarity 0.9558124010804885\n",
      "{'anger': 0.952310931125332, 'surprise': 0.9768531181167662, 'trust': 0.9999041502920539, 'love': 0.9996123898611282, 'disgust': 0.9246480765274423, 'fear': 0.974461456406984, 'noemo': 0.8626920104080481, 'sadness': 0.9747060939532828, 'joy': 0.9684908203288196}\n",
      "file saved to  tales-emotion_dailydialogSimilarities.txt\n",
      "------------------------------ ('tales-emotion', 'crowdflower', 'tales', 'tweets') -------------------------------------------\n",
      "Getting data\n",
      "{'anger', 'surprise', 'trust', 'love', 'disgust', 'fear', 'noemo', 'sadness', 'joy'}\n",
      "{'anger', 'surprise', 'trust', 'shame', 'love', 'disgust', 'fear', 'noemo', 'sadness', 'guilt', 'joy'}\n",
      "matched Labels: {'anger', 'surprise', 'trust', 'love', 'disgust', 'fear', 'noemo', 'sadness', 'joy'}\n",
      "{'anger', 'surprise', 'trust', 'love', 'disgust', 'fear', 'noemo', 'sadness', 'joy'}\n",
      "{'anger', 'surprise', 'trust', 'shame', 'love', 'disgust', 'fear', 'noemo', 'sadness', 'guilt', 'joy'}\n",
      "matched Labels: {'anger', 'surprise', 'trust', 'love', 'disgust', 'fear', 'noemo', 'sadness', 'joy'}\n",
      "creating file for corpus similarity\n",
      "CosineSimilarity 0.9562985797537327\n",
      "{'anger': 0.9532166073110527, 'surprise': 0.9774639855012386, 'trust': 0.9999041502920539, 'love': 0.9998131613768365, 'disgust': 0.9251602860090734, 'fear': 0.9756474422211265, 'noemo': 0.8685112607290231, 'sadness': 0.9755263513848133, 'joy': 0.9696771040725901}\n",
      "file saved to  tales-emotion_crowdflowerSimilarities.txt\n",
      "------------------------------ ('tales-emotion', 'affectivetext', 'tales', 'headlines') -------------------------------------------\n",
      "Getting data\n",
      "{'anger', 'surprise', 'trust', 'love', 'disgust', 'fear', 'noemo', 'sadness', 'joy'}\n",
      "{'anger', 'surprise', 'trust', 'shame', 'love', 'disgust', 'fear', 'noemo', 'sadness', 'guilt', 'joy'}\n",
      "matched Labels: {'anger', 'surprise', 'trust', 'love', 'disgust', 'fear', 'noemo', 'sadness', 'joy'}\n",
      "{'anger', 'surprise', 'trust', 'love', 'disgust', 'fear', 'noemo', 'sadness', 'joy'}\n",
      "{'anger', 'surprise', 'trust', 'shame', 'love', 'disgust', 'fear', 'noemo', 'sadness', 'guilt', 'joy'}\n",
      "matched Labels: {'anger', 'surprise', 'trust', 'love', 'disgust', 'fear', 'noemo', 'sadness', 'joy'}\n",
      "creating file for corpus similarity\n",
      "CosineSimilarity 0.9571870757436517\n",
      "{'anger': 0.9534058029441163, 'surprise': 0.977723914119311, 'trust': 0.9999041502920539, 'love': 0.9998131613768365, 'disgust': 0.9253632184260933, 'fear': 0.9757605040868613, 'noemo': 0.8689297126560778, 'sadness': 0.9756665351131848, 'joy': 0.9698432765132721}\n",
      "file saved to  tales-emotion_affectivetextSimilarities.txt\n",
      "------------------------------ ('emotion-cause', 'tec', 'paragraphs', 'tweets') -------------------------------------------\n",
      "Getting data\n",
      "{'anger', 'surprise', 'trust', 'love', 'disgust', 'fear', 'noemo', 'sadness', 'joy'}\n",
      "{'anger', 'surprise', 'trust', 'shame', 'love', 'disgust', 'fear', 'noemo', 'sadness', 'guilt', 'joy'}\n",
      "matched Labels: {'anger', 'surprise', 'trust', 'love', 'disgust', 'fear', 'noemo', 'sadness', 'joy'}\n",
      "{'anger', 'surprise', 'trust', 'love', 'disgust', 'fear', 'noemo', 'sadness', 'joy'}\n",
      "{'anger', 'surprise', 'trust', 'shame', 'love', 'disgust', 'fear', 'noemo', 'sadness', 'guilt', 'joy'}\n",
      "matched Labels: {'anger', 'surprise', 'trust', 'love', 'disgust', 'fear', 'noemo', 'sadness', 'joy'}\n",
      "creating file for corpus similarity\n",
      "CosineSimilarity 0.9625626769839145\n",
      "{'anger': 0.9690292523672379, 'surprise': 0.9863982987219293, 'trust': 0.9999041502920539, 'love': 0.9998131613768365, 'disgust': 0.9362753865508011, 'fear': 0.9842243777260902, 'noemo': 0.8689297126560778, 'sadness': 0.9851889555576488, 'joy': 0.9762587179364127}\n",
      "file saved to  emotion-cause_tecSimilarities.txt\n",
      "------------------------------ ('emotion-cause', 'tales-emotion', 'paragraphs', 'tales') -------------------------------------------\n",
      "Getting data\n",
      "{'anger', 'surprise', 'trust', 'love', 'disgust', 'fear', 'noemo', 'sadness', 'joy'}\n",
      "{'anger', 'surprise', 'trust', 'shame', 'love', 'disgust', 'fear', 'noemo', 'sadness', 'guilt', 'joy'}\n",
      "matched Labels: {'anger', 'surprise', 'trust', 'love', 'disgust', 'fear', 'noemo', 'sadness', 'joy'}\n",
      "{'anger', 'surprise', 'trust', 'love', 'disgust', 'fear', 'noemo', 'sadness', 'joy'}\n",
      "{'anger', 'surprise', 'trust', 'shame', 'love', 'disgust', 'fear', 'noemo', 'sadness', 'guilt', 'joy'}\n",
      "matched Labels: {'anger', 'surprise', 'trust', 'love', 'disgust', 'fear', 'noemo', 'sadness', 'joy'}\n",
      "creating file for corpus similarity\n",
      "CosineSimilarity 0.9644088932051322\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'anger': 0.9706886684563688, 'surprise': 0.987098989128282, 'trust': 0.9999041502920539, 'love': 0.9998131613768365, 'disgust': 0.9374216201003379, 'fear': 0.9850870977666286, 'noemo': 0.8696046017073195, 'sadness': 0.9861368290123251, 'joy': 0.9768432280025922}\n",
      "file saved to  emotion-cause_tales-emotionSimilarities.txt\n",
      "------------------------------ ('emotion-cause', 'ssec', 'paragraphs', 'tweets') -------------------------------------------\n",
      "Getting data\n",
      "{'anger', 'surprise', 'trust', 'love', 'disgust', 'fear', 'noemo', 'sadness', 'joy'}\n",
      "{'anger', 'surprise', 'trust', 'shame', 'love', 'disgust', 'fear', 'noemo', 'sadness', 'guilt', 'joy'}\n",
      "matched Labels: {'anger', 'surprise', 'trust', 'love', 'disgust', 'fear', 'noemo', 'sadness', 'joy'}\n",
      "{'anger', 'surprise', 'trust', 'love', 'disgust', 'fear', 'noemo', 'sadness', 'joy'}\n",
      "{'anger', 'surprise', 'trust', 'shame', 'love', 'disgust', 'fear', 'noemo', 'sadness', 'guilt', 'joy'}\n",
      "matched Labels: {'anger', 'surprise', 'trust', 'love', 'disgust', 'fear', 'noemo', 'sadness', 'joy'}\n",
      "creating file for corpus similarity\n",
      "CosineSimilarity 0.964883119540305\n",
      "{'anger': 0.9719126860507764, 'surprise': 0.9873830789110147, 'trust': 0.9999599468433906, 'love': 0.9998131613768365, 'disgust': 0.9396753540325538, 'fear': 0.9855131811761704, 'noemo': 0.8696046017073195, 'sadness': 0.9866073126607025, 'joy': 0.9771967455484789}\n",
      "file saved to  emotion-cause_ssecSimilarities.txt\n",
      "------------------------------ ('emotion-cause', 'isear', 'paragraphs', 'descriptions') -------------------------------------------\n",
      "Getting data\n",
      "{'anger', 'surprise', 'trust', 'love', 'disgust', 'fear', 'noemo', 'sadness', 'joy'}\n",
      "{'anger', 'surprise', 'trust', 'shame', 'love', 'disgust', 'fear', 'noemo', 'sadness', 'guilt', 'joy'}\n",
      "matched Labels: {'anger', 'surprise', 'trust', 'love', 'disgust', 'fear', 'noemo', 'sadness', 'joy'}\n",
      "{'anger', 'surprise', 'trust', 'love', 'disgust', 'fear', 'noemo', 'sadness', 'joy'}\n",
      "{'anger', 'surprise', 'trust', 'shame', 'love', 'disgust', 'fear', 'noemo', 'sadness', 'guilt', 'joy'}\n",
      "matched Labels: {'anger', 'surprise', 'trust', 'love', 'disgust', 'fear', 'noemo', 'sadness', 'joy'}\n",
      "creating file for corpus similarity\n",
      "CosineSimilarity 0.9649644871012966\n",
      "{'anger': 0.9713555069194898, 'surprise': 0.9875951927232495, 'trust': 0.9999599468433906, 'love': 0.9998131613768365, 'disgust': 0.9377071135689089, 'fear': 0.9851293897165181, 'noemo': 0.8696046017073195, 'sadness': 0.9864311713489414, 'joy': 0.9771029099931963}\n",
      "file saved to  emotion-cause_isearSimilarities.txt\n",
      "------------------------------ ('emotion-cause', 'grounded_emotions', 'paragraphs', 'tweets') -------------------------------------------\n",
      "Getting data\n",
      "{'anger', 'surprise', 'trust', 'love', 'disgust', 'fear', 'noemo', 'sadness', 'joy'}\n",
      "{'anger', 'surprise', 'trust', 'shame', 'love', 'disgust', 'fear', 'noemo', 'sadness', 'guilt', 'joy'}\n",
      "matched Labels: {'anger', 'surprise', 'trust', 'love', 'disgust', 'fear', 'noemo', 'sadness', 'joy'}\n",
      "{'anger', 'surprise', 'trust', 'love', 'disgust', 'fear', 'noemo', 'sadness', 'joy'}\n",
      "{'anger', 'surprise', 'trust', 'shame', 'love', 'disgust', 'fear', 'noemo', 'sadness', 'guilt', 'joy'}\n",
      "matched Labels: {'anger', 'surprise', 'trust', 'love', 'disgust', 'fear', 'noemo', 'sadness', 'joy'}\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-93-738ab8614e87>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      8\u001b[0m     \u001b[0mclassifierTrials\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m     \u001b[0msimilarityTrials\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 10\u001b[1;33m     \u001b[0mrunTrials\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mversion\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mverifyResults\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mclassifierTrials\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msimilarityTrials\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcrossCorpus\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msameCorpus\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mallVs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-92-b4c354f3f760>\u001b[0m in \u001b[0;36mrunTrials\u001b[1;34m(version, verifyResults, classifierTrials, similarityTrials, crossCorpus, sameCorpus, allVs)\u001b[0m\n\u001b[0;32m     23\u001b[0m                 \u001b[0mperformTrialUsingCorpusPair\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcorpusPair\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mverifyResults\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     24\u001b[0m             \u001b[1;32mif\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msimilarityTrials\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 25\u001b[1;33m                 \u001b[0mgetCorpusSimilarities\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcorpusPair\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     26\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m \u001b[1;31m#version == \"myTrials\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     27\u001b[0m         \u001b[0mpowerSet\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mgetPowerset\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpossibleChoices\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-90-80eea909fd5b>\u001b[0m in \u001b[0;36mgetCorpusSimilarities\u001b[1;34m(corpusPair)\u001b[0m\n\u001b[0;32m     16\u001b[0m \u001b[1;31m#     np2 = np.load(numPyFileName2)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     17\u001b[0m     \u001b[0mcosineSim\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgetCosineSimilarityFromCorpus\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfirst\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0msecond\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 18\u001b[1;33m     \u001b[0mcosineSimEmotions\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgetCosineSimilarityFromCorpusEmotions\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfirst\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0msecond\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     19\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"creating file for corpus similarity\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     20\u001b[0m     \u001b[1;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msimilaritiesFileName\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'w'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mencoding\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"utf-8\"\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-72-4cc2446607fb>\u001b[0m in \u001b[0;36mgetCosineSimilarityFromCorpusEmotions\u001b[1;34m(corpus1, corpus2)\u001b[0m\n\u001b[0;32m      3\u001b[0m     \u001b[0mcorpus1Data\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mcorpus2Data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcorporaData\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m     \u001b[0memotionLabels\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mgetMatchingLabels\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcorporaData\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m     \u001b[0memotionDicts1\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgetWordCountsByEmotion\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcorpus1Data\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0memotionLabels\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      6\u001b[0m     \u001b[0memotionDicts2\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgetWordCountsByEmotion\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcorpus2Data\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0memotionLabels\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m     \u001b[0memoSim\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m{\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-12-2e66c91e3703>\u001b[0m in \u001b[0;36mgetWordCountsByEmotion\u001b[1;34m(dataset, emotionLabels)\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[1;31m#                 print(data)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[1;31m#                 print(data[\"emotions\"][emotion])\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 10\u001b[1;33m             \u001b[0memotionDict\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m{\u001b[0m\u001b[0mtoken\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mtoken\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mtokenize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"text\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"emotions\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0memotion\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     11\u001b[0m \u001b[1;31m#         print(\"emotionsWordCounts\", len(emotionDict))\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     12\u001b[0m         \u001b[0memotionCounts\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0memotionDict\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-11-f529ac3e73db>\u001b[0m in \u001b[0;36mtokenize\u001b[1;34m(text)\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;31m#if there is improvement, it should be because of my changes\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mtokenize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mre\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfindall\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34mr\"\\p{L}+\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtext\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlower\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\regex\\regex.py\u001b[0m in \u001b[0;36mfindall\u001b[1;34m(pattern, string, flags, pos, endpos, overlapped, concurrent, timeout, ignore_unused, **kwargs)\u001b[0m\n\u001b[0;32m    334\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0ma\u001b[0m \u001b[0mlist\u001b[0m \u001b[0mof\u001b[0m \u001b[0mgroups\u001b[0m\u001b[1;33m;\u001b[0m \u001b[0mthis\u001b[0m \u001b[0mwill\u001b[0m \u001b[0mbe\u001b[0m \u001b[0ma\u001b[0m \u001b[0mlist\u001b[0m \u001b[0mof\u001b[0m \u001b[0mtuples\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mpattern\u001b[0m \u001b[0mhas\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    335\u001b[0m     more than one group. Empty matches are included in the result.\"\"\"\n\u001b[1;32m--> 336\u001b[1;33m     return _compile(pattern, flags, ignore_unused, kwargs).findall(string, pos,\n\u001b[0m\u001b[0;32m    337\u001b[0m       endpos, overlapped, concurrent, timeout)\n\u001b[0;32m    338\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    version = \"previous\"\n",
    "#     version = \"myTrials\"\n",
    "    crossCorpus = True\n",
    "    sameCorpus = False\n",
    "    allVs = False\n",
    "    verifyResults = True\n",
    "    classifierTrials = False\n",
    "    similarityTrials = True\n",
    "    runTrials(version, verifyResults, classifierTrials, similarityTrials, crossCorpus, sameCorpus, allVs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import regex as re\n",
    "import sys\n",
    "import os\n",
    "import json\n",
    "import random\n",
    "import math\n",
    "import operator as op\n",
    "import docopt\n",
    "import numpy as np\n",
    "import os.path\n",
    "import itertools\n",
    "from os import path\n",
    "from tqdm import tqdm\n",
    "from scipy.spatial.distance import jensenshannon, cosine\n",
    "from numpy import asarray\n",
    "import statistics \n",
    "from collections import Counter, defaultdict, namedtuple\n",
    "\n",
    "from sklearn.linear_model import LogisticRegressionCV\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, precision_recall_fscore_support\n",
    "from sklearn.metrics.pairwise import cosine_similarity, chi2_kernel\n",
    "from scipy.spatial import distance\n",
    "import joblib\n",
    "import shutil\n",
    "\n",
    "Report = namedtuple(\"Report\", [\"precision\", \"recall\", \"accuracy\", \"f1\", \"tp\", \"tn\", \"fp\", \"fn\"])\n",
    "JSON = \"unified-dataset.jsonl\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "False\n",
      "False\n",
      "False\n",
      "True\n",
      "False\n",
      "(4868, 5000)\n",
      "(4868, 5000)\n",
      "(4868, 5000)\n",
      "(7666, 5000)\n",
      "(4868, 5000)\n",
      "[0. 0. 0. ... 0. 0. 0.]\n",
      "0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\Anaconda3\\lib\\site-packages\\scipy\\spatial\\distance.py:1279: RuntimeWarning: invalid value encountered in true_divide\n",
      "  q = q / np.sum(q, axis=0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.65300289 0.71217394 0.65470119 ...        nan 0.83255461        nan]\n",
      "0.48101544698034715\n",
      "[[1.00000000e+00 2.54366565e-13 3.44247711e-14 ... 5.10908903e-12\n",
      "  3.77513454e-11 1.38879439e-11]\n",
      " [2.54366565e-13 1.00000000e+00 1.26641655e-14 ... 4.65888615e-15\n",
      "  2.54366565e-13 9.35762297e-14]\n",
      " [3.44247711e-14 1.26641655e-14 1.00000000e+00 ... 6.30511676e-16\n",
      "  6.30511676e-16 1.71390843e-15]\n",
      " ...\n",
      " [5.10908903e-12 4.65888615e-15 6.30511676e-16 ... 1.00000000e+00\n",
      "  5.10908903e-12 2.54366565e-13]\n",
      " [3.77513454e-11 2.54366565e-13 6.30511676e-16 ... 5.10908903e-12\n",
      "  1.00000000e+00 1.87952882e-12]\n",
      " [1.38879439e-11 9.35762297e-14 1.71390843e-15 ... 2.54366565e-13\n",
      "  1.87952882e-12 1.00000000e+00]]\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "only size-1 arrays can be converted to Python scalars",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-25-f6814e2dd214>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     19\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mgetJensenShannonFromNPArrays\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0marr1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0marr2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     20\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mgetJensenShannonFromNPArrays\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0marr2\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0marr3\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 21\u001b[1;33m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mgetCosineFromNPArrays\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0marr1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0marr2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     22\u001b[0m \u001b[1;31m# print(getJensenShannonFromNPArrays(arr4,arr5))\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-3-616c5898512b>\u001b[0m in \u001b[0;36mgetCosineFromNPArrays\u001b[1;34m(np1, np2)\u001b[0m\n\u001b[0;32m      6\u001b[0m     \u001b[0mlength\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mjs_pq\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mjs_pq\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 8\u001b[1;33m         \u001b[1;32mif\u001b[0m \u001b[0mmath\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0misnan\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m \u001b[1;31m#assume nan values should be interpretted as 0\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      9\u001b[0m             \u001b[0msumJS\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: only size-1 arrays can be converted to Python scalars"
     ]
    }
   ],
   "source": [
    "#test code for understanding how NP arrays are distributed\n",
    "arr1 = np.load(\"ssec_emotion-causetrain_xNP.npy\")\n",
    "arr2 = np.load(\"ssec_grounded_emotionstrain_xNP.npy\")\n",
    "arr3 = np.load(\"isear_ssectest_xNP.npy\")\n",
    "arr4 = np.load(\"isear_ssectrain_xNP.npy\")\n",
    "arr5 = np.load(\"ssec_iseartest_xNP.npy\")\n",
    "arr5 = np.load(\"ssec_iseartrain_xNP.npy\")\n",
    "print(np.array_equal(arr1,arr2))\n",
    "print(np.array_equal(arr2,arr3))\n",
    "print(np.array_equal(arr3,arr4))\n",
    "print(np.array_equal(arr4,arr5))\n",
    "print(np.array_equal(arr1,arr5))\n",
    "print(np.array_equal(arr3,arr5))\n",
    "print(arr1.shape)\n",
    "print(arr2.shape)\n",
    "print(arr3.shape)\n",
    "print(arr4.shape)\n",
    "print(arr5.shape)\n",
    "print(getJensenShannonFromNPArrays(arr1,arr2))\n",
    "print(getJensenShannonFromNPArrays(arr2,arr3))\n",
    "# print(getJensenShannonFromNPArrays(arr4,arr5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#this method is used to get the classifier mode and decide whether to single-label or multi-label classification\n",
    "#this method comes from the original authors and is kept to replicate their results\n",
    "def get_clf_mode(train, test):\n",
    "    first = \"single\"\n",
    "    for example in train:\n",
    "        if example.get(\"labeled\", \"multi\") == \"multi\":\n",
    "            first = \"multi\"\n",
    "    print(first)\n",
    "    for example in test:\n",
    "        if example.get(\"labeled\", \"multi\") == \"multi\":\n",
    "            return first, \"multi\"\n",
    "    print(\"oof\")\n",
    "    return first, \"single\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#This methods is used to extract the training and testing data from the unified corpus json.\n",
    "#The unified corpus json must be produced using the authors original code\n",
    "#this version is only used in getting the benchmarks for the previous paper\n",
    "#this version takes the jsonfile, the name of the train file and the name of the test file as parameters\n",
    "def get_train_test(jsonfile, train, test):\n",
    "    print(\"get_train_test param:\")\n",
    "    print(\"json \", jsonfile)\n",
    "    print(\"train \", train)\n",
    "    print(\"test \", test)\n",
    "#     same = test in train.split(\",\") #used if train and test corpus are same\n",
    "    training, testing = [], []\n",
    "    count1 = 0\n",
    "    count2 = 0\n",
    "    count3 = 0\n",
    "    count4 = 0\n",
    "    with open(jsonfile) as f:\n",
    "        for line in f:\n",
    "            data = json.loads(line)\n",
    "            if(data[\"source\"] == test):\n",
    "                count1 += 1\n",
    "            if(data[\"source\"] != test):\n",
    "                count2 += 1\n",
    "            if(train == None and data[\"source\"] != test):\n",
    "                count3 += 1\n",
    "                training.append(data)\n",
    "            elif data[\"source\"] == test:\n",
    "                count4 += 1\n",
    "                testing.append(data)\n",
    "            elif(data[\"source\"] in train.split(\",\")):\n",
    "                count3 += 1\n",
    "                training.append(data)\n",
    "    print(\"there were \", count1, \" entries that were in test and \", count2, \"that were not in test\",\n",
    "          \"and \", count3, \" that were in train\")\n",
    "    print(\"test was appended \", count4, \" times\")\n",
    "#     if same:\n",
    "#         training, testing = hacky_train_test_split(training, train_size=0.8, first=train, second=test)\n",
    "    return training, testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#this method stays as is from the original paper\n",
    "def get_labels(train, test, operation=op.and_, mode=\"multi\"):\n",
    "    \"\"\"Return a list of the emotional intersection of two sources.\"\"\"\n",
    "    emotions = set()\n",
    "    if mode == \"single\":\n",
    "        emotions.add(\"noemo\")\n",
    "    train_emotions = set(\n",
    "        emotion\n",
    "        for data in train\n",
    "        for emotion in data[\"emotions\"]\n",
    "        if data[\"emotions\"][emotion] is not None\n",
    "    )\n",
    "    # print(train_emotions)\n",
    "    test_emotions = set(\n",
    "        emotion\n",
    "        for emotion in test[0][\"emotions\"]\n",
    "        if test[0][\"emotions\"][emotion] is not None\n",
    "    )\n",
    "    # print(test_emotions)\n",
    "    return list(emotions | operation(train_emotions, test_emotions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#expects corpus list in data form\n",
    "#returns compatible labels\n",
    "def getMatchingLabels(corpora):\n",
    "    emotionSetList = []\n",
    "    for corpus in corpora:\n",
    "        emoSet = set(emotion for data in corpus for emotion in data[\"emotions\"] if data[\"emotions\"][emotion] is not None)\n",
    "        emotionSetList.append(emoSet)\n",
    "    intersectionSet = set.intersection(*emotionSetList)\n",
    "    print(intersectionSet)\n",
    "    return intersectionSet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#this method stays as is from the original paper\n",
    "def get_emotion(emovals, labels, emotions, mode=\"multi\"):\n",
    "#     print(\"get emotion mode \", mode)\n",
    "#     print(\"emovals \",emovals)\n",
    "#     print(\"labels \",labels)\n",
    "#     print(\"emotions \",emotions)\n",
    "    if mode == \"single\":\n",
    "        truthy = len(list(filter(bool, emovals.values())))\n",
    "        if truthy == 1:\n",
    "            emotion = [v for v in emovals if emovals[v]][0]\n",
    "        elif truthy == 0:\n",
    "            emotion = \"noemo\"\n",
    "        else:\n",
    "            raise ValueError(\"Dataset marked as 'single' contains multiple emotions\")\n",
    "        return emotions.get(emotion, emotions.get(\"noemo\"))\n",
    "    else:\n",
    "        el = [int((emovals[label] or 0) > 0.1) for label in labels]\n",
    "        return np.array(el)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#this method stays as is from the original paper\n",
    "def get_vector(text, wordlist):\n",
    "    tokens = set(tokenize(text))\n",
    "    print(tokens)\n",
    "    return [1 if word in tokens else 0 for word in wordlist]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#The comment below was left by the original authors. As you can see, their results were unable to use the full bag of words\n",
    "# this is bad. memory error for all_vs (too many words...)\n",
    "def get_wordlist(dataset):\n",
    "    \"\"\"Get a bag of words from a dataset.\"\"\"\n",
    "    bag = set()\n",
    "    for data in dataset:\n",
    "        bag.update({token for token in tokenize(data[\"text\"])})\n",
    "    return list(bag)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#bag of word limit of 5000 is kept from the original authors to match their results\n",
    "def getTop5000Words(dataset):\n",
    "    \"\"\"Get a bag of words from a dataset.\"\"\"\n",
    "    bag = Counter()\n",
    "    for data in dataset:\n",
    "        bag.update({token for token in tokenize(data[\"text\"])})\n",
    "    print(\"bag size\", len(bag))\n",
    "#     print(\"bag\", bag)\n",
    "    out = list(map(op.itemgetter(0), bag.most_common(5000)))\n",
    "#     print(\"this is the output\", out)\n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def cleanReviewDataLemma(dataset):\n",
    "#     taggedDataset = nltk.pos_tag(dataset)\n",
    "#     filteredString = []\n",
    "#     for token, tag in taggedReview:\n",
    "#         for char in token:\n",
    "#             if char in string.punctuation:\n",
    "#                 token = token.replace(char,\"\") #remove punctuation\n",
    "#         if (token not in stopWords):\n",
    "#             lemmatizedToken = \"\"\n",
    "#             if tag[0] == 'N':\n",
    "#                 lemmatizedToken = lemmatizer.lemmatize(token, 'n')\n",
    "#             elif tag[0] == 'V':\n",
    "#                 lemmatizedToken = lemmatizer.lemmatize(token, 'v')\n",
    "#             else:\n",
    "#                 lemmatizedToken = token\n",
    "#             if len(lemmatizedToken) > 2:\n",
    "#                 filteredString.append(lemmatizedToken)\n",
    "#     return filteredString"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#tokenization is kept the same so that performance results match the ones used in the paper as closely as possible\n",
    "#if there is improvement, it should be because of my changes\n",
    "def tokenize(text):\n",
    "    return re.findall(r\"\\p{L}+\", text.lower())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getWordCountsByEmotion(dataset, emotionLabels):\n",
    "    emotionCounts = []\n",
    "    print(\"emotions\")\n",
    "    for emotion in emotionLabels:\n",
    "        emotionDict = Counter()\n",
    "        for data in dataset:\n",
    "#             if data[\"emotions\"][emotion] == 1:\n",
    "#                 print(emotion)\n",
    "#                 print(data)\n",
    "#                 print(data[\"emotions\"][emotion])\n",
    "            emotionDict.update({token for token in tokenize(data[\"text\"]) if data[\"emotions\"][emotion] == 1})\n",
    "        print(len(emotionDict))\n",
    "        emotionCounts.append(emotionDict)\n",
    "    return emotionCounts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getTokenFrequency(dataset):\n",
    "    token2DocFreq = {}\n",
    "    for data in dataset:\n",
    "        tempDict = {}\n",
    "        for word in data:\n",
    "            if word not in tempDict:\n",
    "                tempDict[word] = 1\n",
    "        for key, value in tempDict.items():\n",
    "            if key in token2DocFreq:\n",
    "                token2DocFreq[key] += value\n",
    "            else:\n",
    "                token2DocFreq[key] = value\n",
    "    return token2DocFreq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getTokenizedCorpusTextPair(corpus1, corpus2):\n",
    "    with open(JSON) as f:\n",
    "        for line in f:\n",
    "            data = json.loads(line)\n",
    "            if data[\"source\"] in corporaNameList:\n",
    "                corpus1Text.append(tokenize(data[\"text\"]))\n",
    "                corpus1Data.append(data)\n",
    "            if data[\"source\"] in corporaNameList:\n",
    "                corpus2Text.append(tokenize(data[\"text\"]))\n",
    "                corpus2Data.append(data)\n",
    "    corporaData = [corpus1Data,corpus2Data]\n",
    "    return corpus1Text, corpus2Text, corporaData"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def getNormalizedFreq(tokenFreq):\n",
    "# def getNormalizedFreq(corpus):\n",
    "#     newCorpus = []\n",
    "#     for entry in corpus:\n",
    "#         newCorpus.append(tokenize(entry))\n",
    "#     tokenFreq = getTokenFrequency(newCorpus)\n",
    "#     print(tokenFreq.items())\n",
    "#     print(\"freq values\", tokenFreq)\n",
    "    newTokenFreq = tokenFreq.copy()\n",
    "    for item, freq in newTokenFreq.items():\n",
    "        if(freq == 0):\n",
    "            newTokenFreq[item] = 0\n",
    "        else:\n",
    "            newTokenFreq[item] = 1 + math.log10(freq)\n",
    "#     print(\"log weighted values\", tokenFreq)\n",
    "    docLength = 0\n",
    "    for freq in newTokenFreq.values():\n",
    "        docLength += freq*freq\n",
    "    docLength = math.sqrt(docLength)\n",
    "#     print(\"doclength\", docLength)\n",
    "    for item, freq in newTokenFreq.items():\n",
    "        newTokenFreq[item] = freq/docLength\n",
    "    # logFreq = freq for freq in math.log() \n",
    "#     print(\"normalized\")\n",
    "#     print(tokenFreq)\n",
    "    return newTokenFreq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getCosineSimilarityFromTokenFreq(tokenFreq1, tokenFreq2):\n",
    "    normFreq1 = getNormalizedFreq(tokenFreq1)\n",
    "    normFreq2 = getNormalizedFreq(tokenFreq2)\n",
    "    cosineSum = 0\n",
    "    normFreq1.items()\n",
    "    print(\"length 1\", len(normFreq1))\n",
    "    print(\"length 2\", len(normFreq2))\n",
    "    intersection = normFreq1.keys() & normFreq2.keys()\n",
    "    #only loop intersection because unshared values will be multiplied by 0 anyway\n",
    "    for item in intersection:\n",
    "#         if normFreq1[item] < 0 or normFreq2[item] < 0 :\n",
    "#             print(\"negative?\", item, normFreq1[item],normFreq2[item])\n",
    "#             sys.exit()\n",
    "#         print(item)\n",
    "#         print(normFreq1[item])\n",
    "#         print(normFreq2[item])\n",
    "        x = normFreq1[item] * normFreq2[item]\n",
    "        cosineSum += x\n",
    "    return cosineSum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getCosineSimilarityFromCorpus(corpus1,corpus2):\n",
    "    corpus1Text, corpus2Text, corpus1Data, corpus2Data = getTokenizedCorpusTextPair(corpus1, corpus2)\n",
    "    emotionLabels = getMatchingLabels(corporaData)\n",
    "    tokenFreq1 = getTokenFrequency(corpus1Text)\n",
    "    tokenFreq2 = getTokenFrequency(corpus2Text)\n",
    "    sim = getCosineSimilarityFromTokenFreq(tokenFreq1, tokenFreq2)\n",
    "    return sim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getCosineSimilarityFromCorpusEmotions(corpus1,corpus2):\n",
    "    corpus1Text, corpus2Text, corpus1Data, corpus2Data = getTokenizedCorpusTextPair(corpus1, corpus2)\n",
    "    emotionLabels = getMatchingLabels(corporaData)\n",
    "    emotionDicts1 = getTop5000WordsByEmotion(corpus1Data, words, emotionLabels)\n",
    "    emotionDicts2 = getTop5000WordsByEmotion(corpus2Data, words, emotionLabels)\n",
    "    for emotion in range(len(emotionLabels)):\n",
    "        sim = getCosineSimilarityFromTokenFreq(emotionDicts1[emotion], emotionDicts2[emotion])\n",
    "        print(sim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "#averages the values the come from jensenshannon into a single value\n",
    "def getJensenShannonFromNPArrays(np1,np2):\n",
    "    js_pq = jensenshannon(np1, np2)\n",
    "    print(js_pq)\n",
    "    sumJS = 0\n",
    "    length = len(js_pq)\n",
    "    for x in js_pq:\n",
    "        if math.isnan(x): #assume nan values should be interpretted as 0\n",
    "            sumJS += 0\n",
    "        else:\n",
    "            sumJS += x\n",
    "    js = sumJS/length\n",
    "    return js"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def getChiSquare(observed,calculated):\n",
    "#     chiSquare = ((observed - calculated)**2)/calculated\n",
    "#     return chiSquare"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Calculates Chi Square, or at least it would have if I had finished implementing\n",
    "#see paper for details on why it was not implemented\n",
    "# def getChiSquareFromTokenFreq(tokenFreq1, tokenFreq2):\n",
    "# columnTotal1 = sum(tokenFreq1.values())\n",
    "# columnTotal2 = sum(tokenFreq2.values())\n",
    "# intersection = tokenFreq1.keys() & tokenFreq2.keys()\n",
    "# rowTotals = {key: tokenFreq1.get(key, 0) + tokenFreq2.get(key, 0)\n",
    "#           for key in set(dict1) | set(dict2)}\n",
    "# grandTotal = columnTotal1 + columnTotal2\n",
    "# chiSquareTotal = 0\n",
    "# calculated1 = []\n",
    "# calculated2 = []\n",
    "# for item, rowTotal in rowTotals.items():\n",
    "#     calculated1[item] = (rowTotal * columnTotal1) / grandTotal\n",
    "#     calculated2[item] = (rowTotal * columnTotal2) / grandTotal\n",
    "# for item, value in calculated.items():\n",
    "#     getChiSquare(observed,calculated[item])\n",
    "#     calculated[item]\n",
    "#     return js"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loaded data\n",
      "bag size 17756\n",
      "{'disgust', 'fear', 'sadness', 'anger', 'joy'}\n",
      "emotions\n",
      "7353\n",
      "6707\n",
      "8349\n",
      "8864\n",
      "6938\n",
      "emotions\n",
      "3401\n",
      "3118\n",
      "2523\n",
      "3339\n",
      "2527\n",
      "length 1 7353\n",
      "length 2 3401\n",
      "disgust 0.45165658636487677\n",
      "length 1 6707\n",
      "length 2 3118\n",
      "fear 0.43688992382789643\n",
      "length 1 8349\n",
      "length 2 2523\n",
      "sadness 0.4538342791036557\n",
      "length 1 8864\n",
      "length 2 3339\n",
      "anger 0.462297437783694\n",
      "length 1 6938\n",
      "length 2 2527\n",
      "joy 0.4439890786057688\n",
      "length 1 12661\n",
      "length 2 8888\n",
      "length 1 8888\n",
      "length 2 12661\n",
      "0.5107359175632199\n",
      "0.5107359175632199\n"
     ]
    }
   ],
   "source": [
    "#This is a validation of my corpus similarity metrics\n",
    "corpus1 = \"ssec\"\n",
    "corpus1Data = []\n",
    "corpus1Text = []\n",
    "corpus2 = \"isear\"\n",
    "corpus2Data = []\n",
    "corpus2Text = []\n",
    "with open(JSON) as f:\n",
    "    for line in f:\n",
    "        data = json.loads(line)\n",
    "        if data[\"source\"] == corpus1:\n",
    "            corpus1Text.append(tokenize(data[\"text\"]))\n",
    "            corpus1Data.append(data)\n",
    "        if data[\"source\"] == corpus2:\n",
    "            corpus2Text.append(tokenize(data[\"text\"]))\n",
    "            corpus2Data.append(data)\n",
    "print(\"loaded data\")\n",
    "combinedCorpus = corpus1Data + corpus2Data\n",
    "combinedCorpusText = corpus1Text + corpus2Text\n",
    "# tokenFreq = getTokenFrequency(corpus1Text)\n",
    "# print(\"tokenFreq\", tokenFreq)\n",
    "words = getTop5000Words(combinedCorpus)\n",
    "corporaData = [corpus1Data,corpus2Data]\n",
    "emotionLabels = list(getMatchingLabels(corporaData))\n",
    "emotions1 = getWordCountsByEmotion(corpus1Data, emotionLabels)\n",
    "# print(emotions1)\n",
    "emotions2 = getWordCountsByEmotion(corpus2Data, emotionLabels)\n",
    "# print(emotions2)\n",
    "for emotion in range(len(emotionLabels)):\n",
    "    sim = getCosineSimilarityFromTokenFreq(emotions1[emotion], emotions2[emotion])\n",
    "    print(emotionLabels[emotion], sim)\n",
    "fullCorpus1Words = getTokenFrequency(corpus1Text)\n",
    "fullCorpus2Words = getTokenFrequency(corpus2Text)\n",
    "sim1 = getCosineSimilarityFromTokenFreq(fullCorpus1Words, fullCorpus2Words)\n",
    "sim2 = getCosineSimilarityFromTokenFreq(fullCorpus2Words, fullCorpus1Words)\n",
    "print(sim1)\n",
    "print(sim2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# import gensim\n",
    "# import numpy as np\n",
    "# from nltk.tokenize import word_tokenize\n",
    "# print(corpus1Text[:5])\n",
    "# gen_docs = corpus1Text[:5]\n",
    "# dictionary = gensim.corpora.Dictionary(gen_docs)\n",
    "# # print(dictionary.token2id)\n",
    "# corpus = [dictionary.doc2bow(gen_doc) for gen_doc in gen_docs]\n",
    "# tf_idf = gensim.models.TfidfModel(corpus)\n",
    "# for doc in tf_idf [corpus]:\n",
    "#     print([[dictionary[id], np.around(freq, decimals=2)] for id, freq in doc])\n",
    "# sims = gensim.similarities.Similarity(\"../Ling506TermProject/\",tf_idf[corpus],\n",
    "#                                         num_features=len(dictionary))\n",
    "\n",
    "\n",
    "\n",
    "# file2_docs = [\"Mars is the fourth planet in our solar system.\",\n",
    "#         \"It is second-smallest planet in the Solar System after Mercury.\",\n",
    "#         \"Saturn is yellow planet.\"]\n",
    "# tf_idf = gensim.models.TfidfModel(corpus)\n",
    "\n",
    "# print(\"Number of documents:\",len(file2_docs))  \n",
    "# for line in file2_docs:\n",
    "#     query_doc = [w.lower() for w in word_tokenize(line)]\n",
    "#     query_doc_bow = dictionary.doc2bow(query_doc) #update an existing dictionary and create bag of words\n",
    "\n",
    "# # perform a similarity query against the corpus\n",
    "# query_doc_tf_idf = tf_idf[query_doc_bow]\n",
    "# # print(document_number, document_similarity)\n",
    "# print('Comparing Result:', sims[query_doc_tf_idf]) \n",
    "\n",
    "# sum_of_sims =(np.sum(sims[query_doc_tf_idf], dtype=np.float32))\n",
    "# print(sum_of_sims)\n",
    "\n",
    "# avg_sims = [] # array of averages\n",
    "\n",
    "\n",
    "# # for line in query documents\n",
    "# for line in file2_docs:\n",
    "#     # tokenize words\n",
    "#     query_doc = [w.lower() for w in word_tokenize(line)]\n",
    "#     # create bag of words\n",
    "#     query_doc_bow = dictionary.doc2bow(query_doc)\n",
    "#     # find similarity for each document\n",
    "#     query_doc_tf_idf = tf_idf[query_doc_bow]\n",
    "#     # print (document_number, document_similarity)\n",
    "#     print('Comparing Result:', sims[query_doc_tf_idf]) \n",
    "#     # calculate sum of similarities for each query doc\n",
    "#     sum_of_sims =(np.sum(sims[query_doc_tf_idf], dtype=np.float32))\n",
    "#     # calculate average of similarity for each query doc\n",
    "#     avg = sum_of_sims / len(file_docs)\n",
    "#     # print average of similarity for each query doc\n",
    "#     print(f'avg: {sum_of_sims / len(file_docs)}')\n",
    "#     # add average values into array\n",
    "#     avg_sims.append(avg)  \n",
    "# # calculate total average\n",
    "# total_avg = np.sum(avg_sims, dtype=np.float)\n",
    "# # round the value and multiply by 100 to format it as percentage\n",
    "# percentage_of_similarity = round(float(total_avg) * 100)\n",
    "# # if percentage is greater than 100\n",
    "# # that means documents are almost same\n",
    "# if percentage_of_similarity >= 100:\n",
    "#     percentage_of_similarity = 100\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 379,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Bad attempt at using prebuilt functions for distancing\n",
    "# arr1 = np.load(\"ssec_emotion-causetrain_xNP.npy\")\n",
    "# arr2 = np.load(\"ssec_grounded_emotionstrain_xNP.npy\")\n",
    "# arr3 = np.load(\"isear_ssectest_xNP.npy\")\n",
    "# corpus1 = \"ssec\"\n",
    "# corpus1Data = []\n",
    "# corpus1Text = []\n",
    "# corpus2 = \"isear\"\n",
    "# corpus2Data = []\n",
    "# corpus2Text = []\n",
    "# with open(JSON) as f:\n",
    "#     for line in f:\n",
    "#         data = json.loads(line)\n",
    "#         if data[\"source\"] == corpus1:\n",
    "#             corpus1Data.append(data)\n",
    "#         if data[\"source\"] == corpus2:\n",
    "#             corpus2Data.append(data)\n",
    "# print(\"loaded data\")\n",
    "# words1 = getTop5000Words(corpus1Data)\n",
    "# print(words1)\n",
    "# words2 = getTop5000Words(corpus2Data)\n",
    "# for data in tqdm(corpus1Data):\n",
    "#     corpus1Text.append(get_vector(data[\"text\"], words1))\n",
    "# for data in tqdm(corpus1Data):\n",
    "#     corpus2Text.append(get_vector(data[\"text\"], words2))\n",
    "# # print(corpus1Text[:30])\n",
    "# print(np.array_equal(arr1,arr2))\n",
    "# print(np.array_equal(arr1,arr3))\n",
    "# print(cosine_similarity(arr1,arr3))\n",
    "# print(chi2_kernel(arr1,arr3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#this method is modified to track \n",
    "def make_arrays(train, test, words, labels, mode=\"multi\", all_vs=False):\n",
    "    emotions = {label: x for x, label in enumerate(labels)}\n",
    "    print(\"emotions in make_arrays: \", emotions)\n",
    "    train_x, train_y, test_x, test_y = [], [], [], []\n",
    "    \n",
    "    print(\"train raw text: \", sys.getsizeof(train)/1000000)\n",
    "\n",
    "    for data in tqdm(train):\n",
    "        # Discard examples where we don't have all selected emotions\n",
    "        if (mode == \"single\" or all_vs or all(data[\"emotions\"][emo] is not None for emo in labels)):\n",
    "            train_y.append(get_emotion(data[\"emotions\"], labels, emotions, mode))\n",
    "            train_x.append(get_vector(data[\"text\"], words))\n",
    "    for data in tqdm(test):\n",
    "        test_y.append(get_emotion(data[\"emotions\"], labels, emotions, mode))\n",
    "        test_x.append(get_vector(data[\"text\"], words))\n",
    "\n",
    "    print(\"train_x length \", len(train_x))\n",
    "    print(\"train_x dimension of element \", len(train_x[0]))\n",
    "    train_xSize = sys.getsizeof(train_x)/1000000\n",
    "    train_ySize = sys.getsizeof(train_y)/1000000\n",
    "    train_xLength = len(train_x)\n",
    "    train_yLength = len(train_y)\n",
    "    print(\"train_x (text) size RAW:\", train_xSize,\"megabytes\")\n",
    "    print(\"train_y (labels) size RAW:\", train_ySize,\"megabytes\")\n",
    "    test_xSize = sys.getsizeof(test_x)/1000000\n",
    "    test_ySize = sys.getsizeof(test_y)/1000000\n",
    "    test_xLength = len(test_x)\n",
    "    test_yLength = len(test_y)\n",
    "    print(\"test_x (text) size RAW:\", test_xSize,\"megabytes\")\n",
    "    print(\"test_y (labels) size RAW:\", test_ySize,\"megabytes\")\n",
    "\n",
    "    train_x = np.array(train_x)\n",
    "    train_y = np.array(train_y)\n",
    "    test_x = np.array(test_x)\n",
    "    test_y = np.array(test_y)\n",
    "    train_xNPSize = (train_x.nbytes)/1000000\n",
    "    train_yNPSize = (train_y.nbytes)/1000000\n",
    "    test_xNPSize = (test_x.nbytes)/1000000\n",
    "    test_yNPSize = (test_y.nbytes)/1000000\n",
    "    \n",
    "    print(\"saved test_y\")\n",
    "    print(\"train_x Size stays the same\", train_xSize == train_xNPSize)\n",
    "    print(\"train_y Size stays the same\", train_ySize == train_yNPSize)\n",
    "    print(\"test_x Size stays the same\", test_xSize == test_xNPSize)\n",
    "    print(\"test_y Size stays the same\", test_ySize == test_yNPSize)\n",
    "    print(\"train_xNPSize (text) size:\", train_xNPSize,\"megabytes\")\n",
    "    print(\"train_yNPSize (labels) size:\", train_yNPSize,\"megabytes\")\n",
    "    print(\"test_xNPSize (text) size:\", test_xNPSize,\"megabytes\")\n",
    "    print(\"test_yNPSize (labels) size:\", test_yNPSize,\"megabytes\")\n",
    "    print(\"train_xNP length \", len(train_x))\n",
    "    print(\"train_xNP dimension of element \", train_x.ndim)\n",
    "    print(\"train_xNP size \", train_x.size)\n",
    "    sizes = train_xNPSize, train_yNPSize, test_xNPSize, test_yNPSize\n",
    "    return train_x, train_y, test_x, test_y, sizes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#kept as part of classification definitions, prevents division by 0 errors\n",
    "def cheatydiv(x, y):\n",
    "    return math.nan if y == 0 else x / y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#classification reporting is kept the same for simplicity (ie, no need to reinvent the wheel)\n",
    "def classification_report_own_single(test_y, predict_y, labels):\n",
    "    reports = {}\n",
    "    num2emo = {i: label for i, label in enumerate(labels)}\n",
    "    decisions = defaultdict(Counter)\n",
    "    for t, p in zip(test_y, predict_y):\n",
    "        decisions[t][p] += 1\n",
    "    for label in decisions:\n",
    "        tp = decisions[label][label]\n",
    "        fp = sum(decisions[x][label] for x in decisions if x != label)\n",
    "        tn = sum(\n",
    "            decisions[x][y]\n",
    "            for x in decisions\n",
    "            for y in decisions[x]\n",
    "            if x != label and y != label\n",
    "        )\n",
    "        fn = sum(decisions[label][y] for y in decisions[label] if y != label)\n",
    "        precision = tp / (tp + fp) if tp + fp else math.nan\n",
    "        recall = tp / (tp + fn) if tp + fn else math.nan\n",
    "        if y == 0:\n",
    "        f1 = 2 * cheatydiv((precision * recall), (precision + recall))\n",
    "        accuracy = (tp + tn) / (tp + tn + fp + fn)\n",
    "        reports[num2emo[label]] = Report(precision, recall, accuracy, f1, tp, tn, fp, fn)\n",
    "    return reports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#classification reporting is kept the same for simplicity (ie, no need to reinvent the wheel)\n",
    "def classification_report_own_multi(test_y, predict_y, labels):\n",
    "    reports = {}\n",
    "    num2emo = {i: label for i, label in enumerate(labels)}\n",
    "    emo2num = {label: i for i, label in enumerate(labels)}\n",
    "    decisions = defaultdict(Counter)\n",
    "    for label in labels:\n",
    "        tp = fp = tn = fn = 0\n",
    "        for t, p in zip(test_y, predict_y):\n",
    "            # decisions[t][p] += 1\n",
    "            tp += bool(t[emo2num[label]] and p[emo2num[label]])\n",
    "            fp += bool(p[emo2num[label]] and not t[emo2num[label]])\n",
    "            fn += bool(t[emo2num[label]] and not p[emo2num[label]])\n",
    "            tn += bool(not t[emo2num[label]] and not p[emo2num[label]])\n",
    "        precision = tp / (tp + fp) if tp + fp else math.nan\n",
    "        recall = tp / (tp + fn) if tp + fn else math.nan\n",
    "        f1 = 2 * cheatydiv((precision * recall), (precision + recall))\n",
    "        accuracy = (tp + tn) / (tp + tn + fp + fn)\n",
    "        reports[label] = Report(precision, recall, accuracy, f1, tp, tn, fp, fn)\n",
    "    return reports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "#classification reporting is kept the same for simplicity (ie, no need to reinvent the wheel)\n",
    "def analyse_results(test_y, predict_y, labels, test, first, second, output, mode):\n",
    "    print(\"analyse_results\")\n",
    "    prefix = f\"{first}_vs_{second}_{mode}\"\n",
    "    fprefix = output + \"/\" + prefix\n",
    "    with open(fprefix + \".txt\", \"w\", encoding=\"utf-8\") as f, open(fprefix + \".json\", \"w\") as g:\n",
    "        print(\"hello\")\n",
    "        prec, reca, f1, supp = precision_recall_fscore_support(\n",
    "            test_y, predict_y, pos_label=None, average=\"micro\"\n",
    "        )\n",
    "        accuracy = accuracy_score(test_y, predict_y)\n",
    "        scoreNameArray = [(prec, \"Precision\"),(reca, \"Recall\"),(f1, \"F1-score\"),(accuracy, \"Accuracy\")]\n",
    "        for score, name in scoreNameArray:\n",
    "            print(name, score, sep=\"\\t\", file=f)\n",
    "            print(name, score, sep=\"\\t\")\n",
    "            \n",
    "        # print(\"real:\", Counter(test_y), file=f)\n",
    "        # print(\"predicted:\", Counter(predict_y), file=f)\n",
    "        \n",
    "        print(test_y[:10], predict_y[:10], file=f)\n",
    "        emotions = {i: label for i, label in enumerate(labels)}\n",
    "        for text, real, predicted, _ in zip(test, test_y, predict_y, range(20)):\n",
    "            if mode == \"multi\" and np.array_equal(real, predicted):\n",
    "                continue\n",
    "            elif mode == \"single\" and real == predicted:\n",
    "                continue\n",
    "            print(text, \"=> predicted:\", predicted, \", truth:\", real, file=f)\n",
    "        if mode == \"multi\":\n",
    "            results = classification_report_own_multi(test_y, predict_y, labels)\n",
    "        elif mode == \"single\":\n",
    "            results = classification_report_own_single(test_y, predict_y, labels)\n",
    "        json.dump(\n",
    "            {\n",
    "                \"precision\": prec,\n",
    "                \"recall\": reca,\n",
    "                \"f1\": f1,\n",
    "                \"accuracy\": accuracy,\n",
    "                \"name\": prefix,\n",
    "                **{\n",
    "                    (emotion + \"_\" + metric): getattr(results[emotion], metric)\n",
    "                    for emotion in results\n",
    "                    for metric in Report._fields\n",
    "                },\n",
    "            },\n",
    "            g,\n",
    "        )\n",
    "        g.write(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "#used for benchmarking/validating the results of the authors, but not in the final version\n",
    "#method is kept here for documentation\n",
    "def hacky_train_test_split(training, train_size=0.8, first=None, second=None):\n",
    "    tra, tes = [], []\n",
    "    for example in training:\n",
    "        if example.get(\"split\") == \"train\" or example[\"source\"] != second:\n",
    "            tra.append(example)\n",
    "        elif example.get(\"split\") == \"test\":\n",
    "            tes.append(example)\n",
    "        else:\n",
    "            # don't try this at home\n",
    "            [tes, tra][random.random()<train_size].append(example)\n",
    "    return tra, tes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "#this method is used in my testing to generate the combinations that I use in my trials automation\n",
    "def getPowerset(s):\n",
    "    x = len(s)\n",
    "    masks = [1 << i for i in range(x)]\n",
    "    for i in range(1 << x):\n",
    "        yield [ss for mask, ss in zip(masks, s) if i & mask]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "#this method is used in my testing to generate the combinations that I use in my trials automation\n",
    "def getPermutations(s):\n",
    "    subsets = set()\n",
    "    for L in range(2, 3): #this \n",
    "        for subset in itertools.permutations(s, L):\n",
    "            subsets.add(subset)\n",
    "    return subsets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "#this method is simply in place to get a measure of hard drive space left on my computer\n",
    "def getHardDriveSpaceLeft():\n",
    "    total, used, free = shutil.disk_usage(\"/\")\n",
    "    total = (total // (2**30))\n",
    "    used = (used // (2**30))\n",
    "    free = (free // (2**30))\n",
    "    print(\"Total: %d GB\" % total)\n",
    "    print(\"Used: %d GB\" % used)\n",
    "    print(\"Free: %d GB\" % free)\n",
    "    return total, used, free"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "#gets the runtime values for cross corpus trials\n",
    "#ordering will matter if using the original authors version\n",
    "def getCrossCorpusValuesWithOrder(possibleChoices):\n",
    "    if orderingMatters:\n",
    "        permutations = list(getPermutations(possibleChoices))\n",
    "        print(\"permutations length: \",len(permutations))\n",
    "#         print(permutations)\n",
    "        corporaSets = []\n",
    "        for choice in permutations:\n",
    "    #         print(\"choice \", choice)\n",
    "            if(len(choice) == 2):\n",
    "    #             print(\"pair\")\n",
    "                first, second = choice\n",
    "                firstCorpus, domain1 = first\n",
    "                secondCorpus, domain2 = second\n",
    "            corpusPairData = (firstCorpus, secondCorpus, domain1, domain2)\n",
    "            corporaSets.append(corpusPairData)\n",
    "    return(corporaSets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This method adds the combinations relating to the ALl-VS trials\n",
    "def getAllVsCorpusValues(possibleChoices):\n",
    "    corporaSets = []\n",
    "    for entry in possibleChoices:\n",
    "        firstCorpus, domain1 = (None, None)\n",
    "        secondCorpus, domain2 = entry\n",
    "        corpusPairData = (firstCorpus, secondCorpus, domain1, domain2)\n",
    "        corporaSets.append(corpusPairData)\n",
    "    return corporaSets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Gets the corpora pairs of the same domain\n",
    "def getCorporaPairsOfSameDomain(powerSet, sizeBoundLower=1, sizeBoundUpper=3):\n",
    "    for entry in powerSet:\n",
    "#       if len(entry) < 3 and len(entry) > 0:\n",
    "        if len(entry) < sizeBoundUpper and len(entry) > sizeBoundLower:\n",
    "            domainMatch = entry[0][1]\n",
    "            shouldAppend = True\n",
    "            for corpus, domain in entry:\n",
    "                if domain != domainMatch:\n",
    "                    shouldAppend = False\n",
    "            if(shouldAppend):\n",
    "                powerSetCondensed.append(entry)\n",
    "    print(\"CorporaPairsOfSameDomain:\",len(powerSetCondensed))\n",
    "    return sameDomainCorporaPairs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "#this method adds the trials where the corpus is trained and tested on itself\n",
    "def getCorporaPairsWithItself(possibleChoices):\n",
    "    corporaSets = []\n",
    "    for entry in possibleChoices:\n",
    "        firstCorpus, domain1 = entry\n",
    "        secondCorpus, domain2 = entry\n",
    "        corpusPairData = (firstCorpus, secondCorpus, domain1, domain2)\n",
    "        corporaSets.append(corpusPairData)\n",
    "    return corporaSets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def performTrialUsingCorpusPair(corpusPair):\n",
    "    print(entry)\n",
    "    (first, second, domain1, domain2) = entry\n",
    "    print(\"Getting data\")\n",
    "    jsonfile = \"unified-dataset.jsonl\"\n",
    "    output = \".\"\n",
    "    debug = True\n",
    "    forceMulti = False\n",
    "    isAllVS = False\n",
    "    if first == None:\n",
    "        isAllVS = True\n",
    "\n",
    "    training_data, testing_data = get_train_test(jsonfile, first,second)\n",
    "    firstCLF, secondCLF = ([\"multi\", \"multi\"] if forceMulti else get_clf_mode(training_data, testing_data))\n",
    "    mode = \"multi\" if \"multi\" in [firstCLF, secondCLF] else \"single\"\n",
    "\n",
    "    print(\"Detected mode: {}...\".format(mode))\n",
    "    print(len(training_data), len(testing_data))\n",
    "    print(\"Getting wordlist...\")\n",
    "    if debug:\n",
    "        wordlist = getTop5000Words(training_data)\n",
    "    else:\n",
    "        wordlist = getTop5000Words(training_data)\n",
    "        # wordlist = get_wordlist(training_data)\n",
    "    print(\"Getting emotions\")\n",
    "    labels = get_labels(training_data, testing_data, mode=mode)\n",
    "    print(labels)\n",
    "    print(\"Making arrays\")\n",
    "    print(\"checking for save files\")\n",
    "    if(first == None):\n",
    "        first = \"all-vs\"\n",
    "    train_xNPFileName = first + \"_\" + second + \"train_xNP\" +\".npy\"\n",
    "    train_yNPFileName = first + \"_\" + second + \"train_yNP\" +\".npy\"\n",
    "    test_xNPFileName = first + \"_\" + second + \"test_xNP\" +\".npy\"\n",
    "    test_yNPFileName = first + \"_\" + second + \"test_yNP\" +\".npy\"\n",
    "\n",
    "    if(path.exists(train_xNPFileName) \n",
    "       and path.exists(train_yNPFileName)\n",
    "       and path.exists(test_xNPFileName)\n",
    "       and path.exists(test_yNPFileName)):\n",
    "        print('saved train_xNP as', train_xNPFileName)\n",
    "        print('saved train_yNP as', train_yNPFileName)\n",
    "        print('saved test_xNP as', test_xNPFileName)\n",
    "        print('saved test_yNP as', test_yNPFileName)\n",
    "        print(\"loading from np\")\n",
    "        train_x = np.load(train_xNPFileName)\n",
    "        train_y = np.load(train_yNPFileName)\n",
    "        test_x = np.load(test_xNPFileName)\n",
    "        test_y = np.load(test_yNPFileName)\n",
    "        train_xNPSize = (train_x.nbytes)/1000000\n",
    "        train_yNPSize = (train_y.nbytes)/1000000\n",
    "        test_xNPSize = (test_x.nbytes)/1000000\n",
    "        test_yNPSize = (test_y.nbytes)/1000000\n",
    "        print(\"loaded directly from NP.load\")\n",
    "        print(\"train_xNPSize (text) size loaded:\", train_xNPSize,\"megabytes\")\n",
    "        print(\"train_yNPSize (labels) size loaded:\", train_yNPSize,\"megabytes\")\n",
    "        print(\"test_xNPSize (text) size loaded:\", test_xNPSize,\"megabytes\")\n",
    "        print(\"test_yNPSize (labels) size loaded:\", test_yNPSize,\"megabytes\")\n",
    "    else:\n",
    "        train_x, train_y, test_x, test_y, sizes = make_arrays(training_data, testing_data, wordlist, labels, mode, isAllVS)\n",
    "        train_xSize, train_ySize, test_xSize, test_ySize = sizes\n",
    "        if any(not part.size for part in [train_x, train_y, test_x, test_y]):\n",
    "            print(\"Train or test empty. Did you misspell the dataset name?\")\n",
    "            continue\n",
    "        #             sys.exit(1)\n",
    "        print(\"saving NP arrays\")\n",
    "        np.save(train_xNPFileName, train_x)\n",
    "        np.save(train_yNPFileName, train_y)\n",
    "        np.save(test_xNPFileName, test_x)\n",
    "        np.save(test_yNPFileName, test_y)\n",
    "        print(\"NP arrays saved\")\n",
    "\n",
    "    print(\"Initializing classifier\")\n",
    "    trainClassifier = True\n",
    "    if debug:\n",
    "        classifierName = \"RandomForestClassifier\"\n",
    "        print(\"Searching for a \", classifierName)\n",
    "        classiferSaveFile = first+\"_\"+second+classifierName+\".pkl\"\n",
    "        print(path.exists(classiferSaveFile))\n",
    "        if(path.exists(classiferSaveFile)):\n",
    "            trainClassifier = False\n",
    "            print(\"Loading classifier from file\")\n",
    "            classifier = joblib.load(classiferSaveFile)\n",
    "            print(\"classifier loaded successfully\")\n",
    "        else:\n",
    "            print(\"file not found, creating new classifier\")\n",
    "            classifier = RandomForestClassifier()\n",
    "    elif mode == \"single\":\n",
    "        classifierName = \"LogisticRegressionCV\"\n",
    "        print(\"Searching for a \", classifierName)\n",
    "        classiferSaveFile = first+\"_\"+second+classifierName+\".pkl\"\n",
    "        print(path.exists(classiferSaveFile))\n",
    "        if(path.exists(classiferSaveFile)):\n",
    "            trainClassifier = False\n",
    "            print(\"Loading classifier from file\")\n",
    "            classifier = joblib.load(classiferSaveFile)\n",
    "            print(\"classifier loaded successfully\")\n",
    "        else:\n",
    "            print(\"file not found, creating new classifier\")\n",
    "            classifier = LogisticRegressionCV(\n",
    "                cv=10,\n",
    "                penalty=\"l2\",\n",
    "                fit_intercept=True,\n",
    "                solver=\"sag\",\n",
    "                scoring=\"f1\",\n",
    "                refit=True,\n",
    "                # n_jobs=-1,\n",
    "                class_weight=\"balanced\",\n",
    "            )\n",
    "    else:\n",
    "        classifierName = \"OneVsRestClassifier\"\n",
    "        print(\"Searching for a \", classifierName)\n",
    "        classiferSaveFile = first+\"_\"+second+classifierName+\".pkl\"\n",
    "        print(path.exists(classiferSaveFile))\n",
    "        if(path.exists(classiferSaveFile)):\n",
    "            trainClassifier = False\n",
    "            print(\"Loading classifier from file\")\n",
    "            classifier = joblib.load(classiferSaveFile)\n",
    "            print(\"classifier loaded successfully\")\n",
    "        else:\n",
    "            print(\"file not found, creating new classifier\")\n",
    "            classifier = OneVsRestClassifier(\n",
    "                LogisticRegressionCV(\n",
    "                    cv=10,\n",
    "                    penalty=\"l2\",\n",
    "                    fit_intercept=True,\n",
    "                    solver=\"sag\",\n",
    "                    scoring=\"f1\",\n",
    "                    refit=True,\n",
    "                    class_weight=\"balanced\",\n",
    "                    tol = 0.1,\n",
    "                ),\n",
    "                n_jobs=-1,\n",
    "            )\n",
    "    if(trainClassifier):\n",
    "        print(\"this is the classifierName: \", classifierName)\n",
    "        print(\"Training...\")\n",
    "        print(\"train_x (text) size:\", (train_x.nbytes)/1000000,\"megabytes\")\n",
    "        print(\"train_y (labels) size:\", (train_y.nbytes)/1000000,\"megabytes\")\n",
    "        print(\"train_x (text) length:\", len(train_x))\n",
    "        print(\"train_y (labels) length:\", len(train_y))\n",
    "        print(train_x[:5])\n",
    "        print(train_y[:5])\n",
    "\n",
    "        classifier.fit(train_x, train_y)\n",
    "        print(\"finished training, classifier size:\", sys.getsizeof(classifier)/1000000,\"megabytes\")\n",
    "    print(\"Predicting...\")\n",
    "    if first == \"multi\" and second == \"single\":\n",
    "        predict_y = classifier.predict_proba(test_x)\n",
    "        helper = np.zeros_like(predict_y)\n",
    "        helper[range(len(predict_y)), predict_y.argmax(1)] = 1\n",
    "        predict_y = helper\n",
    "    else:\n",
    "        predict_y = classifier.predict(test_x)\n",
    "\n",
    "    print(\"Analysing...\")\n",
    "\n",
    "    analyse_results(\n",
    "        test_y,\n",
    "        predict_y,\n",
    "        labels,\n",
    "        testing_data,\n",
    "        first,\n",
    "        second,\n",
    "        output,\n",
    "        mode,  # TODO\n",
    "    )\n",
    "    if(path.exists(classiferSaveFile)):\n",
    "        print(\"classifier already saved\")\n",
    "    else:\n",
    "#         classiferSaveFile = first+\"_\"+second+classifierName+\".pkl\"\n",
    "        print(\"classiferSaveFile: \", classiferSaveFile)\n",
    "        joblib.dump(classifier, classiferSaveFile)\n",
    "        print(\"Saved Successfully\")\n",
    "    total, used, free = getHardDriveSpaceLeft()\n",
    "    if(free < 10):\n",
    "        sys.exit(\"Error: less than 10 gb remaining on disk\")\n",
    "    print(\"-----------------------------------------------------------------------------------------\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def runTrials(version, crossCorpus=True, sameCorpus=True, allVs=False):\n",
    "    possibleChoices = [('affectivetext','headlines'), ('crowdflower','tweets'), ('dailydialog','conversations'), \n",
    "                       ('emobank','headlines'), ('emoint','tweets'), \n",
    "                       ('emotion-cause','paragraphs'), ('grounded_emotions','tweets'), ('isear','descriptions'),\n",
    "                       ('ssec','tweets'),('tales-emotion','tales'), ('tec','tweets')]\n",
    "    corporaSets = []\n",
    "    if version == \"previous\":\n",
    "        corporaSets.append(getCrossCorpusValuesWithOrder(possibleChoices))\n",
    "        sortedPermutations = sorted(corporaSets, key = lambda x: (x[2], x[0], x[1]), reverse = True)\n",
    "        sortedPermutations.append(getCorporaPairsWithItself(possibleChoices))\n",
    "        sortedPermutations.append(getAllVsCorpusValues(possibleChoices))\n",
    "        return sortedPermutations\n",
    "        #this was added to sort the lists by domain of the first, then by the first corpus name, then the second.\n",
    "        #it is placed in reverse order simply because if it was put in regular order, the largest of the trials would be first\n",
    "        #sorting in reverse will (loosely) make the smaller trials run first, while having no impact on the ability to obtain all results\n",
    "        sortedPermutations = sorted(corporaSets, key = lambda x: (x[2], x[0], x[1]), reverse = True)\n",
    "        for corpusPair in sortedPermutations:\n",
    "            performTrialUsingCorpusPair(corpusPair)\n",
    "    else: #version == \"my trials\"\n",
    "        \n",
    "    \n",
    "    print(\"End of program!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "permutations length:  110\n",
      "('tec', 'tales-emotion', 'tweets', 'tales')\n",
      "('tec', 'ssec', 'tweets', 'tweets')\n",
      "('tec', 'isear', 'tweets', 'descriptions')\n",
      "('tec', 'grounded_emotions', 'tweets', 'tweets')\n",
      "('tec', 'emotion-cause', 'tweets', 'paragraphs')\n",
      "('tec', 'emoint', 'tweets', 'tweets')\n",
      "('tec', 'emobank', 'tweets', 'headlines')\n",
      "('tec', 'dailydialog', 'tweets', 'conversations')\n",
      "('tec', 'crowdflower', 'tweets', 'tweets')\n",
      "('tec', 'affectivetext', 'tweets', 'headlines')\n",
      "('ssec', 'tec', 'tweets', 'tweets')\n",
      "('ssec', 'tales-emotion', 'tweets', 'tales')\n",
      "('ssec', 'isear', 'tweets', 'descriptions')\n",
      "('ssec', 'grounded_emotions', 'tweets', 'tweets')\n",
      "('ssec', 'emotion-cause', 'tweets', 'paragraphs')\n",
      "('ssec', 'emoint', 'tweets', 'tweets')\n",
      "('ssec', 'emobank', 'tweets', 'headlines')\n",
      "('ssec', 'dailydialog', 'tweets', 'conversations')\n",
      "('ssec', 'crowdflower', 'tweets', 'tweets')\n",
      "('ssec', 'affectivetext', 'tweets', 'headlines')\n",
      "('grounded_emotions', 'tec', 'tweets', 'tweets')\n",
      "('grounded_emotions', 'tales-emotion', 'tweets', 'tales')\n",
      "('grounded_emotions', 'ssec', 'tweets', 'tweets')\n",
      "('grounded_emotions', 'isear', 'tweets', 'descriptions')\n",
      "('grounded_emotions', 'emotion-cause', 'tweets', 'paragraphs')\n",
      "('grounded_emotions', 'emoint', 'tweets', 'tweets')\n",
      "('grounded_emotions', 'emobank', 'tweets', 'headlines')\n",
      "('grounded_emotions', 'dailydialog', 'tweets', 'conversations')\n",
      "('grounded_emotions', 'crowdflower', 'tweets', 'tweets')\n",
      "('grounded_emotions', 'affectivetext', 'tweets', 'headlines')\n",
      "('emoint', 'tec', 'tweets', 'tweets')\n",
      "('emoint', 'tales-emotion', 'tweets', 'tales')\n",
      "('emoint', 'ssec', 'tweets', 'tweets')\n",
      "('emoint', 'isear', 'tweets', 'descriptions')\n",
      "('emoint', 'grounded_emotions', 'tweets', 'tweets')\n",
      "('emoint', 'emotion-cause', 'tweets', 'paragraphs')\n",
      "('emoint', 'emobank', 'tweets', 'headlines')\n",
      "('emoint', 'dailydialog', 'tweets', 'conversations')\n",
      "('emoint', 'crowdflower', 'tweets', 'tweets')\n",
      "('emoint', 'affectivetext', 'tweets', 'headlines')\n",
      "('crowdflower', 'tec', 'tweets', 'tweets')\n",
      "('crowdflower', 'tales-emotion', 'tweets', 'tales')\n",
      "('crowdflower', 'ssec', 'tweets', 'tweets')\n",
      "('crowdflower', 'isear', 'tweets', 'descriptions')\n",
      "('crowdflower', 'grounded_emotions', 'tweets', 'tweets')\n",
      "('crowdflower', 'emotion-cause', 'tweets', 'paragraphs')\n",
      "('crowdflower', 'emoint', 'tweets', 'tweets')\n",
      "('crowdflower', 'emobank', 'tweets', 'headlines')\n",
      "('crowdflower', 'dailydialog', 'tweets', 'conversations')\n",
      "('crowdflower', 'affectivetext', 'tweets', 'headlines')\n",
      "('tales-emotion', 'tec', 'tales', 'tweets')\n",
      "('tales-emotion', 'ssec', 'tales', 'tweets')\n",
      "('tales-emotion', 'isear', 'tales', 'descriptions')\n",
      "('tales-emotion', 'grounded_emotions', 'tales', 'tweets')\n",
      "('tales-emotion', 'emotion-cause', 'tales', 'paragraphs')\n",
      "('tales-emotion', 'emoint', 'tales', 'tweets')\n",
      "('tales-emotion', 'emobank', 'tales', 'headlines')\n",
      "('tales-emotion', 'dailydialog', 'tales', 'conversations')\n",
      "('tales-emotion', 'crowdflower', 'tales', 'tweets')\n",
      "('tales-emotion', 'affectivetext', 'tales', 'headlines')\n",
      "('emotion-cause', 'tec', 'paragraphs', 'tweets')\n",
      "('emotion-cause', 'tales-emotion', 'paragraphs', 'tales')\n",
      "('emotion-cause', 'ssec', 'paragraphs', 'tweets')\n",
      "('emotion-cause', 'isear', 'paragraphs', 'descriptions')\n",
      "('emotion-cause', 'grounded_emotions', 'paragraphs', 'tweets')\n",
      "('emotion-cause', 'emoint', 'paragraphs', 'tweets')\n",
      "('emotion-cause', 'emobank', 'paragraphs', 'headlines')\n",
      "('emotion-cause', 'dailydialog', 'paragraphs', 'conversations')\n",
      "('emotion-cause', 'crowdflower', 'paragraphs', 'tweets')\n",
      "('emotion-cause', 'affectivetext', 'paragraphs', 'headlines')\n",
      "('emobank', 'tec', 'headlines', 'tweets')\n",
      "('emobank', 'tales-emotion', 'headlines', 'tales')\n",
      "('emobank', 'ssec', 'headlines', 'tweets')\n",
      "('emobank', 'isear', 'headlines', 'descriptions')\n",
      "('emobank', 'grounded_emotions', 'headlines', 'tweets')\n",
      "('emobank', 'emotion-cause', 'headlines', 'paragraphs')\n",
      "('emobank', 'emoint', 'headlines', 'tweets')\n",
      "('emobank', 'dailydialog', 'headlines', 'conversations')\n",
      "('emobank', 'crowdflower', 'headlines', 'tweets')\n",
      "('emobank', 'affectivetext', 'headlines', 'headlines')\n",
      "('affectivetext', 'tec', 'headlines', 'tweets')\n",
      "('affectivetext', 'tales-emotion', 'headlines', 'tales')\n",
      "('affectivetext', 'ssec', 'headlines', 'tweets')\n",
      "('affectivetext', 'isear', 'headlines', 'descriptions')\n",
      "('affectivetext', 'grounded_emotions', 'headlines', 'tweets')\n",
      "('affectivetext', 'emotion-cause', 'headlines', 'paragraphs')\n",
      "('affectivetext', 'emoint', 'headlines', 'tweets')\n",
      "('affectivetext', 'emobank', 'headlines', 'headlines')\n",
      "('affectivetext', 'dailydialog', 'headlines', 'conversations')\n",
      "('affectivetext', 'crowdflower', 'headlines', 'tweets')\n",
      "('isear', 'tec', 'descriptions', 'tweets')\n",
      "('isear', 'tales-emotion', 'descriptions', 'tales')\n",
      "('isear', 'ssec', 'descriptions', 'tweets')\n",
      "('isear', 'grounded_emotions', 'descriptions', 'tweets')\n",
      "('isear', 'emotion-cause', 'descriptions', 'paragraphs')\n",
      "('isear', 'emoint', 'descriptions', 'tweets')\n",
      "('isear', 'emobank', 'descriptions', 'headlines')\n",
      "('isear', 'dailydialog', 'descriptions', 'conversations')\n",
      "('isear', 'crowdflower', 'descriptions', 'tweets')\n",
      "('isear', 'affectivetext', 'descriptions', 'headlines')\n",
      "('dailydialog', 'tec', 'conversations', 'tweets')\n",
      "('dailydialog', 'tales-emotion', 'conversations', 'tales')\n",
      "('dailydialog', 'ssec', 'conversations', 'tweets')\n",
      "('dailydialog', 'isear', 'conversations', 'descriptions')\n",
      "('dailydialog', 'grounded_emotions', 'conversations', 'tweets')\n",
      "('dailydialog', 'emotion-cause', 'conversations', 'paragraphs')\n",
      "('dailydialog', 'emoint', 'conversations', 'tweets')\n",
      "('dailydialog', 'emobank', 'conversations', 'headlines')\n",
      "('dailydialog', 'crowdflower', 'conversations', 'tweets')\n",
      "('dailydialog', 'affectivetext', 'conversations', 'headlines')\n",
      "('affectivetext', 'affectivetext', 'headlines', 'headlines')\n",
      "('crowdflower', 'crowdflower', 'tweets', 'tweets')\n",
      "('dailydialog', 'dailydialog', 'conversations', 'conversations')\n",
      "('emobank', 'emobank', 'headlines', 'headlines')\n",
      "('emoint', 'emoint', 'tweets', 'tweets')\n",
      "('emotion-cause', 'emotion-cause', 'paragraphs', 'paragraphs')\n",
      "('grounded_emotions', 'grounded_emotions', 'tweets', 'tweets')\n",
      "('isear', 'isear', 'descriptions', 'descriptions')\n",
      "('ssec', 'ssec', 'tweets', 'tweets')\n",
      "('tales-emotion', 'tales-emotion', 'tales', 'tales')\n",
      "('tec', 'tec', 'tweets', 'tweets')\n",
      "(None, 'affectivetext', None, 'headlines')\n",
      "(None, 'crowdflower', None, 'tweets')\n",
      "(None, 'dailydialog', None, 'conversations')\n",
      "(None, 'emobank', None, 'headlines')\n",
      "(None, 'emoint', None, 'tweets')\n",
      "(None, 'emotion-cause', None, 'paragraphs')\n",
      "(None, 'grounded_emotions', None, 'tweets')\n",
      "(None, 'isear', None, 'descriptions')\n",
      "(None, 'ssec', None, 'tweets')\n",
      "(None, 'tales-emotion', None, 'tales')\n",
      "(None, 'tec', None, 'tweets')\n",
      "('tec', 'tales-emotion', 'tweets', 'tales')\n",
      "Getting data\n",
      "get_train_test param:\n",
      "json  unified-dataset.jsonl\n",
      "train  tec\n",
      "test  tales-emotion\n",
      "there were  14771  entries that were in test and  206668 that were not in test and  21051  that were in train\n",
      "test was appended  14771  times\n",
      "single\n",
      "oof\n",
      "Detected mode: single...\n",
      "21051 14771\n",
      "Getting wordlist...\n",
      "Getting emotions\n",
      "['anger', 'joy', 'noemo', 'surprise', 'disgust', 'sadness', 'fear']\n",
      "Making arrays\n",
      "checking for save files\n",
      "saved train_xNP as tec_tales-emotiontrain_xNP.npy\n",
      "saved train_yNP as tec_tales-emotiontrain_yNP.npy\n",
      "saved test_xNP as tec_tales-emotiontest_xNP.npy\n",
      "saved test_yNP as tec_tales-emotiontest_yNP.npy\n",
      "loading from np\n",
      "loaded directly from NP.load\n",
      "train_xNPSize (text) size loaded: 421.02 megabytes\n",
      "train_yNPSize (labels) size loaded: 0.084204 megabytes\n",
      "test_xNPSize (text) size loaded: 295.42 megabytes\n",
      "test_yNPSize (labels) size loaded: 0.059084 megabytes\n",
      "Initializing classifier\n",
      "Searching for a  RandomForestClassifier\n",
      "True\n",
      "Loading classifier from file\n",
      "classifier loaded successfully\n",
      "Predicting...\n",
      "Analysing...\n",
      "analyse_results\n",
      "hello\n",
      "Precision\t0.12659941777807868\n",
      "Recall\t0.12659941777807868\n",
      "F1-score\t0.12659941777807868\n",
      "Accuracy\t0.12659941777807868\n",
      "classifier already saved\n",
      "Total: 475 GiB\n",
      "Used: 295 GiB\n",
      "Free: 179 GiB\n",
      "-----------------------------------------------------------------------------------------\n",
      "('tec', 'ssec', 'tweets', 'tweets')\n",
      "Getting data\n",
      "get_train_test param:\n",
      "json  unified-dataset.jsonl\n",
      "train  tec\n",
      "test  ssec\n",
      "there were  4868  entries that were in test and  216571 that were not in test and  21051  that were in train\n",
      "test was appended  4868  times\n",
      "single\n",
      "Detected mode: multi...\n",
      "21051 4868\n",
      "Getting wordlist...\n",
      "Getting emotions\n",
      "['anger', 'joy', 'surprise', 'disgust', 'sadness', 'fear']\n",
      "Making arrays\n",
      "checking for save files\n",
      "saved train_xNP as tec_ssectrain_xNP.npy\n",
      "saved train_yNP as tec_ssectrain_yNP.npy\n",
      "saved test_xNP as tec_ssectest_xNP.npy\n",
      "saved test_yNP as tec_ssectest_yNP.npy\n",
      "loading from np\n",
      "loaded directly from NP.load\n",
      "train_xNPSize (text) size loaded: 421.02 megabytes\n",
      "train_yNPSize (labels) size loaded: 0.505224 megabytes\n",
      "test_xNPSize (text) size loaded: 97.36 megabytes\n",
      "test_yNPSize (labels) size loaded: 0.116832 megabytes\n",
      "Initializing classifier\n",
      "Searching for a  RandomForestClassifier\n",
      "True\n",
      "Loading classifier from file\n",
      "classifier loaded successfully\n",
      "Predicting...\n",
      "Analysing...\n",
      "analyse_results\n",
      "hello\n",
      "Precision\t0.5476020042949177\n",
      "Recall\t0.06002824858757062\n",
      "F1-score\t0.10819602574075385\n",
      "Accuracy\t0.09654889071487263\n",
      "classifier already saved\n",
      "Total: 475 GiB\n",
      "Used: 295 GiB\n",
      "Free: 179 GiB\n",
      "-----------------------------------------------------------------------------------------\n",
      "('tec', 'isear', 'tweets', 'descriptions')\n",
      "Getting data\n",
      "get_train_test param:\n",
      "json  unified-dataset.jsonl\n",
      "train  tec\n",
      "test  isear\n",
      "there were  7666  entries that were in test and  213773 that were not in test and  21051  that were in train\n",
      "test was appended  7666  times\n",
      "single\n",
      "oof\n",
      "Detected mode: single...\n",
      "21051 7666\n",
      "Getting wordlist...\n",
      "Getting emotions\n",
      "['anger', 'joy', 'noemo', 'disgust', 'sadness', 'fear']\n",
      "Making arrays\n",
      "checking for save files\n",
      "saved train_xNP as tec_iseartrain_xNP.npy\n",
      "saved train_yNP as tec_iseartrain_yNP.npy\n",
      "saved test_xNP as tec_iseartest_xNP.npy\n",
      "saved test_yNP as tec_iseartest_yNP.npy\n",
      "loading from np\n",
      "loaded directly from NP.load\n",
      "train_xNPSize (text) size loaded: 421.02 megabytes\n",
      "train_yNPSize (labels) size loaded: 0.084204 megabytes\n",
      "test_xNPSize (text) size loaded: 153.32 megabytes\n",
      "test_yNPSize (labels) size loaded: 0.030664 megabytes\n",
      "Initializing classifier\n",
      "Searching for a  RandomForestClassifier\n",
      "True\n",
      "Loading classifier from file\n",
      "classifier loaded successfully\n",
      "Predicting...\n",
      "Analysing...\n",
      "analyse_results\n",
      "hello\n",
      "Precision\t0.24002087138012002\n",
      "Recall\t0.24002087138012002\n",
      "F1-score\t0.24002087138012002\n",
      "Accuracy\t0.24002087138012002\n",
      "classifier already saved\n",
      "Total: 475 GiB\n",
      "Used: 295 GiB\n",
      "Free: 179 GiB\n",
      "-----------------------------------------------------------------------------------------\n",
      "('tec', 'grounded_emotions', 'tweets', 'tweets')\n",
      "Getting data\n",
      "get_train_test param:\n",
      "json  unified-dataset.jsonl\n",
      "train  tec\n",
      "test  grounded_emotions\n",
      "there were  2585  entries that were in test and  218854 that were not in test and  21051  that were in train\n",
      "test was appended  2585  times\n",
      "single\n",
      "oof\n",
      "Detected mode: single...\n",
      "21051 2585\n",
      "Getting wordlist...\n",
      "Getting emotions\n",
      "['joy', 'noemo', 'sadness']\n",
      "Making arrays\n",
      "checking for save files\n",
      "saved train_xNP as tec_grounded_emotionstrain_xNP.npy\n",
      "saved train_yNP as tec_grounded_emotionstrain_yNP.npy\n",
      "saved test_xNP as tec_grounded_emotionstest_xNP.npy\n",
      "saved test_yNP as tec_grounded_emotionstest_yNP.npy\n",
      "loading from np\n",
      "loaded directly from NP.load\n",
      "train_xNPSize (text) size loaded: 421.02 megabytes\n",
      "train_yNPSize (labels) size loaded: 0.084204 megabytes\n",
      "test_xNPSize (text) size loaded: 51.7 megabytes\n",
      "test_yNPSize (labels) size loaded: 0.01034 megabytes\n",
      "Initializing classifier\n",
      "Searching for a  RandomForestClassifier\n",
      "True\n",
      "Loading classifier from file\n",
      "classifier loaded successfully\n",
      "Predicting...\n",
      "Analysing...\n",
      "analyse_results\n",
      "hello\n",
      "Precision\t0.13152804642166344\n",
      "Recall\t0.13152804642166344\n",
      "F1-score\t0.13152804642166344\n",
      "Accuracy\t0.13152804642166344\n",
      "classifier already saved\n",
      "Total: 475 GiB\n",
      "Used: 295 GiB\n",
      "Free: 179 GiB\n",
      "-----------------------------------------------------------------------------------------\n",
      "('tec', 'emotion-cause', 'tweets', 'paragraphs')\n",
      "Getting data\n",
      "get_train_test param:\n",
      "json  unified-dataset.jsonl\n",
      "train  tec\n",
      "test  emotion-cause\n",
      "there were  2414  entries that were in test and  219025 that were not in test and  21051  that were in train\n",
      "test was appended  2414  times\n",
      "single\n",
      "oof\n",
      "Detected mode: single...\n",
      "21051 2414\n",
      "Getting wordlist...\n",
      "Getting emotions\n",
      "['anger', 'joy', 'noemo', 'surprise', 'disgust', 'sadness', 'fear']\n",
      "Making arrays\n",
      "checking for save files\n",
      "saved train_xNP as tec_emotion-causetrain_xNP.npy\n",
      "saved train_yNP as tec_emotion-causetrain_yNP.npy\n",
      "saved test_xNP as tec_emotion-causetest_xNP.npy\n",
      "saved test_yNP as tec_emotion-causetest_yNP.npy\n",
      "loading from np\n",
      "loaded directly from NP.load\n",
      "train_xNPSize (text) size loaded: 421.02 megabytes\n",
      "train_yNPSize (labels) size loaded: 0.084204 megabytes\n",
      "test_xNPSize (text) size loaded: 48.28 megabytes\n",
      "test_yNPSize (labels) size loaded: 0.009656 megabytes\n",
      "Initializing classifier\n",
      "Searching for a  RandomForestClassifier\n",
      "True\n",
      "Loading classifier from file\n",
      "classifier loaded successfully\n",
      "Predicting...\n",
      "Analysing...\n",
      "analyse_results\n",
      "hello\n",
      "Precision\t0.24026512013256007\n",
      "Recall\t0.24026512013256007\n",
      "F1-score\t0.24026512013256007\n",
      "Accuracy\t0.24026512013256007\n",
      "classifier already saved\n",
      "Total: 475 GiB\n",
      "Used: 295 GiB\n",
      "Free: 179 GiB\n",
      "-----------------------------------------------------------------------------------------\n",
      "('tec', 'emoint', 'tweets', 'tweets')\n",
      "Getting data\n",
      "get_train_test param:\n",
      "json  unified-dataset.jsonl\n",
      "train  tec\n",
      "test  emoint\n",
      "there were  7102  entries that were in test and  214337 that were not in test and  21051  that were in train\n",
      "test was appended  7102  times\n",
      "single\n",
      "oof\n",
      "Detected mode: single...\n",
      "21051 7102\n",
      "Getting wordlist...\n",
      "Getting emotions\n",
      "['anger', 'joy', 'noemo', 'sadness', 'fear']\n",
      "Making arrays\n",
      "checking for save files\n",
      "saved train_xNP as tec_emointtrain_xNP.npy\n",
      "saved train_yNP as tec_emointtrain_yNP.npy\n",
      "saved test_xNP as tec_emointtest_xNP.npy\n",
      "saved test_yNP as tec_emointtest_yNP.npy\n",
      "loading from np\n",
      "loaded directly from NP.load\n",
      "train_xNPSize (text) size loaded: 421.02 megabytes\n",
      "train_yNPSize (labels) size loaded: 0.084204 megabytes\n",
      "test_xNPSize (text) size loaded: 142.04 megabytes\n",
      "test_yNPSize (labels) size loaded: 0.028408 megabytes\n",
      "Initializing classifier\n",
      "Searching for a  RandomForestClassifier\n",
      "True\n",
      "Loading classifier from file\n",
      "classifier loaded successfully\n",
      "Predicting...\n",
      "Analysing...\n",
      "analyse_results\n",
      "hello\n",
      "Precision\t0.2682343001971276\n",
      "Recall\t0.2682343001971276\n",
      "F1-score\t0.2682343001971276\n",
      "Accuracy\t0.2682343001971276\n",
      "classifier already saved\n",
      "Total: 475 GiB\n",
      "Used: 295 GiB\n",
      "Free: 179 GiB\n",
      "-----------------------------------------------------------------------------------------\n",
      "('tec', 'emobank', 'tweets', 'headlines')\n",
      "Getting data\n",
      "get_train_test param:\n",
      "json  unified-dataset.jsonl\n",
      "train  tec\n",
      "test  emobank\n",
      "there were  10062  entries that were in test and  211377 that were not in test and  21051  that were in train\n",
      "test was appended  10062  times\n",
      "single\n",
      "Detected mode: multi...\n",
      "21051 10062\n",
      "Getting wordlist...\n",
      "Getting emotions\n",
      "[]\n",
      "Making arrays\n",
      "checking for save files\n",
      "emotions in make_arrays:  {}\n",
      "train super raw:  0.178016\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████| 21051/21051 [00:08<00:00, 2627.20it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████| 10062/10062 [00:04<00:00, 2169.32it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_x length  21051\n",
      "train_x dimension of element  5000\n",
      "train_x (text) size RAW: 0.178016 megabytes\n",
      "train_y (labels) size RAW: 0.178016 megabytes\n",
      "test_x (text) size RAW: 0.087616 megabytes\n",
      "test_y (labels) size RAW: 0.087616 megabytes\n",
      "saved test_y\n",
      "train_x Size stays the same False\n",
      "train_y Size stays the same False\n",
      "test_x Size stays the same False\n",
      "test_y Size stays the same False\n",
      "train_xNPSize (text) size: 421.02 megabytes\n",
      "train_yNPSize (labels) size: 0.0 megabytes\n",
      "test_xNPSize (text) size: 201.24 megabytes\n",
      "test_yNPSize (labels) size: 0.0 megabytes\n",
      "train_xNP length  21051\n",
      "train_xNP dimension of element  2\n",
      "train_xNP size  105255000\n",
      "Train or test empty. Did you misspell the dataset name?\n",
      "('tec', 'dailydialog', 'tweets', 'conversations')\n",
      "Getting data\n",
      "get_train_test param:\n",
      "json  unified-dataset.jsonl\n",
      "train  tec\n",
      "test  dailydialog\n",
      "there were  102979  entries that were in test and  118460 that were not in test and  21051  that were in train\n",
      "test was appended  102979  times\n",
      "single\n",
      "oof\n",
      "Detected mode: single...\n",
      "21051 102979\n",
      "Getting wordlist...\n",
      "Getting emotions\n",
      "['anger', 'joy', 'noemo', 'surprise', 'disgust', 'sadness', 'fear']\n",
      "Making arrays\n",
      "checking for save files\n",
      "emotions in make_arrays:  {'anger': 0, 'joy': 1, 'noemo': 2, 'surprise': 3, 'disgust': 4, 'sadness': 5, 'fear': 6}\n",
      "train super raw:  0.178016\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████| 21051/21051 [00:07<00:00, 2726.93it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████| 102979/102979 [00:45<00:00, 2248.01it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_x length  21051\n",
      "train_x dimension of element  5000\n",
      "train_x (text) size RAW: 0.178016 megabytes\n",
      "train_y (labels) size RAW: 0.178016 megabytes\n",
      "test_x (text) size RAW: 0.824456 megabytes\n",
      "test_y (labels) size RAW: 0.824456 megabytes\n",
      "saved test_y\n",
      "train_x Size stays the same False\n",
      "train_y Size stays the same False\n",
      "test_x Size stays the same False\n",
      "test_y Size stays the same False\n",
      "train_xNPSize (text) size: 421.02 megabytes\n",
      "train_yNPSize (labels) size: 0.084204 megabytes\n",
      "test_xNPSize (text) size: 2059.58 megabytes\n",
      "test_yNPSize (labels) size: 0.411916 megabytes\n",
      "train_xNP length  21051\n",
      "train_xNP dimension of element  2\n",
      "train_xNP size  105255000\n",
      "saving NP arrays\n",
      "NP arrays saved\n",
      "Initializing classifier\n",
      "Searching for a  RandomForestClassifier\n",
      "False\n",
      "file not found, creating new classifier\n",
      "this is the classifierName:  RandomForestClassifier\n",
      "Training...\n",
      "train_x (text) size: 421.02 megabytes\n",
      "train_y (labels) size: 0.084204 megabytes\n",
      "train_x (text) length: 21051\n",
      "train_y (labels) length: 21051\n",
      "[[0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 1 0 ... 0 0 0]\n",
      " [0 1 0 ... 0 0 0]\n",
      " [0 1 1 ... 0 0 0]]\n",
      "[3 5 1 1 4]\n",
      "finished training, classifier size: 4.8e-05 megabytes\n",
      "Predicting...\n",
      "Analysing...\n",
      "analyse_results\n",
      "hello\n",
      "Precision\t0.10104972858543974\n",
      "Recall\t0.10104972858543974\n",
      "F1-score\t0.10104972858543974\n",
      "Accuracy\t0.10104972858543974\n",
      "classiferSaveFile:  tec_dailydialogRandomForestClassifier.pkl\n",
      "Saved Successfully\n",
      "Total: 475 GiB\n",
      "Used: 298 GiB\n",
      "Free: 176 GiB\n",
      "-----------------------------------------------------------------------------------------\n",
      "('tec', 'crowdflower', 'tweets', 'tweets')\n",
      "Getting data\n",
      "get_train_test param:\n",
      "json  unified-dataset.jsonl\n",
      "train  tec\n",
      "test  crowdflower\n",
      "there were  39740  entries that were in test and  181699 that were not in test and  21051  that were in train\n",
      "test was appended  39740  times\n",
      "single\n",
      "oof\n",
      "Detected mode: single...\n",
      "21051 39740\n",
      "Getting wordlist...\n",
      "Getting emotions\n",
      "['anger', 'joy', 'noemo', 'surprise', 'disgust', 'sadness', 'fear']\n",
      "Making arrays\n",
      "checking for save files\n",
      "emotions in make_arrays:  {'anger': 0, 'joy': 1, 'noemo': 2, 'surprise': 3, 'disgust': 4, 'sadness': 5, 'fear': 6}\n",
      "train super raw:  0.178016\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████| 21051/21051 [00:07<00:00, 2717.54it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████| 39740/39740 [00:16<00:00, 2399.72it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_x length  21051\n",
      "train_x dimension of element  5000\n",
      "train_x (text) size RAW: 0.178016 megabytes\n",
      "train_y (labels) size RAW: 0.178016 megabytes\n",
      "test_x (text) size RAW: 0.321096 megabytes\n",
      "test_y (labels) size RAW: 0.321096 megabytes\n",
      "saved test_y\n",
      "train_x Size stays the same False\n",
      "train_y Size stays the same False\n",
      "test_x Size stays the same False\n",
      "test_y Size stays the same False\n",
      "train_xNPSize (text) size: 421.02 megabytes\n",
      "train_yNPSize (labels) size: 0.084204 megabytes\n",
      "test_xNPSize (text) size: 794.8 megabytes\n",
      "test_yNPSize (labels) size: 0.15896 megabytes\n",
      "train_xNP length  21051\n",
      "train_xNP dimension of element  2\n",
      "train_xNP size  105255000\n",
      "saving NP arrays\n",
      "NP arrays saved\n",
      "Initializing classifier\n",
      "Searching for a  RandomForestClassifier\n",
      "False\n",
      "file not found, creating new classifier\n",
      "this is the classifierName:  RandomForestClassifier\n",
      "Training...\n",
      "train_x (text) size: 421.02 megabytes\n",
      "train_y (labels) size: 0.084204 megabytes\n",
      "train_x (text) length: 21051\n",
      "train_y (labels) length: 21051\n",
      "[[0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 1 0 ... 0 0 0]\n",
      " [0 1 0 ... 0 0 0]\n",
      " [0 1 1 ... 0 0 0]]\n",
      "[3 5 1 1 4]\n",
      "finished training, classifier size: 4.8e-05 megabytes\n",
      "Predicting...\n",
      "Analysing...\n",
      "analyse_results\n",
      "hello\n",
      "Precision\t0.23779567186713638\n",
      "Recall\t0.23779567186713638\n",
      "F1-score\t0.23779567186713638\n",
      "Accuracy\t0.23779567186713638\n",
      "classiferSaveFile:  tec_crowdflowerRandomForestClassifier.pkl\n",
      "Saved Successfully\n",
      "Total: 475 GiB\n",
      "Used: 299 GiB\n",
      "Free: 175 GiB\n",
      "-----------------------------------------------------------------------------------------\n",
      "('tec', 'affectivetext', 'tweets', 'headlines')\n",
      "Getting data\n",
      "get_train_test param:\n",
      "json  unified-dataset.jsonl\n",
      "train  tec\n",
      "test  affectivetext\n",
      "there were  1250  entries that were in test and  220189 that were not in test and  21051  that were in train\n",
      "test was appended  1250  times\n",
      "single\n",
      "Detected mode: multi...\n",
      "21051 1250\n",
      "Getting wordlist...\n",
      "Getting emotions\n",
      "['anger', 'joy', 'surprise', 'disgust', 'sadness', 'fear']\n",
      "Making arrays\n",
      "checking for save files\n",
      "emotions in make_arrays:  {'anger': 0, 'joy': 1, 'surprise': 2, 'disgust': 3, 'sadness': 4, 'fear': 5}\n",
      "train super raw:  0.178016\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████| 21051/21051 [00:07<00:00, 2654.00it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████| 1250/1250 [00:00<00:00, 2859.63it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_x length  21051\n",
      "train_x dimension of element  5000\n",
      "train_x (text) size RAW: 0.178016 megabytes\n",
      "train_y (labels) size RAW: 0.178016 megabytes\n",
      "test_x (text) size RAW: 0.010192 megabytes\n",
      "test_y (labels) size RAW: 0.010192 megabytes\n",
      "saved test_y\n",
      "train_x Size stays the same False\n",
      "train_y Size stays the same False\n",
      "test_x Size stays the same False\n",
      "test_y Size stays the same False\n",
      "train_xNPSize (text) size: 421.02 megabytes\n",
      "train_yNPSize (labels) size: 0.505224 megabytes\n",
      "test_xNPSize (text) size: 25.0 megabytes\n",
      "test_yNPSize (labels) size: 0.03 megabytes\n",
      "train_xNP length  21051\n",
      "train_xNP dimension of element  2\n",
      "train_xNP size  105255000\n",
      "saving NP arrays\n",
      "NP arrays saved\n",
      "Initializing classifier\n",
      "Searching for a  RandomForestClassifier\n",
      "False\n",
      "file not found, creating new classifier\n",
      "this is the classifierName:  RandomForestClassifier\n",
      "Training...\n",
      "train_x (text) size: 421.02 megabytes\n",
      "train_y (labels) size: 0.505224 megabytes\n",
      "train_x (text) length: 21051\n",
      "train_y (labels) length: 21051\n",
      "[[0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 1 0 ... 0 0 0]\n",
      " [0 1 0 ... 0 0 0]\n",
      " [0 1 1 ... 0 0 0]]\n",
      "[[0 0 1 0 0 0]\n",
      " [0 0 0 0 1 0]\n",
      " [0 1 0 0 0 0]\n",
      " [0 1 0 0 0 0]\n",
      " [0 0 0 1 0 0]]\n",
      "finished training, classifier size: 4.8e-05 megabytes\n",
      "Predicting...\n",
      "Analysing...\n",
      "analyse_results\n",
      "hello\n",
      "Precision\t0.5069767441860465\n",
      "Recall\t0.1015527950310559\n",
      "F1-score\t0.16921086675291075\n",
      "Accuracy\t0.0704\n",
      "classiferSaveFile:  tec_affectivetextRandomForestClassifier.pkl\n",
      "Saved Successfully\n",
      "Total: 475 GiB\n",
      "Used: 300 GiB\n",
      "Free: 174 GiB\n",
      "-----------------------------------------------------------------------------------------\n",
      "('ssec', 'tec', 'tweets', 'tweets')\n",
      "Getting data\n",
      "get_train_test param:\n",
      "json  unified-dataset.jsonl\n",
      "train  ssec\n",
      "test  tec\n",
      "there were  21051  entries that were in test and  200388 that were not in test and  4868  that were in train\n",
      "test was appended  21051  times\n",
      "multi\n",
      "oof\n",
      "Detected mode: multi...\n",
      "4868 21051\n",
      "Getting wordlist...\n",
      "Getting emotions\n",
      "['anger', 'joy', 'surprise', 'disgust', 'sadness', 'fear']\n",
      "Making arrays\n",
      "checking for save files\n",
      "saved train_xNP as ssec_tectrain_xNP.npy\n",
      "saved train_yNP as ssec_tectrain_yNP.npy\n",
      "saved test_xNP as ssec_tectest_xNP.npy\n",
      "saved test_yNP as ssec_tectest_yNP.npy\n",
      "loading from np\n",
      "loaded directly from NP.load\n",
      "train_xNPSize (text) size loaded: 97.36 megabytes\n",
      "train_yNPSize (labels) size loaded: 0.116832 megabytes\n",
      "test_xNPSize (text) size loaded: 421.02 megabytes\n",
      "test_yNPSize (labels) size loaded: 0.505224 megabytes\n",
      "Initializing classifier\n",
      "Searching for a  RandomForestClassifier\n",
      "True\n",
      "Loading classifier from file\n",
      "classifier loaded successfully\n",
      "Predicting...\n",
      "Analysing...\n",
      "analyse_results\n",
      "hello\n",
      "Precision\t0.25536179595109243\n",
      "Recall\t0.3026415811478525\n",
      "F1-score\t0.2769986737112169\n",
      "Accuracy\t0.15899482209871266\n",
      "classifier already saved\n",
      "Total: 475 GiB\n",
      "Used: 300 GiB\n",
      "Free: 174 GiB\n",
      "-----------------------------------------------------------------------------------------\n",
      "('ssec', 'tales-emotion', 'tweets', 'tales')\n",
      "Getting data\n",
      "get_train_test param:\n",
      "json  unified-dataset.jsonl\n",
      "train  ssec\n",
      "test  tales-emotion\n",
      "there were  14771  entries that were in test and  206668 that were not in test and  4868  that were in train\n",
      "test was appended  14771  times\n",
      "multi\n",
      "oof\n",
      "Detected mode: multi...\n",
      "4868 14771\n",
      "Getting wordlist...\n",
      "Getting emotions\n",
      "['anger', 'joy', 'surprise', 'disgust', 'sadness', 'fear']\n",
      "Making arrays\n",
      "checking for save files\n",
      "emotions in make_arrays:  {'anger': 0, 'joy': 1, 'surprise': 2, 'disgust': 3, 'sadness': 4, 'fear': 5}\n",
      "train super raw:  0.043032\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████| 4868/4868 [00:02<00:00, 1836.17it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████| 14771/14771 [00:05<00:00, 2551.23it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_x length  4868\n",
      "train_x dimension of element  5000\n",
      "train_x (text) size RAW: 0.043032 megabytes\n",
      "train_y (labels) size RAW: 0.043032 megabytes\n",
      "test_x (text) size RAW: 0.124912 megabytes\n",
      "test_y (labels) size RAW: 0.124912 megabytes\n",
      "saved test_y\n",
      "train_x Size stays the same False\n",
      "train_y Size stays the same False\n",
      "test_x Size stays the same False\n",
      "test_y Size stays the same False\n",
      "train_xNPSize (text) size: 97.36 megabytes\n",
      "train_yNPSize (labels) size: 0.116832 megabytes\n",
      "test_xNPSize (text) size: 295.42 megabytes\n",
      "test_yNPSize (labels) size: 0.354504 megabytes\n",
      "train_xNP length  4868\n",
      "train_xNP dimension of element  2\n",
      "train_xNP size  24340000\n",
      "saving NP arrays\n",
      "NP arrays saved\n",
      "Initializing classifier\n",
      "Searching for a  RandomForestClassifier\n",
      "False\n",
      "file not found, creating new classifier\n",
      "this is the classifierName:  RandomForestClassifier\n",
      "Training...\n",
      "train_x (text) size: 97.36 megabytes\n",
      "train_y (labels) size: 0.116832 megabytes\n",
      "train_x (text) length: 4868\n",
      "train_y (labels) length: 4868\n",
      "[[1 0 0 ... 0 0 0]\n",
      " [1 1 0 ... 0 0 0]\n",
      " [1 1 1 ... 0 0 0]\n",
      " [1 0 0 ... 0 0 0]\n",
      " [1 0 0 ... 0 0 0]]\n",
      "[[1 1 0 1 0 0]\n",
      " [0 1 0 0 1 0]\n",
      " [0 1 0 0 0 0]\n",
      " [0 0 0 0 1 1]\n",
      " [1 1 1 0 0 1]]\n",
      "finished training, classifier size: 4.8e-05 megabytes\n",
      "Predicting...\n",
      "Analysing...\n",
      "analyse_results\n",
      "hello\n",
      "Precision\t0.07260598235420701\n",
      "Recall\t0.3138020833333333\n",
      "F1-score\t0.11792667155988953\n",
      "Accuracy\t0.16749035271816398\n",
      "classiferSaveFile:  ssec_tales-emotionRandomForestClassifier.pkl\n",
      "Saved Successfully\n",
      "Total: 475 GiB\n",
      "Used: 300 GiB\n",
      "Free: 174 GiB\n",
      "-----------------------------------------------------------------------------------------\n",
      "('ssec', 'isear', 'tweets', 'descriptions')\n",
      "Getting data\n",
      "get_train_test param:\n",
      "json  unified-dataset.jsonl\n",
      "train  ssec\n",
      "test  isear\n",
      "there were  7666  entries that were in test and  213773 that were not in test and  4868  that were in train\n",
      "test was appended  7666  times\n",
      "multi\n",
      "oof\n",
      "Detected mode: multi...\n",
      "4868 7666\n",
      "Getting wordlist...\n",
      "Getting emotions\n",
      "['anger', 'joy', 'disgust', 'sadness', 'fear']\n",
      "Making arrays\n",
      "checking for save files\n",
      "emotions in make_arrays:  {'anger': 0, 'joy': 1, 'disgust': 2, 'sadness': 3, 'fear': 4}\n",
      "train super raw:  0.043032\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████| 4868/4868 [00:02<00:00, 2171.56it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████| 7666/7666 [00:03<00:00, 2101.59it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_x length  4868\n",
      "train_x dimension of element  5000\n",
      "train_x (text) size RAW: 0.043032 megabytes\n",
      "train_y (labels) size RAW: 0.043032 megabytes\n",
      "test_x (text) size RAW: 0.061424 megabytes\n",
      "test_y (labels) size RAW: 0.061424 megabytes\n",
      "saved test_y\n",
      "train_x Size stays the same False\n",
      "train_y Size stays the same False\n",
      "test_x Size stays the same False\n",
      "test_y Size stays the same False\n",
      "train_xNPSize (text) size: 97.36 megabytes\n",
      "train_yNPSize (labels) size: 0.09736 megabytes\n",
      "test_xNPSize (text) size: 153.32 megabytes\n",
      "test_yNPSize (labels) size: 0.15332 megabytes\n",
      "train_xNP length  4868\n",
      "train_xNP dimension of element  2\n",
      "train_xNP size  24340000\n",
      "saving NP arrays\n",
      "NP arrays saved\n",
      "Initializing classifier\n",
      "Searching for a  RandomForestClassifier\n",
      "False\n",
      "file not found, creating new classifier\n",
      "this is the classifierName:  RandomForestClassifier\n",
      "Training...\n",
      "train_x (text) size: 97.36 megabytes\n",
      "train_y (labels) size: 0.09736 megabytes\n",
      "train_x (text) length: 4868\n",
      "train_y (labels) length: 4868\n",
      "[[1 0 0 ... 0 0 0]\n",
      " [1 1 0 ... 0 0 0]\n",
      " [1 1 1 ... 0 0 0]\n",
      " [1 0 0 ... 0 0 0]\n",
      " [1 0 0 ... 0 0 0]]\n",
      "[[1 1 1 0 0]\n",
      " [0 1 0 1 0]\n",
      " [0 1 0 0 0]\n",
      " [0 0 0 1 1]\n",
      " [1 1 0 0 1]]\n",
      "finished training, classifier size: 4.8e-05 megabytes\n",
      "Predicting...\n",
      "Analysing...\n",
      "analyse_results\n",
      "hello\n",
      "Precision\t0.166890663293541\n",
      "Recall\t0.3854299799160124\n",
      "F1-score\t0.23292507999558645\n",
      "Accuracy\t0.08844247325854422\n",
      "classiferSaveFile:  ssec_isearRandomForestClassifier.pkl\n",
      "Saved Successfully\n",
      "Total: 475 GiB\n",
      "Used: 301 GiB\n",
      "Free: 173 GiB\n",
      "-----------------------------------------------------------------------------------------\n",
      "('ssec', 'grounded_emotions', 'tweets', 'tweets')\n",
      "Getting data\n",
      "get_train_test param:\n",
      "json  unified-dataset.jsonl\n",
      "train  ssec\n",
      "test  grounded_emotions\n",
      "there were  2585  entries that were in test and  218854 that were not in test and  4868  that were in train\n",
      "test was appended  2585  times\n",
      "multi\n",
      "oof\n",
      "Detected mode: multi...\n",
      "4868 2585\n",
      "Getting wordlist...\n",
      "Getting emotions\n",
      "['joy', 'sadness']\n",
      "Making arrays\n",
      "checking for save files\n",
      "emotions in make_arrays:  {'joy': 0, 'sadness': 1}\n",
      "train super raw:  0.043032\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████| 4868/4868 [00:02<00:00, 2199.62it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████| 2585/2585 [00:01<00:00, 2123.12it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_x length  4868\n",
      "train_x dimension of element  5000\n",
      "train_x (text) size RAW: 0.043032 megabytes\n",
      "train_y (labels) size RAW: 0.043032 megabytes\n",
      "test_x (text) size RAW: 0.02104 megabytes\n",
      "test_y (labels) size RAW: 0.02104 megabytes\n",
      "saved test_y\n",
      "train_x Size stays the same False\n",
      "train_y Size stays the same False\n",
      "test_x Size stays the same False\n",
      "test_y Size stays the same False\n",
      "train_xNPSize (text) size: 97.36 megabytes\n",
      "train_yNPSize (labels) size: 0.038944 megabytes\n",
      "test_xNPSize (text) size: 51.7 megabytes\n",
      "test_yNPSize (labels) size: 0.02068 megabytes\n",
      "train_xNP length  4868\n",
      "train_xNP dimension of element  2\n",
      "train_xNP size  24340000\n",
      "saving NP arrays\n",
      "NP arrays saved\n",
      "Initializing classifier\n",
      "Searching for a  RandomForestClassifier\n",
      "False\n",
      "file not found, creating new classifier\n",
      "this is the classifierName:  RandomForestClassifier\n",
      "Training...\n",
      "train_x (text) size: 97.36 megabytes\n",
      "train_y (labels) size: 0.038944 megabytes\n",
      "train_x (text) length: 4868\n",
      "train_y (labels) length: 4868\n",
      "[[1 0 0 ... 0 0 0]\n",
      " [1 1 0 ... 0 0 0]\n",
      " [1 1 1 ... 0 0 0]\n",
      " [1 0 0 ... 0 0 0]\n",
      " [1 0 0 ... 0 0 0]]\n",
      "[[1 0]\n",
      " [1 1]\n",
      " [1 0]\n",
      " [0 1]\n",
      " [1 0]]\n",
      "finished training, classifier size: 4.8e-05 megabytes\n",
      "Predicting...\n",
      "Analysing...\n",
      "analyse_results\n",
      "hello\n",
      "Precision\t0.46430329886755295\n",
      "Recall\t0.36479690522243713\n",
      "F1-score\t0.408578856152513\n",
      "Accuracy\t0.34545454545454546\n",
      "classiferSaveFile:  ssec_grounded_emotionsRandomForestClassifier.pkl\n",
      "Saved Successfully\n",
      "Total: 475 GiB\n",
      "Used: 301 GiB\n",
      "Free: 173 GiB\n",
      "-----------------------------------------------------------------------------------------\n",
      "('ssec', 'emotion-cause', 'tweets', 'paragraphs')\n",
      "Getting data\n",
      "get_train_test param:\n",
      "json  unified-dataset.jsonl\n",
      "train  ssec\n",
      "test  emotion-cause\n",
      "there were  2414  entries that were in test and  219025 that were not in test and  4868  that were in train\n",
      "test was appended  2414  times\n",
      "multi\n",
      "oof\n",
      "Detected mode: multi...\n",
      "4868 2414\n",
      "Getting wordlist...\n",
      "Getting emotions\n",
      "['anger', 'joy', 'surprise', 'disgust', 'sadness', 'fear']\n",
      "Making arrays\n",
      "checking for save files\n",
      "emotions in make_arrays:  {'anger': 0, 'joy': 1, 'surprise': 2, 'disgust': 3, 'sadness': 4, 'fear': 5}\n",
      "train super raw:  0.043032\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████| 4868/4868 [00:02<00:00, 2366.29it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████| 2414/2414 [00:00<00:00, 2659.38it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_x length  4868\n",
      "train_x dimension of element  5000\n",
      "train_x (text) size RAW: 0.043032 megabytes\n",
      "train_y (labels) size RAW: 0.043032 megabytes\n",
      "test_x (text) size RAW: 0.02104 megabytes\n",
      "test_y (labels) size RAW: 0.02104 megabytes\n",
      "saved test_y\n",
      "train_x Size stays the same False\n",
      "train_y Size stays the same False\n",
      "test_x Size stays the same False\n",
      "test_y Size stays the same False\n",
      "train_xNPSize (text) size: 97.36 megabytes\n",
      "train_yNPSize (labels) size: 0.116832 megabytes\n",
      "test_xNPSize (text) size: 48.28 megabytes\n",
      "test_yNPSize (labels) size: 0.057936 megabytes\n",
      "train_xNP length  4868\n",
      "train_xNP dimension of element  2\n",
      "train_xNP size  24340000\n",
      "saving NP arrays\n",
      "NP arrays saved\n",
      "Initializing classifier\n",
      "Searching for a  RandomForestClassifier\n",
      "False\n",
      "file not found, creating new classifier\n",
      "this is the classifierName:  RandomForestClassifier\n",
      "Training...\n",
      "train_x (text) size: 97.36 megabytes\n",
      "train_y (labels) size: 0.116832 megabytes\n",
      "train_x (text) length: 4868\n",
      "train_y (labels) length: 4868\n",
      "[[1 0 0 ... 0 0 0]\n",
      " [1 1 0 ... 0 0 0]\n",
      " [1 1 1 ... 0 0 0]\n",
      " [1 0 0 ... 0 0 0]\n",
      " [1 0 0 ... 0 0 0]]\n",
      "[[1 1 0 1 0 0]\n",
      " [0 1 0 0 1 0]\n",
      " [0 1 0 0 0 0]\n",
      " [0 0 0 0 1 1]\n",
      " [1 1 1 0 0 1]]\n",
      "finished training, classifier size: 4.8e-05 megabytes\n",
      "Predicting...\n",
      "Analysing...\n",
      "analyse_results\n",
      "hello\n",
      "Precision\t0.21096388672382438\n",
      "Recall\t0.35802469135802467\n",
      "F1-score\t0.2654896190943273\n",
      "Accuracy\t0.0940347970173985\n",
      "classiferSaveFile:  ssec_emotion-causeRandomForestClassifier.pkl\n",
      "Saved Successfully\n",
      "Total: 475 GiB\n",
      "Used: 301 GiB\n",
      "Free: 173 GiB\n",
      "-----------------------------------------------------------------------------------------\n",
      "('ssec', 'emoint', 'tweets', 'tweets')\n",
      "Getting data\n",
      "get_train_test param:\n",
      "json  unified-dataset.jsonl\n",
      "train  ssec\n",
      "test  emoint\n",
      "there were  7102  entries that were in test and  214337 that were not in test and  4868  that were in train\n",
      "test was appended  7102  times\n",
      "multi\n",
      "oof\n",
      "Detected mode: multi...\n",
      "4868 7102\n",
      "Getting wordlist...\n",
      "Getting emotions\n",
      "['joy', 'sadness', 'anger', 'fear']\n",
      "Making arrays\n",
      "checking for save files\n",
      "emotions in make_arrays:  {'joy': 0, 'sadness': 1, 'anger': 2, 'fear': 3}\n",
      "train super raw:  0.043032\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████| 4868/4868 [00:01<00:00, 2674.10it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████| 7102/7102 [00:02<00:00, 2594.80it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_x length  4868\n",
      "train_x dimension of element  5000\n",
      "train_x (text) size RAW: 0.043032 megabytes\n",
      "train_y (labels) size RAW: 0.043032 megabytes\n",
      "test_x (text) size RAW: 0.061424 megabytes\n",
      "test_y (labels) size RAW: 0.061424 megabytes\n",
      "saved test_y\n",
      "train_x Size stays the same False\n",
      "train_y Size stays the same False\n",
      "test_x Size stays the same False\n",
      "test_y Size stays the same False\n",
      "train_xNPSize (text) size: 97.36 megabytes\n",
      "train_yNPSize (labels) size: 0.077888 megabytes\n",
      "test_xNPSize (text) size: 142.04 megabytes\n",
      "test_yNPSize (labels) size: 0.113632 megabytes\n",
      "train_xNP length  4868\n",
      "train_xNP dimension of element  2\n",
      "train_xNP size  24340000\n",
      "saving NP arrays\n",
      "NP arrays saved\n",
      "Initializing classifier\n",
      "Searching for a  RandomForestClassifier\n",
      "False\n",
      "file not found, creating new classifier\n",
      "this is the classifierName:  RandomForestClassifier\n",
      "Training...\n",
      "train_x (text) size: 97.36 megabytes\n",
      "train_y (labels) size: 0.077888 megabytes\n",
      "train_x (text) length: 4868\n",
      "train_y (labels) length: 4868\n",
      "[[1 0 0 ... 0 0 0]\n",
      " [1 1 0 ... 0 0 0]\n",
      " [1 1 1 ... 0 0 0]\n",
      " [1 0 0 ... 0 0 0]\n",
      " [1 0 0 ... 0 0 0]]\n",
      "[[1 0 1 0]\n",
      " [1 1 0 0]\n",
      " [1 0 0 0]\n",
      " [0 1 0 1]\n",
      " [1 0 1 1]]\n",
      "finished training, classifier size: 4.8e-05 megabytes\n",
      "Predicting...\n",
      "Analysing...\n",
      "analyse_results\n",
      "hello\n",
      "Precision\t0.2753483386923901\n",
      "Recall\t0.36172909039707124\n",
      "F1-score\t0.3126825705939629\n",
      "Accuracy\t0.12081103914390312\n",
      "classiferSaveFile:  ssec_emointRandomForestClassifier.pkl\n",
      "Saved Successfully\n",
      "Total: 475 GiB\n",
      "Used: 301 GiB\n",
      "Free: 173 GiB\n",
      "-----------------------------------------------------------------------------------------\n",
      "('ssec', 'emobank', 'tweets', 'headlines')\n",
      "Getting data\n",
      "get_train_test param:\n",
      "json  unified-dataset.jsonl\n",
      "train  ssec\n",
      "test  emobank\n",
      "there were  10062  entries that were in test and  211377 that were not in test and  4868  that were in train\n",
      "test was appended  10062  times\n",
      "multi\n",
      "Detected mode: multi...\n",
      "4868 10062\n",
      "Getting wordlist...\n",
      "Getting emotions\n",
      "[]\n",
      "Making arrays\n",
      "checking for save files\n",
      "emotions in make_arrays:  {}\n",
      "train super raw:  0.043032\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████| 4868/4868 [00:01<00:00, 2463.20it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████| 10062/10062 [00:03<00:00, 2594.24it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_x length  4868\n",
      "train_x dimension of element  5000\n",
      "train_x (text) size RAW: 0.043032 megabytes\n",
      "train_y (labels) size RAW: 0.043032 megabytes\n",
      "test_x (text) size RAW: 0.087616 megabytes\n",
      "test_y (labels) size RAW: 0.087616 megabytes\n",
      "saved test_y\n",
      "train_x Size stays the same False\n",
      "train_y Size stays the same False\n",
      "test_x Size stays the same False\n",
      "test_y Size stays the same False\n",
      "train_xNPSize (text) size: 97.36 megabytes\n",
      "train_yNPSize (labels) size: 0.0 megabytes\n",
      "test_xNPSize (text) size: 201.24 megabytes\n",
      "test_yNPSize (labels) size: 0.0 megabytes\n",
      "train_xNP length  4868\n",
      "train_xNP dimension of element  2\n",
      "train_xNP size  24340000\n",
      "Train or test empty. Did you misspell the dataset name?\n",
      "('ssec', 'dailydialog', 'tweets', 'conversations')\n",
      "Getting data\n",
      "get_train_test param:\n",
      "json  unified-dataset.jsonl\n",
      "train  ssec\n",
      "test  dailydialog\n",
      "there were  102979  entries that were in test and  118460 that were not in test and  4868  that were in train\n",
      "test was appended  102979  times\n",
      "multi\n",
      "oof\n",
      "Detected mode: multi...\n",
      "4868 102979\n",
      "Getting wordlist...\n",
      "Getting emotions\n",
      "['anger', 'joy', 'surprise', 'disgust', 'sadness', 'fear']\n",
      "Making arrays\n",
      "checking for save files\n",
      "emotions in make_arrays:  {'anger': 0, 'joy': 1, 'surprise': 2, 'disgust': 3, 'sadness': 4, 'fear': 5}\n",
      "train super raw:  0.043032\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████| 4868/4868 [00:01<00:00, 2549.72it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████| 102979/102979 [00:44<00:00, 2290.94it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_x length  4868\n",
      "train_x dimension of element  5000\n",
      "train_x (text) size RAW: 0.043032 megabytes\n",
      "train_y (labels) size RAW: 0.043032 megabytes\n",
      "test_x (text) size RAW: 0.824456 megabytes\n",
      "test_y (labels) size RAW: 0.824456 megabytes\n",
      "saved test_y\n",
      "train_x Size stays the same False\n",
      "train_y Size stays the same False\n",
      "test_x Size stays the same False\n",
      "test_y Size stays the same False\n",
      "train_xNPSize (text) size: 97.36 megabytes\n",
      "train_yNPSize (labels) size: 0.116832 megabytes\n",
      "test_xNPSize (text) size: 2059.58 megabytes\n",
      "test_yNPSize (labels) size: 2.471496 megabytes\n",
      "train_xNP length  4868\n",
      "train_xNP dimension of element  2\n",
      "train_xNP size  24340000\n",
      "saving NP arrays\n",
      "NP arrays saved\n",
      "Initializing classifier\n",
      "Searching for a  RandomForestClassifier\n",
      "False\n",
      "file not found, creating new classifier\n",
      "this is the classifierName:  RandomForestClassifier\n",
      "Training...\n",
      "train_x (text) size: 97.36 megabytes\n",
      "train_y (labels) size: 0.116832 megabytes\n",
      "train_x (text) length: 4868\n",
      "train_y (labels) length: 4868\n",
      "[[1 0 0 ... 0 0 0]\n",
      " [1 1 0 ... 0 0 0]\n",
      " [1 1 1 ... 0 0 0]\n",
      " [1 0 0 ... 0 0 0]\n",
      " [1 0 0 ... 0 0 0]]\n",
      "[[1 1 0 1 0 0]\n",
      " [0 1 0 0 1 0]\n",
      " [0 1 0 0 0 0]\n",
      " [0 0 0 0 1 1]\n",
      " [1 1 1 0 0 1]]\n",
      "finished training, classifier size: 4.8e-05 megabytes\n",
      "Predicting...\n",
      "Analysing...\n",
      "analyse_results\n",
      "hello\n",
      "Precision\t0.06844302907621815\n",
      "Recall\t0.4642385247314299\n",
      "F1-score\t0.11929788301987068\n",
      "Accuracy\t0.3155983258722652\n",
      "classiferSaveFile:  ssec_dailydialogRandomForestClassifier.pkl\n",
      "Saved Successfully\n",
      "Total: 475 GiB\n",
      "Used: 303 GiB\n",
      "Free: 171 GiB\n",
      "-----------------------------------------------------------------------------------------\n",
      "('ssec', 'crowdflower', 'tweets', 'tweets')\n",
      "Getting data\n",
      "get_train_test param:\n",
      "json  unified-dataset.jsonl\n",
      "train  ssec\n",
      "test  crowdflower\n",
      "there were  39740  entries that were in test and  181699 that were not in test and  4868  that were in train\n",
      "test was appended  39740  times\n",
      "multi\n",
      "oof\n",
      "Detected mode: multi...\n",
      "4868 39740\n",
      "Getting wordlist...\n",
      "Getting emotions\n",
      "['anger', 'joy', 'surprise', 'disgust', 'sadness', 'fear']\n",
      "Making arrays\n",
      "checking for save files\n",
      "emotions in make_arrays:  {'anger': 0, 'joy': 1, 'surprise': 2, 'disgust': 3, 'sadness': 4, 'fear': 5}\n",
      "train super raw:  0.043032\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████| 4868/4868 [00:01<00:00, 2701.92it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████| 39740/39740 [00:16<00:00, 2465.08it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_x length  4868\n",
      "train_x dimension of element  5000\n",
      "train_x (text) size RAW: 0.043032 megabytes\n",
      "train_y (labels) size RAW: 0.043032 megabytes\n",
      "test_x (text) size RAW: 0.321096 megabytes\n",
      "test_y (labels) size RAW: 0.321096 megabytes\n",
      "saved test_y\n",
      "train_x Size stays the same False\n",
      "train_y Size stays the same False\n",
      "test_x Size stays the same False\n",
      "test_y Size stays the same False\n",
      "train_xNPSize (text) size: 97.36 megabytes\n",
      "train_yNPSize (labels) size: 0.116832 megabytes\n",
      "test_xNPSize (text) size: 794.8 megabytes\n",
      "test_yNPSize (labels) size: 0.95376 megabytes\n",
      "train_xNP length  4868\n",
      "train_xNP dimension of element  2\n",
      "train_xNP size  24340000\n",
      "saving NP arrays\n",
      "NP arrays saved\n",
      "Initializing classifier\n",
      "Searching for a  RandomForestClassifier\n",
      "False\n",
      "file not found, creating new classifier\n",
      "this is the classifierName:  RandomForestClassifier\n",
      "Training...\n",
      "train_x (text) size: 97.36 megabytes\n",
      "train_y (labels) size: 0.116832 megabytes\n",
      "train_x (text) length: 4868\n",
      "train_y (labels) length: 4868\n",
      "[[1 0 0 ... 0 0 0]\n",
      " [1 1 0 ... 0 0 0]\n",
      " [1 1 1 ... 0 0 0]\n",
      " [1 0 0 ... 0 0 0]\n",
      " [1 0 0 ... 0 0 0]]\n",
      "[[1 1 0 1 0 0]\n",
      " [0 1 0 0 1 0]\n",
      " [0 1 0 0 0 0]\n",
      " [0 0 0 0 1 1]\n",
      " [1 1 1 0 0 1]]\n",
      "finished training, classifier size: 4.8e-05 megabytes\n",
      "Predicting...\n",
      "Analysing...\n",
      "analyse_results\n",
      "hello\n",
      "Precision\t0.16286106092597027\n",
      "Recall\t0.2818079096045198\n",
      "F1-score\t0.20642562525003105\n",
      "Accuracy\t0.21444388525415198\n",
      "classiferSaveFile:  ssec_crowdflowerRandomForestClassifier.pkl\n",
      "Saved Successfully\n",
      "Total: 475 GiB\n",
      "Used: 304 GiB\n",
      "Free: 170 GiB\n",
      "-----------------------------------------------------------------------------------------\n",
      "('ssec', 'affectivetext', 'tweets', 'headlines')\n",
      "Getting data\n",
      "get_train_test param:\n",
      "json  unified-dataset.jsonl\n",
      "train  ssec\n",
      "test  affectivetext\n",
      "there were  1250  entries that were in test and  220189 that were not in test and  4868  that were in train\n",
      "test was appended  1250  times\n",
      "multi\n",
      "Detected mode: multi...\n",
      "4868 1250\n",
      "Getting wordlist...\n",
      "Getting emotions\n",
      "['anger', 'joy', 'surprise', 'disgust', 'sadness', 'fear']\n",
      "Making arrays\n",
      "checking for save files\n",
      "emotions in make_arrays:  {'anger': 0, 'joy': 1, 'surprise': 2, 'disgust': 3, 'sadness': 4, 'fear': 5}\n",
      "train super raw:  0.043032\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████| 4868/4868 [00:01<00:00, 2719.84it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████| 1250/1250 [00:00<00:00, 2354.82it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_x length  4868\n",
      "train_x dimension of element  5000\n",
      "train_x (text) size RAW: 0.043032 megabytes\n",
      "train_y (labels) size RAW: 0.043032 megabytes\n",
      "test_x (text) size RAW: 0.010192 megabytes\n",
      "test_y (labels) size RAW: 0.010192 megabytes\n",
      "saved test_y\n",
      "train_x Size stays the same False\n",
      "train_y Size stays the same False\n",
      "test_x Size stays the same False\n",
      "test_y Size stays the same False\n",
      "train_xNPSize (text) size: 97.36 megabytes\n",
      "train_yNPSize (labels) size: 0.116832 megabytes\n",
      "test_xNPSize (text) size: 25.0 megabytes\n",
      "test_yNPSize (labels) size: 0.03 megabytes\n",
      "train_xNP length  4868\n",
      "train_xNP dimension of element  2\n",
      "train_xNP size  24340000\n",
      "saving NP arrays\n",
      "NP arrays saved\n",
      "Initializing classifier\n",
      "Searching for a  RandomForestClassifier\n",
      "False\n",
      "file not found, creating new classifier\n",
      "this is the classifierName:  RandomForestClassifier\n",
      "Training...\n",
      "train_x (text) size: 97.36 megabytes\n",
      "train_y (labels) size: 0.116832 megabytes\n",
      "train_x (text) length: 4868\n",
      "train_y (labels) length: 4868\n",
      "[[1 0 0 ... 0 0 0]\n",
      " [1 1 0 ... 0 0 0]\n",
      " [1 1 1 ... 0 0 0]\n",
      " [1 0 0 ... 0 0 0]\n",
      " [1 0 0 ... 0 0 0]]\n",
      "[[1 1 0 1 0 0]\n",
      " [0 1 0 0 1 0]\n",
      " [0 1 0 0 0 0]\n",
      " [0 0 0 0 1 1]\n",
      " [1 1 1 0 0 1]]\n",
      "finished training, classifier size: 4.8e-05 megabytes\n",
      "Predicting...\n",
      "Analysing...\n",
      "analyse_results\n",
      "hello\n",
      "Precision\t0.4777227722772277\n",
      "Recall\t0.05993788819875776\n",
      "F1-score\t0.10651214128035319\n",
      "Accuracy\t0.0376\n",
      "classiferSaveFile:  ssec_affectivetextRandomForestClassifier.pkl\n",
      "Saved Successfully\n",
      "Total: 475 GiB\n",
      "Used: 304 GiB\n",
      "Free: 170 GiB\n",
      "-----------------------------------------------------------------------------------------\n",
      "('grounded_emotions', 'tec', 'tweets', 'tweets')\n",
      "Getting data\n",
      "get_train_test param:\n",
      "json  unified-dataset.jsonl\n",
      "train  grounded_emotions\n",
      "test  tec\n",
      "there were  21051  entries that were in test and  200388 that were not in test and  2585  that were in train\n",
      "test was appended  21051  times\n",
      "single\n",
      "oof\n",
      "Detected mode: single...\n",
      "2585 21051\n",
      "Getting wordlist...\n",
      "Getting emotions\n",
      "['joy', 'noemo', 'sadness']\n",
      "Making arrays\n",
      "checking for save files\n",
      "emotions in make_arrays:  {'joy': 0, 'noemo': 1, 'sadness': 2}\n",
      "train super raw:  0.02104\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████| 2585/2585 [00:00<00:00, 2869.51it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████| 21051/21051 [00:08<00:00, 2557.60it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_x length  2585\n",
      "train_x dimension of element  5000\n",
      "train_x (text) size RAW: 0.02104 megabytes\n",
      "train_y (labels) size RAW: 0.02104 megabytes\n",
      "test_x (text) size RAW: 0.178016 megabytes\n",
      "test_y (labels) size RAW: 0.178016 megabytes\n",
      "saved test_y\n",
      "train_x Size stays the same False\n",
      "train_y Size stays the same False\n",
      "test_x Size stays the same False\n",
      "test_y Size stays the same False\n",
      "train_xNPSize (text) size: 51.7 megabytes\n",
      "train_yNPSize (labels) size: 0.01034 megabytes\n",
      "test_xNPSize (text) size: 421.02 megabytes\n",
      "test_yNPSize (labels) size: 0.084204 megabytes\n",
      "train_xNP length  2585\n",
      "train_xNP dimension of element  2\n",
      "train_xNP size  12925000\n",
      "saving NP arrays\n",
      "NP arrays saved\n",
      "Initializing classifier\n",
      "Searching for a  RandomForestClassifier\n",
      "False\n",
      "file not found, creating new classifier\n",
      "this is the classifierName:  RandomForestClassifier\n",
      "Training...\n",
      "train_x (text) size: 51.7 megabytes\n",
      "train_y (labels) size: 0.01034 megabytes\n",
      "train_x (text) length: 2585\n",
      "train_y (labels) length: 2585\n",
      "[[0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " [1 1 1 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " [1 1 1 ... 0 0 0]]\n",
      "[2 0 0 0 0]\n",
      "finished training, classifier size: 4.8e-05 megabytes\n",
      "Predicting...\n",
      "Analysing...\n",
      "analyse_results\n",
      "hello\n",
      "Precision\t0.3665859104080566\n",
      "Recall\t0.3665859104080566\n",
      "F1-score\t0.3665859104080566\n",
      "Accuracy\t0.3665859104080566\n",
      "classiferSaveFile:  grounded_emotions_tecRandomForestClassifier.pkl\n",
      "Saved Successfully\n",
      "Total: 475 GiB\n",
      "Used: 305 GiB\n",
      "Free: 169 GiB\n",
      "-----------------------------------------------------------------------------------------\n",
      "('grounded_emotions', 'tales-emotion', 'tweets', 'tales')\n",
      "Getting data\n",
      "get_train_test param:\n",
      "json  unified-dataset.jsonl\n",
      "train  grounded_emotions\n",
      "test  tales-emotion\n",
      "there were  14771  entries that were in test and  206668 that were not in test and  2585  that were in train\n",
      "test was appended  14771  times\n",
      "single\n",
      "oof\n",
      "Detected mode: single...\n",
      "2585 14771\n",
      "Getting wordlist...\n",
      "Getting emotions\n",
      "['joy', 'noemo', 'sadness']\n",
      "Making arrays\n",
      "checking for save files\n",
      "emotions in make_arrays:  {'joy': 0, 'noemo': 1, 'sadness': 2}\n",
      "train super raw:  0.02104\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████| 2585/2585 [00:00<00:00, 2734.80it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████| 14771/14771 [00:05<00:00, 2580.25it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_x length  2585\n",
      "train_x dimension of element  5000\n",
      "train_x (text) size RAW: 0.02104 megabytes\n",
      "train_y (labels) size RAW: 0.02104 megabytes\n",
      "test_x (text) size RAW: 0.124912 megabytes\n",
      "test_y (labels) size RAW: 0.124912 megabytes\n",
      "saved test_y\n",
      "train_x Size stays the same False\n",
      "train_y Size stays the same False\n",
      "test_x Size stays the same False\n",
      "test_y Size stays the same False\n",
      "train_xNPSize (text) size: 51.7 megabytes\n",
      "train_yNPSize (labels) size: 0.01034 megabytes\n",
      "test_xNPSize (text) size: 295.42 megabytes\n",
      "test_yNPSize (labels) size: 0.059084 megabytes\n",
      "train_xNP length  2585\n",
      "train_xNP dimension of element  2\n",
      "train_xNP size  12925000\n",
      "saving NP arrays\n",
      "NP arrays saved\n",
      "Initializing classifier\n",
      "Searching for a  RandomForestClassifier\n",
      "False\n",
      "file not found, creating new classifier\n",
      "this is the classifierName:  RandomForestClassifier\n",
      "Training...\n",
      "train_x (text) size: 51.7 megabytes\n",
      "train_y (labels) size: 0.01034 megabytes\n",
      "train_x (text) length: 2585\n",
      "train_y (labels) length: 2585\n",
      "[[0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " [1 1 1 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " [1 1 1 ... 0 0 0]]\n",
      "[2 0 0 0 0]\n",
      "finished training, classifier size: 4.8e-05 megabytes\n",
      "Predicting...\n",
      "Analysing...\n",
      "analyse_results\n",
      "hello\n",
      "Precision\t0.11421027689391375\n",
      "Recall\t0.11421027689391375\n",
      "F1-score\t0.11421027689391375\n",
      "Accuracy\t0.11421027689391375\n",
      "classiferSaveFile:  grounded_emotions_tales-emotionRandomForestClassifier.pkl\n",
      "Saved Successfully\n",
      "Total: 475 GiB\n",
      "Used: 305 GiB\n",
      "Free: 169 GiB\n",
      "-----------------------------------------------------------------------------------------\n",
      "('grounded_emotions', 'ssec', 'tweets', 'tweets')\n",
      "Getting data\n",
      "get_train_test param:\n",
      "json  unified-dataset.jsonl\n",
      "train  grounded_emotions\n",
      "test  ssec\n",
      "there were  4868  entries that were in test and  216571 that were not in test and  2585  that were in train\n",
      "test was appended  4868  times\n",
      "single\n",
      "Detected mode: multi...\n",
      "2585 4868\n",
      "Getting wordlist...\n",
      "Getting emotions\n",
      "['joy', 'sadness']\n",
      "Making arrays\n",
      "checking for save files\n",
      "emotions in make_arrays:  {'joy': 0, 'sadness': 1}\n",
      "train super raw:  0.02104\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████| 2585/2585 [00:00<00:00, 2793.03it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████| 4868/4868 [00:01<00:00, 2756.26it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_x length  2585\n",
      "train_x dimension of element  5000\n",
      "train_x (text) size RAW: 0.02104 megabytes\n",
      "train_y (labels) size RAW: 0.02104 megabytes\n",
      "test_x (text) size RAW: 0.043032 megabytes\n",
      "test_y (labels) size RAW: 0.043032 megabytes\n",
      "saved test_y\n",
      "train_x Size stays the same False\n",
      "train_y Size stays the same False\n",
      "test_x Size stays the same False\n",
      "test_y Size stays the same False\n",
      "train_xNPSize (text) size: 51.7 megabytes\n",
      "train_yNPSize (labels) size: 0.02068 megabytes\n",
      "test_xNPSize (text) size: 97.36 megabytes\n",
      "test_yNPSize (labels) size: 0.038944 megabytes\n",
      "train_xNP length  2585\n",
      "train_xNP dimension of element  2\n",
      "train_xNP size  12925000\n",
      "saving NP arrays\n",
      "NP arrays saved\n",
      "Initializing classifier\n",
      "Searching for a  RandomForestClassifier\n",
      "False\n",
      "file not found, creating new classifier\n",
      "this is the classifierName:  RandomForestClassifier\n",
      "Training...\n",
      "train_x (text) size: 51.7 megabytes\n",
      "train_y (labels) size: 0.02068 megabytes\n",
      "train_x (text) length: 2585\n",
      "train_y (labels) length: 2585\n",
      "[[0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " [1 1 1 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " [1 1 1 ... 0 0 0]]\n",
      "[[0 1]\n",
      " [1 0]\n",
      " [1 0]\n",
      " [1 0]\n",
      " [1 0]]\n",
      "finished training, classifier size: 4.8e-05 megabytes\n",
      "Predicting...\n",
      "Analysing...\n",
      "analyse_results\n",
      "hello\n",
      "Precision\t0.4366226259289843\n",
      "Recall\t0.44894926767140736\n",
      "F1-score\t0.4427001569858713\n",
      "Accuracy\t0.29642563681183237\n",
      "classiferSaveFile:  grounded_emotions_ssecRandomForestClassifier.pkl\n",
      "Saved Successfully\n",
      "Total: 475 GiB\n",
      "Used: 305 GiB\n",
      "Free: 169 GiB\n",
      "-----------------------------------------------------------------------------------------\n",
      "('grounded_emotions', 'isear', 'tweets', 'descriptions')\n",
      "Getting data\n",
      "get_train_test param:\n",
      "json  unified-dataset.jsonl\n",
      "train  grounded_emotions\n",
      "test  isear\n",
      "there were  7666  entries that were in test and  213773 that were not in test and  2585  that were in train\n",
      "test was appended  7666  times\n",
      "single\n",
      "oof\n",
      "Detected mode: single...\n",
      "2585 7666\n",
      "Getting wordlist...\n",
      "Getting emotions\n",
      "['joy', 'noemo', 'sadness']\n",
      "Making arrays\n",
      "checking for save files\n",
      "emotions in make_arrays:  {'joy': 0, 'noemo': 1, 'sadness': 2}\n",
      "train super raw:  0.02104\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████| 2585/2585 [00:00<00:00, 2726.26it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████| 7666/7666 [00:02<00:00, 2755.15it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_x length  2585\n",
      "train_x dimension of element  5000\n",
      "train_x (text) size RAW: 0.02104 megabytes\n",
      "train_y (labels) size RAW: 0.02104 megabytes\n",
      "test_x (text) size RAW: 0.061424 megabytes\n",
      "test_y (labels) size RAW: 0.061424 megabytes\n",
      "saved test_y\n",
      "train_x Size stays the same False\n",
      "train_y Size stays the same False\n",
      "test_x Size stays the same False\n",
      "test_y Size stays the same False\n",
      "train_xNPSize (text) size: 51.7 megabytes\n",
      "train_yNPSize (labels) size: 0.01034 megabytes\n",
      "test_xNPSize (text) size: 153.32 megabytes\n",
      "test_yNPSize (labels) size: 0.030664 megabytes\n",
      "train_xNP length  2585\n",
      "train_xNP dimension of element  2\n",
      "train_xNP size  12925000\n",
      "saving NP arrays\n",
      "NP arrays saved\n",
      "Initializing classifier\n",
      "Searching for a  RandomForestClassifier\n",
      "False\n",
      "file not found, creating new classifier\n",
      "this is the classifierName:  RandomForestClassifier\n",
      "Training...\n",
      "train_x (text) size: 51.7 megabytes\n",
      "train_y (labels) size: 0.01034 megabytes\n",
      "train_x (text) length: 2585\n",
      "train_y (labels) length: 2585\n",
      "[[0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " [1 1 1 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " [1 1 1 ... 0 0 0]]\n",
      "[2 0 0 0 0]\n",
      "finished training, classifier size: 4.8e-05 megabytes\n",
      "Predicting...\n",
      "Analysing...\n",
      "analyse_results\n",
      "hello\n",
      "Precision\t0.1436211844508218\n",
      "Recall\t0.1436211844508218\n",
      "F1-score\t0.1436211844508218\n",
      "Accuracy\t0.1436211844508218\n",
      "classiferSaveFile:  grounded_emotions_isearRandomForestClassifier.pkl\n",
      "Saved Successfully\n",
      "Total: 475 GiB\n",
      "Used: 306 GiB\n",
      "Free: 168 GiB\n",
      "-----------------------------------------------------------------------------------------\n",
      "('grounded_emotions', 'emotion-cause', 'tweets', 'paragraphs')\n",
      "Getting data\n",
      "get_train_test param:\n",
      "json  unified-dataset.jsonl\n",
      "train  grounded_emotions\n",
      "test  emotion-cause\n",
      "there were  2414  entries that were in test and  219025 that were not in test and  2585  that were in train\n",
      "test was appended  2414  times\n",
      "single\n",
      "oof\n",
      "Detected mode: single...\n",
      "2585 2414\n",
      "Getting wordlist...\n",
      "Getting emotions\n",
      "['joy', 'noemo', 'sadness']\n",
      "Making arrays\n",
      "checking for save files\n",
      "emotions in make_arrays:  {'joy': 0, 'noemo': 1, 'sadness': 2}\n",
      "train super raw:  0.02104\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████| 2585/2585 [00:01<00:00, 2179.64it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████| 2414/2414 [00:01<00:00, 2352.52it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_x length  2585\n",
      "train_x dimension of element  5000\n",
      "train_x (text) size RAW: 0.02104 megabytes\n",
      "train_y (labels) size RAW: 0.02104 megabytes\n",
      "test_x (text) size RAW: 0.02104 megabytes\n",
      "test_y (labels) size RAW: 0.02104 megabytes\n",
      "saved test_y\n",
      "train_x Size stays the same False\n",
      "train_y Size stays the same False\n",
      "test_x Size stays the same False\n",
      "test_y Size stays the same False\n",
      "train_xNPSize (text) size: 51.7 megabytes\n",
      "train_yNPSize (labels) size: 0.01034 megabytes\n",
      "test_xNPSize (text) size: 48.28 megabytes\n",
      "test_yNPSize (labels) size: 0.009656 megabytes\n",
      "train_xNP length  2585\n",
      "train_xNP dimension of element  2\n",
      "train_xNP size  12925000\n",
      "saving NP arrays\n",
      "NP arrays saved\n",
      "Initializing classifier\n",
      "Searching for a  RandomForestClassifier\n",
      "False\n",
      "file not found, creating new classifier\n",
      "this is the classifierName:  RandomForestClassifier\n",
      "Training...\n",
      "train_x (text) size: 51.7 megabytes\n",
      "train_y (labels) size: 0.01034 megabytes\n",
      "train_x (text) length: 2585\n",
      "train_y (labels) length: 2585\n",
      "[[0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " [1 1 1 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " [1 1 1 ... 0 0 0]]\n",
      "[2 0 0 0 0]\n",
      "finished training, classifier size: 4.8e-05 megabytes\n",
      "Predicting...\n",
      "Analysing...\n",
      "analyse_results\n",
      "hello\n",
      "Precision\t0.2067108533554267\n",
      "Recall\t0.2067108533554267\n",
      "F1-score\t0.20671085335542666\n",
      "Accuracy\t0.2067108533554267\n",
      "classiferSaveFile:  grounded_emotions_emotion-causeRandomForestClassifier.pkl\n",
      "Saved Successfully\n",
      "Total: 475 GiB\n",
      "Used: 306 GiB\n",
      "Free: 168 GiB\n",
      "-----------------------------------------------------------------------------------------\n",
      "('grounded_emotions', 'emoint', 'tweets', 'tweets')\n",
      "Getting data\n",
      "get_train_test param:\n",
      "json  unified-dataset.jsonl\n",
      "train  grounded_emotions\n",
      "test  emoint\n",
      "there were  7102  entries that were in test and  214337 that were not in test and  2585  that were in train\n",
      "test was appended  7102  times\n",
      "single\n",
      "oof\n",
      "Detected mode: single...\n",
      "2585 7102\n",
      "Getting wordlist...\n",
      "Getting emotions\n",
      "['joy', 'noemo', 'sadness']\n",
      "Making arrays\n",
      "checking for save files\n",
      "emotions in make_arrays:  {'joy': 0, 'noemo': 1, 'sadness': 2}\n",
      "train super raw:  0.02104\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████| 2585/2585 [00:00<00:00, 2749.05it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████| 7102/7102 [00:02<00:00, 2814.98it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_x length  2585\n",
      "train_x dimension of element  5000\n",
      "train_x (text) size RAW: 0.02104 megabytes\n",
      "train_y (labels) size RAW: 0.02104 megabytes\n",
      "test_x (text) size RAW: 0.061424 megabytes\n",
      "test_y (labels) size RAW: 0.061424 megabytes\n",
      "saved test_y\n",
      "train_x Size stays the same False\n",
      "train_y Size stays the same False\n",
      "test_x Size stays the same False\n",
      "test_y Size stays the same False\n",
      "train_xNPSize (text) size: 51.7 megabytes\n",
      "train_yNPSize (labels) size: 0.01034 megabytes\n",
      "test_xNPSize (text) size: 142.04 megabytes\n",
      "test_yNPSize (labels) size: 0.028408 megabytes\n",
      "train_xNP length  2585\n",
      "train_xNP dimension of element  2\n",
      "train_xNP size  12925000\n",
      "saving NP arrays\n",
      "NP arrays saved\n",
      "Initializing classifier\n",
      "Searching for a  RandomForestClassifier\n",
      "True\n",
      "Loading classifier from file\n",
      "classifier loaded successfully\n",
      "Predicting...\n",
      "Analysing...\n",
      "analyse_results\n",
      "hello\n",
      "Precision\t0.51957195156294\n",
      "Recall\t0.51957195156294\n",
      "F1-score\t0.51957195156294\n",
      "Accuracy\t0.51957195156294\n",
      "classifier already saved\n",
      "Total: 475 GiB\n",
      "Used: 306 GiB\n",
      "Free: 168 GiB\n",
      "-----------------------------------------------------------------------------------------\n",
      "('grounded_emotions', 'emobank', 'tweets', 'headlines')\n",
      "Getting data\n",
      "get_train_test param:\n",
      "json  unified-dataset.jsonl\n",
      "train  grounded_emotions\n",
      "test  emobank\n",
      "there were  10062  entries that were in test and  211377 that were not in test and  2585  that were in train\n",
      "test was appended  10062  times\n",
      "single\n",
      "Detected mode: multi...\n",
      "2585 10062\n",
      "Getting wordlist...\n",
      "Getting emotions\n",
      "[]\n",
      "Making arrays\n",
      "checking for save files\n",
      "emotions in make_arrays:  {}\n",
      "train super raw:  0.02104\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████| 2585/2585 [00:01<00:00, 2509.45it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████| 10062/10062 [00:03<00:00, 2612.86it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_x length  2585\n",
      "train_x dimension of element  5000\n",
      "train_x (text) size RAW: 0.02104 megabytes\n",
      "train_y (labels) size RAW: 0.02104 megabytes\n",
      "test_x (text) size RAW: 0.087616 megabytes\n",
      "test_y (labels) size RAW: 0.087616 megabytes\n",
      "saved test_y\n",
      "train_x Size stays the same False\n",
      "train_y Size stays the same False\n",
      "test_x Size stays the same False\n",
      "test_y Size stays the same False\n",
      "train_xNPSize (text) size: 51.7 megabytes\n",
      "train_yNPSize (labels) size: 0.0 megabytes\n",
      "test_xNPSize (text) size: 201.24 megabytes\n",
      "test_yNPSize (labels) size: 0.0 megabytes\n",
      "train_xNP length  2585\n",
      "train_xNP dimension of element  2\n",
      "train_xNP size  12925000\n",
      "Train or test empty. Did you misspell the dataset name?\n",
      "('grounded_emotions', 'dailydialog', 'tweets', 'conversations')\n",
      "Getting data\n",
      "get_train_test param:\n",
      "json  unified-dataset.jsonl\n",
      "train  grounded_emotions\n",
      "test  dailydialog\n",
      "there were  102979  entries that were in test and  118460 that were not in test and  2585  that were in train\n",
      "test was appended  102979  times\n",
      "single\n",
      "oof\n",
      "Detected mode: single...\n",
      "2585 102979\n",
      "Getting wordlist...\n",
      "Getting emotions\n",
      "['joy', 'noemo', 'sadness']\n",
      "Making arrays\n",
      "checking for save files\n",
      "emotions in make_arrays:  {'joy': 0, 'noemo': 1, 'sadness': 2}\n",
      "train super raw:  0.02104\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████| 2585/2585 [00:01<00:00, 2526.46it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████| 102979/102979 [00:43<00:00, 2380.23it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_x length  2585\n",
      "train_x dimension of element  5000\n",
      "train_x (text) size RAW: 0.02104 megabytes\n",
      "train_y (labels) size RAW: 0.02104 megabytes\n",
      "test_x (text) size RAW: 0.824456 megabytes\n",
      "test_y (labels) size RAW: 0.824456 megabytes\n",
      "saved test_y\n",
      "train_x Size stays the same False\n",
      "train_y Size stays the same False\n",
      "test_x Size stays the same False\n",
      "test_y Size stays the same False\n",
      "train_xNPSize (text) size: 51.7 megabytes\n",
      "train_yNPSize (labels) size: 0.01034 megabytes\n",
      "test_xNPSize (text) size: 2059.58 megabytes\n",
      "test_yNPSize (labels) size: 0.411916 megabytes\n",
      "train_xNP length  2585\n",
      "train_xNP dimension of element  2\n",
      "train_xNP size  12925000\n",
      "saving NP arrays\n",
      "NP arrays saved\n",
      "Initializing classifier\n",
      "Searching for a  RandomForestClassifier\n",
      "False\n",
      "file not found, creating new classifier\n",
      "this is the classifierName:  RandomForestClassifier\n",
      "Training...\n",
      "train_x (text) size: 51.7 megabytes\n",
      "train_y (labels) size: 0.01034 megabytes\n",
      "train_x (text) length: 2585\n",
      "train_y (labels) length: 2585\n",
      "[[0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " [1 1 1 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " [1 1 1 ... 0 0 0]]\n",
      "[2 0 0 0 0]\n",
      "finished training, classifier size: 4.8e-05 megabytes\n",
      "Predicting...\n",
      "Analysing...\n",
      "analyse_results\n",
      "hello\n",
      "Precision\t0.10083609279561852\n",
      "Recall\t0.10083609279561852\n",
      "F1-score\t0.10083609279561852\n",
      "Accuracy\t0.10083609279561852\n",
      "classiferSaveFile:  grounded_emotions_dailydialogRandomForestClassifier.pkl\n",
      "Saved Successfully\n",
      "Total: 475 GiB\n",
      "Used: 308 GiB\n",
      "Free: 166 GiB\n",
      "-----------------------------------------------------------------------------------------\n",
      "('grounded_emotions', 'crowdflower', 'tweets', 'tweets')\n",
      "Getting data\n",
      "get_train_test param:\n",
      "json  unified-dataset.jsonl\n",
      "train  grounded_emotions\n",
      "test  crowdflower\n",
      "there were  39740  entries that were in test and  181699 that were not in test and  2585  that were in train\n",
      "test was appended  39740  times\n",
      "single\n",
      "oof\n",
      "Detected mode: single...\n",
      "2585 39740\n",
      "Getting wordlist...\n",
      "Getting emotions\n",
      "['joy', 'noemo', 'sadness']\n",
      "Making arrays\n",
      "checking for save files\n",
      "emotions in make_arrays:  {'joy': 0, 'noemo': 1, 'sadness': 2}\n",
      "train super raw:  0.02104\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████| 2585/2585 [00:01<00:00, 2341.32it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████| 39740/39740 [00:15<00:00, 2501.68it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_x length  2585\n",
      "train_x dimension of element  5000\n",
      "train_x (text) size RAW: 0.02104 megabytes\n",
      "train_y (labels) size RAW: 0.02104 megabytes\n",
      "test_x (text) size RAW: 0.321096 megabytes\n",
      "test_y (labels) size RAW: 0.321096 megabytes\n",
      "saved test_y\n",
      "train_x Size stays the same False\n",
      "train_y Size stays the same False\n",
      "test_x Size stays the same False\n",
      "test_y Size stays the same False\n",
      "train_xNPSize (text) size: 51.7 megabytes\n",
      "train_yNPSize (labels) size: 0.01034 megabytes\n",
      "test_xNPSize (text) size: 794.8 megabytes\n",
      "test_yNPSize (labels) size: 0.15896 megabytes\n",
      "train_xNP length  2585\n",
      "train_xNP dimension of element  2\n",
      "train_xNP size  12925000\n",
      "saving NP arrays\n",
      "NP arrays saved\n",
      "Initializing classifier\n",
      "Searching for a  RandomForestClassifier\n",
      "False\n",
      "file not found, creating new classifier\n",
      "this is the classifierName:  RandomForestClassifier\n",
      "Training...\n",
      "train_x (text) size: 51.7 megabytes\n",
      "train_y (labels) size: 0.01034 megabytes\n",
      "train_x (text) length: 2585\n",
      "train_y (labels) length: 2585\n",
      "[[0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " [1 1 1 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " [1 1 1 ... 0 0 0]]\n",
      "[2 0 0 0 0]\n",
      "finished training, classifier size: 4.8e-05 megabytes\n",
      "Predicting...\n",
      "Analysing...\n",
      "analyse_results\n",
      "hello\n",
      "Precision\t0.21474584801207852\n",
      "Recall\t0.21474584801207852\n",
      "F1-score\t0.2147458480120785\n",
      "Accuracy\t0.21474584801207852\n",
      "classiferSaveFile:  grounded_emotions_crowdflowerRandomForestClassifier.pkl\n",
      "Saved Successfully\n",
      "Total: 475 GiB\n",
      "Used: 309 GiB\n",
      "Free: 165 GiB\n",
      "-----------------------------------------------------------------------------------------\n",
      "('grounded_emotions', 'affectivetext', 'tweets', 'headlines')\n",
      "Getting data\n",
      "get_train_test param:\n",
      "json  unified-dataset.jsonl\n",
      "train  grounded_emotions\n",
      "test  affectivetext\n",
      "there were  1250  entries that were in test and  220189 that were not in test and  2585  that were in train\n",
      "test was appended  1250  times\n",
      "single\n",
      "Detected mode: multi...\n",
      "2585 1250\n",
      "Getting wordlist...\n",
      "Getting emotions\n",
      "['joy', 'sadness']\n",
      "Making arrays\n",
      "checking for save files\n",
      "emotions in make_arrays:  {'joy': 0, 'sadness': 1}\n",
      "train super raw:  0.02104\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████| 2585/2585 [00:01<00:00, 2185.10it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████| 1250/1250 [00:00<00:00, 2372.45it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_x length  2585\n",
      "train_x dimension of element  5000\n",
      "train_x (text) size RAW: 0.02104 megabytes\n",
      "train_y (labels) size RAW: 0.02104 megabytes\n",
      "test_x (text) size RAW: 0.010192 megabytes\n",
      "test_y (labels) size RAW: 0.010192 megabytes\n",
      "saved test_y\n",
      "train_x Size stays the same False\n",
      "train_y Size stays the same False\n",
      "test_x Size stays the same False\n",
      "test_y Size stays the same False\n",
      "train_xNPSize (text) size: 51.7 megabytes\n",
      "train_yNPSize (labels) size: 0.02068 megabytes\n",
      "test_xNPSize (text) size: 25.0 megabytes\n",
      "test_yNPSize (labels) size: 0.01 megabytes\n",
      "train_xNP length  2585\n",
      "train_xNP dimension of element  2\n",
      "train_xNP size  12925000\n",
      "saving NP arrays\n",
      "NP arrays saved\n",
      "Initializing classifier\n",
      "Searching for a  RandomForestClassifier\n",
      "True\n",
      "Loading classifier from file\n",
      "classifier loaded successfully\n",
      "Predicting...\n",
      "Analysing...\n",
      "analyse_results\n",
      "hello\n",
      "Precision\t0.524\n",
      "Recall\t0.5161544523246651\n",
      "F1-score\t0.5200476379515682\n",
      "Accuracy\t0.3896\n",
      "classifier already saved\n",
      "Total: 475 GiB\n",
      "Used: 309 GiB\n",
      "Free: 165 GiB\n",
      "-----------------------------------------------------------------------------------------\n",
      "('emoint', 'tec', 'tweets', 'tweets')\n",
      "Getting data\n",
      "get_train_test param:\n",
      "json  unified-dataset.jsonl\n",
      "train  emoint\n",
      "test  tec\n",
      "there were  21051  entries that were in test and  200388 that were not in test and  7102  that were in train\n",
      "test was appended  21051  times\n",
      "single\n",
      "oof\n",
      "Detected mode: single...\n",
      "7102 21051\n",
      "Getting wordlist...\n",
      "Getting emotions\n",
      "['anger', 'joy', 'noemo', 'sadness', 'fear']\n",
      "Making arrays\n",
      "checking for save files\n",
      "emotions in make_arrays:  {'anger': 0, 'joy': 1, 'noemo': 2, 'sadness': 3, 'fear': 4}\n",
      "train super raw:  0.061424\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████| 7102/7102 [00:03<00:00, 1896.70it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████| 21051/21051 [00:09<00:00, 2168.89it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_x length  7102\n",
      "train_x dimension of element  5000\n",
      "train_x (text) size RAW: 0.061424 megabytes\n",
      "train_y (labels) size RAW: 0.061424 megabytes\n",
      "test_x (text) size RAW: 0.178016 megabytes\n",
      "test_y (labels) size RAW: 0.178016 megabytes\n",
      "saved test_y\n",
      "train_x Size stays the same False\n",
      "train_y Size stays the same False\n",
      "test_x Size stays the same False\n",
      "test_y Size stays the same False\n",
      "train_xNPSize (text) size: 142.04 megabytes\n",
      "train_yNPSize (labels) size: 0.028408 megabytes\n",
      "test_xNPSize (text) size: 421.02 megabytes\n",
      "test_yNPSize (labels) size: 0.084204 megabytes\n",
      "train_xNP length  7102\n",
      "train_xNP dimension of element  2\n",
      "train_xNP size  35510000\n",
      "saving NP arrays\n",
      "NP arrays saved\n",
      "Initializing classifier\n",
      "Searching for a  RandomForestClassifier\n",
      "False\n",
      "file not found, creating new classifier\n",
      "this is the classifierName:  RandomForestClassifier\n",
      "Training...\n",
      "train_x (text) size: 142.04 megabytes\n",
      "train_y (labels) size: 0.028408 megabytes\n",
      "train_x (text) length: 7102\n",
      "train_y (labels) length: 7102\n",
      "[[1 0 0 ... 0 0 0]\n",
      " [0 1 1 ... 0 0 0]\n",
      " [0 0 1 ... 0 0 0]\n",
      " [0 1 0 ... 0 0 0]\n",
      " [0 1 1 ... 0 0 0]]\n",
      "[0 0 0 0 0]\n",
      "finished training, classifier size: 4.8e-05 megabytes\n",
      "Predicting...\n",
      "Analysing...\n",
      "analyse_results\n",
      "hello\n",
      "Precision\t0.20526340791411335\n",
      "Recall\t0.20526340791411335\n",
      "F1-score\t0.20526340791411332\n",
      "Accuracy\t0.20526340791411335\n",
      "classiferSaveFile:  emoint_tecRandomForestClassifier.pkl\n",
      "Saved Successfully\n",
      "Total: 475 GiB\n",
      "Used: 309 GiB\n",
      "Free: 165 GiB\n",
      "-----------------------------------------------------------------------------------------\n",
      "('emoint', 'tales-emotion', 'tweets', 'tales')\n",
      "Getting data\n",
      "get_train_test param:\n",
      "json  unified-dataset.jsonl\n",
      "train  emoint\n",
      "test  tales-emotion\n",
      "there were  14771  entries that were in test and  206668 that were not in test and  7102  that were in train\n",
      "test was appended  14771  times\n",
      "single\n",
      "oof\n",
      "Detected mode: single...\n",
      "7102 14771\n",
      "Getting wordlist...\n",
      "Getting emotions\n",
      "['anger', 'joy', 'noemo', 'sadness', 'fear']\n",
      "Making arrays\n",
      "checking for save files\n",
      "emotions in make_arrays:  {'anger': 0, 'joy': 1, 'noemo': 2, 'sadness': 3, 'fear': 4}\n",
      "train super raw:  0.061424\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████| 7102/7102 [00:02<00:00, 2721.35it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████| 14771/14771 [00:05<00:00, 2609.47it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_x length  7102\n",
      "train_x dimension of element  5000\n",
      "train_x (text) size RAW: 0.061424 megabytes\n",
      "train_y (labels) size RAW: 0.061424 megabytes\n",
      "test_x (text) size RAW: 0.124912 megabytes\n",
      "test_y (labels) size RAW: 0.124912 megabytes\n",
      "saved test_y\n",
      "train_x Size stays the same False\n",
      "train_y Size stays the same False\n",
      "test_x Size stays the same False\n",
      "test_y Size stays the same False\n",
      "train_xNPSize (text) size: 142.04 megabytes\n",
      "train_yNPSize (labels) size: 0.028408 megabytes\n",
      "test_xNPSize (text) size: 295.42 megabytes\n",
      "test_yNPSize (labels) size: 0.059084 megabytes\n",
      "train_xNP length  7102\n",
      "train_xNP dimension of element  2\n",
      "train_xNP size  35510000\n",
      "saving NP arrays\n",
      "NP arrays saved\n",
      "Initializing classifier\n",
      "Searching for a  RandomForestClassifier\n",
      "False\n",
      "file not found, creating new classifier\n",
      "this is the classifierName:  RandomForestClassifier\n",
      "Training...\n",
      "train_x (text) size: 142.04 megabytes\n",
      "train_y (labels) size: 0.028408 megabytes\n",
      "train_x (text) length: 7102\n",
      "train_y (labels) length: 7102\n",
      "[[1 0 0 ... 0 0 0]\n",
      " [0 1 1 ... 0 0 0]\n",
      " [0 0 1 ... 0 0 0]\n",
      " [0 1 0 ... 0 0 0]\n",
      " [0 1 1 ... 0 0 0]]\n",
      "[0 0 0 0 0]\n",
      "finished training, classifier size: 4.8e-05 megabytes\n",
      "Predicting...\n",
      "Analysing...\n",
      "analyse_results\n",
      "hello\n",
      "Precision\t0.08036016518854512\n",
      "Recall\t0.08036016518854512\n",
      "F1-score\t0.08036016518854512\n",
      "Accuracy\t0.08036016518854512\n",
      "classiferSaveFile:  emoint_tales-emotionRandomForestClassifier.pkl\n",
      "Saved Successfully\n",
      "Total: 475 GiB\n",
      "Used: 310 GiB\n",
      "Free: 164 GiB\n",
      "-----------------------------------------------------------------------------------------\n",
      "('emoint', 'ssec', 'tweets', 'tweets')\n",
      "Getting data\n",
      "get_train_test param:\n",
      "json  unified-dataset.jsonl\n",
      "train  emoint\n",
      "test  ssec\n",
      "there were  4868  entries that were in test and  216571 that were not in test and  7102  that were in train\n",
      "test was appended  4868  times\n",
      "single\n",
      "Detected mode: multi...\n",
      "7102 4868\n",
      "Getting wordlist...\n",
      "Getting emotions\n",
      "['joy', 'sadness', 'anger', 'fear']\n",
      "Making arrays\n",
      "checking for save files\n",
      "emotions in make_arrays:  {'joy': 0, 'sadness': 1, 'anger': 2, 'fear': 3}\n",
      "train super raw:  0.061424\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████| 7102/7102 [00:02<00:00, 2722.38it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████| 4868/4868 [00:01<00:00, 2613.24it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_x length  7102\n",
      "train_x dimension of element  5000\n",
      "train_x (text) size RAW: 0.061424 megabytes\n",
      "train_y (labels) size RAW: 0.061424 megabytes\n",
      "test_x (text) size RAW: 0.043032 megabytes\n",
      "test_y (labels) size RAW: 0.043032 megabytes\n",
      "saved test_y\n",
      "train_x Size stays the same False\n",
      "train_y Size stays the same False\n",
      "test_x Size stays the same False\n",
      "test_y Size stays the same False\n",
      "train_xNPSize (text) size: 142.04 megabytes\n",
      "train_yNPSize (labels) size: 0.113632 megabytes\n",
      "test_xNPSize (text) size: 97.36 megabytes\n",
      "test_yNPSize (labels) size: 0.077888 megabytes\n",
      "train_xNP length  7102\n",
      "train_xNP dimension of element  2\n",
      "train_xNP size  35510000\n",
      "saving NP arrays\n",
      "NP arrays saved\n",
      "Initializing classifier\n",
      "Searching for a  RandomForestClassifier\n",
      "False\n",
      "file not found, creating new classifier\n",
      "this is the classifierName:  RandomForestClassifier\n",
      "Training...\n",
      "train_x (text) size: 142.04 megabytes\n",
      "train_y (labels) size: 0.113632 megabytes\n",
      "train_x (text) length: 7102\n",
      "train_y (labels) length: 7102\n",
      "[[1 0 0 ... 0 0 0]\n",
      " [0 1 1 ... 0 0 0]\n",
      " [0 0 1 ... 0 0 0]\n",
      " [0 1 0 ... 0 0 0]\n",
      " [0 1 1 ... 0 0 0]]\n",
      "[[0 0 1 0]\n",
      " [0 0 1 0]\n",
      " [0 0 1 0]\n",
      " [0 0 1 0]\n",
      " [0 0 1 0]]\n",
      "finished training, classifier size: 4.8e-05 megabytes\n",
      "Predicting...\n",
      "Analysing...\n",
      "analyse_results\n",
      "hello\n",
      "Precision\t0.434939216569113\n",
      "Recall\t0.10218978102189781\n",
      "F1-score\t0.1654959739592256\n",
      "Accuracy\t0.04560394412489729\n",
      "classiferSaveFile:  emoint_ssecRandomForestClassifier.pkl\n",
      "Saved Successfully\n",
      "Total: 475 GiB\n",
      "Used: 310 GiB\n",
      "Free: 164 GiB\n",
      "-----------------------------------------------------------------------------------------\n",
      "('emoint', 'isear', 'tweets', 'descriptions')\n",
      "Getting data\n",
      "get_train_test param:\n",
      "json  unified-dataset.jsonl\n",
      "train  emoint\n",
      "test  isear\n",
      "there were  7666  entries that were in test and  213773 that were not in test and  7102  that were in train\n",
      "test was appended  7666  times\n",
      "single\n",
      "oof\n",
      "Detected mode: single...\n",
      "7102 7666\n",
      "Getting wordlist...\n",
      "Getting emotions\n",
      "['anger', 'joy', 'noemo', 'sadness', 'fear']\n",
      "Making arrays\n",
      "checking for save files\n",
      "emotions in make_arrays:  {'anger': 0, 'joy': 1, 'noemo': 2, 'sadness': 3, 'fear': 4}\n",
      "train super raw:  0.061424\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████| 7102/7102 [00:02<00:00, 2653.12it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████| 7666/7666 [00:02<00:00, 2649.03it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_x length  7102\n",
      "train_x dimension of element  5000\n",
      "train_x (text) size RAW: 0.061424 megabytes\n",
      "train_y (labels) size RAW: 0.061424 megabytes\n",
      "test_x (text) size RAW: 0.061424 megabytes\n",
      "test_y (labels) size RAW: 0.061424 megabytes\n",
      "saved test_y\n",
      "train_x Size stays the same False\n",
      "train_y Size stays the same False\n",
      "test_x Size stays the same False\n",
      "test_y Size stays the same False\n",
      "train_xNPSize (text) size: 142.04 megabytes\n",
      "train_yNPSize (labels) size: 0.028408 megabytes\n",
      "test_xNPSize (text) size: 153.32 megabytes\n",
      "test_yNPSize (labels) size: 0.030664 megabytes\n",
      "train_xNP length  7102\n",
      "train_xNP dimension of element  2\n",
      "train_xNP size  35510000\n",
      "saving NP arrays\n",
      "NP arrays saved\n",
      "Initializing classifier\n",
      "Searching for a  RandomForestClassifier\n",
      "False\n",
      "file not found, creating new classifier\n",
      "this is the classifierName:  RandomForestClassifier\n",
      "Training...\n",
      "train_x (text) size: 142.04 megabytes\n",
      "train_y (labels) size: 0.028408 megabytes\n",
      "train_x (text) length: 7102\n",
      "train_y (labels) length: 7102\n",
      "[[1 0 0 ... 0 0 0]\n",
      " [0 1 1 ... 0 0 0]\n",
      " [0 0 1 ... 0 0 0]\n",
      " [0 1 0 ... 0 0 0]\n",
      " [0 1 1 ... 0 0 0]]\n",
      "[0 0 0 0 0]\n",
      "finished training, classifier size: 4.8e-05 megabytes\n",
      "Predicting...\n",
      "Analysing...\n",
      "analyse_results\n",
      "hello\n",
      "Precision\t0.2148447691103574\n",
      "Recall\t0.2148447691103574\n",
      "F1-score\t0.2148447691103574\n",
      "Accuracy\t0.2148447691103574\n",
      "classiferSaveFile:  emoint_isearRandomForestClassifier.pkl\n",
      "Saved Successfully\n",
      "Total: 475 GiB\n",
      "Used: 310 GiB\n",
      "Free: 164 GiB\n",
      "-----------------------------------------------------------------------------------------\n",
      "('emoint', 'grounded_emotions', 'tweets', 'tweets')\n",
      "Getting data\n",
      "get_train_test param:\n",
      "json  unified-dataset.jsonl\n",
      "train  emoint\n",
      "test  grounded_emotions\n",
      "there were  2585  entries that were in test and  218854 that were not in test and  7102  that were in train\n",
      "test was appended  2585  times\n",
      "single\n",
      "oof\n",
      "Detected mode: single...\n",
      "7102 2585\n",
      "Getting wordlist...\n",
      "Getting emotions\n",
      "['joy', 'noemo', 'sadness']\n",
      "Making arrays\n",
      "checking for save files\n",
      "emotions in make_arrays:  {'joy': 0, 'noemo': 1, 'sadness': 2}\n",
      "train super raw:  0.061424\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████| 7102/7102 [00:02<00:00, 2721.35it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████| 2585/2585 [00:00<00:00, 2746.19it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_x length  7102\n",
      "train_x dimension of element  5000\n",
      "train_x (text) size RAW: 0.061424 megabytes\n",
      "train_y (labels) size RAW: 0.061424 megabytes\n",
      "test_x (text) size RAW: 0.02104 megabytes\n",
      "test_y (labels) size RAW: 0.02104 megabytes\n",
      "saved test_y\n",
      "train_x Size stays the same False\n",
      "train_y Size stays the same False\n",
      "test_x Size stays the same False\n",
      "test_y Size stays the same False\n",
      "train_xNPSize (text) size: 142.04 megabytes\n",
      "train_yNPSize (labels) size: 0.028408 megabytes\n",
      "test_xNPSize (text) size: 51.7 megabytes\n",
      "test_yNPSize (labels) size: 0.01034 megabytes\n",
      "train_xNP length  7102\n",
      "train_xNP dimension of element  2\n",
      "train_xNP size  35510000\n",
      "saving NP arrays\n",
      "NP arrays saved\n",
      "Initializing classifier\n",
      "Searching for a  RandomForestClassifier\n",
      "False\n",
      "file not found, creating new classifier\n",
      "this is the classifierName:  RandomForestClassifier\n",
      "Training...\n",
      "train_x (text) size: 142.04 megabytes\n",
      "train_y (labels) size: 0.028408 megabytes\n",
      "train_x (text) length: 7102\n",
      "train_y (labels) length: 7102\n",
      "[[1 0 0 ... 0 0 0]\n",
      " [0 1 1 ... 0 0 0]\n",
      " [0 0 1 ... 0 0 0]\n",
      " [0 1 0 ... 0 0 0]\n",
      " [0 1 1 ... 0 0 0]]\n",
      "[1 1 1 1 1]\n",
      "finished training, classifier size: 4.8e-05 megabytes\n",
      "Predicting...\n",
      "Analysing...\n",
      "analyse_results\n",
      "hello\n",
      "Precision\t0.07040618955512573\n",
      "Recall\t0.07040618955512573\n",
      "F1-score\t0.07040618955512573\n",
      "Accuracy\t0.07040618955512573\n",
      "classiferSaveFile:  emoint_grounded_emotionsRandomForestClassifier.pkl\n",
      "Saved Successfully\n",
      "Total: 475 GiB\n",
      "Used: 311 GiB\n",
      "Free: 164 GiB\n",
      "-----------------------------------------------------------------------------------------\n",
      "('emoint', 'emotion-cause', 'tweets', 'paragraphs')\n",
      "Getting data\n",
      "get_train_test param:\n",
      "json  unified-dataset.jsonl\n",
      "train  emoint\n",
      "test  emotion-cause\n",
      "there were  2414  entries that were in test and  219025 that were not in test and  7102  that were in train\n",
      "test was appended  2414  times\n",
      "single\n",
      "oof\n",
      "Detected mode: single...\n",
      "7102 2414\n",
      "Getting wordlist...\n",
      "Getting emotions\n",
      "['anger', 'joy', 'noemo', 'sadness', 'fear']\n",
      "Making arrays\n",
      "checking for save files\n",
      "emotions in make_arrays:  {'anger': 0, 'joy': 1, 'noemo': 2, 'sadness': 3, 'fear': 4}\n",
      "train super raw:  0.061424\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████| 7102/7102 [00:02<00:00, 2708.02it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████| 2414/2414 [00:00<00:00, 2506.79it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_x length  7102\n",
      "train_x dimension of element  5000\n",
      "train_x (text) size RAW: 0.061424 megabytes\n",
      "train_y (labels) size RAW: 0.061424 megabytes\n",
      "test_x (text) size RAW: 0.02104 megabytes\n",
      "test_y (labels) size RAW: 0.02104 megabytes\n",
      "saved test_y\n",
      "train_x Size stays the same False\n",
      "train_y Size stays the same False\n",
      "test_x Size stays the same False\n",
      "test_y Size stays the same False\n",
      "train_xNPSize (text) size: 142.04 megabytes\n",
      "train_yNPSize (labels) size: 0.028408 megabytes\n",
      "test_xNPSize (text) size: 48.28 megabytes\n",
      "test_yNPSize (labels) size: 0.009656 megabytes\n",
      "train_xNP length  7102\n",
      "train_xNP dimension of element  2\n",
      "train_xNP size  35510000\n",
      "saving NP arrays\n",
      "NP arrays saved\n",
      "Initializing classifier\n",
      "Searching for a  RandomForestClassifier\n",
      "False\n",
      "file not found, creating new classifier\n",
      "this is the classifierName:  RandomForestClassifier\n",
      "Training...\n",
      "train_x (text) size: 142.04 megabytes\n",
      "train_y (labels) size: 0.028408 megabytes\n",
      "train_x (text) length: 7102\n",
      "train_y (labels) length: 7102\n",
      "[[1 0 0 ... 0 0 0]\n",
      " [0 1 1 ... 0 0 0]\n",
      " [0 0 1 ... 0 0 0]\n",
      " [0 1 0 ... 0 0 0]\n",
      " [0 1 1 ... 0 0 0]]\n",
      "[0 0 0 0 0]\n",
      "finished training, classifier size: 4.8e-05 megabytes\n",
      "Predicting...\n",
      "Analysing...\n",
      "analyse_results\n",
      "hello\n",
      "Precision\t0.35501242750621376\n",
      "Recall\t0.35501242750621376\n",
      "F1-score\t0.35501242750621376\n",
      "Accuracy\t0.35501242750621376\n",
      "classiferSaveFile:  emoint_emotion-causeRandomForestClassifier.pkl\n",
      "Saved Successfully\n",
      "Total: 475 GiB\n",
      "Used: 311 GiB\n",
      "Free: 163 GiB\n",
      "-----------------------------------------------------------------------------------------\n",
      "('emoint', 'emobank', 'tweets', 'headlines')\n",
      "Getting data\n",
      "get_train_test param:\n",
      "json  unified-dataset.jsonl\n",
      "train  emoint\n",
      "test  emobank\n",
      "there were  10062  entries that were in test and  211377 that were not in test and  7102  that were in train\n",
      "test was appended  10062  times\n",
      "single\n",
      "Detected mode: multi...\n",
      "7102 10062\n",
      "Getting wordlist...\n",
      "Getting emotions\n",
      "[]\n",
      "Making arrays\n",
      "checking for save files\n",
      "emotions in make_arrays:  {}\n",
      "train super raw:  0.061424\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████| 7102/7102 [00:02<00:00, 2635.66it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████| 10062/10062 [00:03<00:00, 2560.38it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_x length  7102\n",
      "train_x dimension of element  5000\n",
      "train_x (text) size RAW: 0.061424 megabytes\n",
      "train_y (labels) size RAW: 0.061424 megabytes\n",
      "test_x (text) size RAW: 0.087616 megabytes\n",
      "test_y (labels) size RAW: 0.087616 megabytes\n",
      "saved test_y\n",
      "train_x Size stays the same False\n",
      "train_y Size stays the same False\n",
      "test_x Size stays the same False\n",
      "test_y Size stays the same False\n",
      "train_xNPSize (text) size: 142.04 megabytes\n",
      "train_yNPSize (labels) size: 0.0 megabytes\n",
      "test_xNPSize (text) size: 201.24 megabytes\n",
      "test_yNPSize (labels) size: 0.0 megabytes\n",
      "train_xNP length  7102\n",
      "train_xNP dimension of element  2\n",
      "train_xNP size  35510000\n",
      "Train or test empty. Did you misspell the dataset name?\n",
      "('emoint', 'dailydialog', 'tweets', 'conversations')\n",
      "Getting data\n",
      "get_train_test param:\n",
      "json  unified-dataset.jsonl\n",
      "train  emoint\n",
      "test  dailydialog\n",
      "there were  102979  entries that were in test and  118460 that were not in test and  7102  that were in train\n",
      "test was appended  102979  times\n",
      "single\n",
      "oof\n",
      "Detected mode: single...\n",
      "7102 102979\n",
      "Getting wordlist...\n",
      "Getting emotions\n",
      "['anger', 'joy', 'noemo', 'sadness', 'fear']\n",
      "Making arrays\n",
      "checking for save files\n",
      "emotions in make_arrays:  {'anger': 0, 'joy': 1, 'noemo': 2, 'sadness': 3, 'fear': 4}\n",
      "train super raw:  0.061424\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████| 7102/7102 [00:02<00:00, 2766.32it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████| 102979/102979 [00:41<00:00, 2484.57it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_x length  7102\n",
      "train_x dimension of element  5000\n",
      "train_x (text) size RAW: 0.061424 megabytes\n",
      "train_y (labels) size RAW: 0.061424 megabytes\n",
      "test_x (text) size RAW: 0.824456 megabytes\n",
      "test_y (labels) size RAW: 0.824456 megabytes\n",
      "saved test_y\n",
      "train_x Size stays the same False\n",
      "train_y Size stays the same False\n",
      "test_x Size stays the same False\n",
      "test_y Size stays the same False\n",
      "train_xNPSize (text) size: 142.04 megabytes\n",
      "train_yNPSize (labels) size: 0.028408 megabytes\n",
      "test_xNPSize (text) size: 2059.58 megabytes\n",
      "test_yNPSize (labels) size: 0.411916 megabytes\n",
      "train_xNP length  7102\n",
      "train_xNP dimension of element  2\n",
      "train_xNP size  35510000\n",
      "saving NP arrays\n",
      "NP arrays saved\n",
      "Initializing classifier\n",
      "Searching for a  RandomForestClassifier\n",
      "False\n",
      "file not found, creating new classifier\n",
      "this is the classifierName:  RandomForestClassifier\n",
      "Training...\n",
      "train_x (text) size: 142.04 megabytes\n",
      "train_y (labels) size: 0.028408 megabytes\n",
      "train_x (text) length: 7102\n",
      "train_y (labels) length: 7102\n",
      "[[1 0 0 ... 0 0 0]\n",
      " [0 1 1 ... 0 0 0]\n",
      " [0 0 1 ... 0 0 0]\n",
      " [0 1 0 ... 0 0 0]\n",
      " [0 1 1 ... 0 0 0]]\n",
      "[0 0 0 0 0]\n",
      "finished training, classifier size: 4.8e-05 megabytes\n",
      "Predicting...\n",
      "Analysing...\n",
      "analyse_results\n",
      "hello\n",
      "Precision\t0.014109672845920043\n",
      "Recall\t0.014109672845920043\n",
      "F1-score\t0.014109672845920043\n",
      "Accuracy\t0.014109672845920043\n",
      "classiferSaveFile:  emoint_dailydialogRandomForestClassifier.pkl\n",
      "Saved Successfully\n",
      "Total: 475 GiB\n",
      "Used: 313 GiB\n",
      "Free: 161 GiB\n",
      "-----------------------------------------------------------------------------------------\n",
      "('emoint', 'crowdflower', 'tweets', 'tweets')\n",
      "Getting data\n",
      "get_train_test param:\n",
      "json  unified-dataset.jsonl\n",
      "train  emoint\n",
      "test  crowdflower\n",
      "there were  39740  entries that were in test and  181699 that were not in test and  7102  that were in train\n",
      "test was appended  39740  times\n",
      "single\n",
      "oof\n",
      "Detected mode: single...\n",
      "7102 39740\n",
      "Getting wordlist...\n",
      "Getting emotions\n",
      "['anger', 'joy', 'noemo', 'sadness', 'fear']\n",
      "Making arrays\n",
      "checking for save files\n",
      "emotions in make_arrays:  {'anger': 0, 'joy': 1, 'noemo': 2, 'sadness': 3, 'fear': 4}\n",
      "train super raw:  0.061424\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████| 7102/7102 [00:02<00:00, 2690.83it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████| 39740/39740 [00:15<00:00, 2555.97it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_x length  7102\n",
      "train_x dimension of element  5000\n",
      "train_x (text) size RAW: 0.061424 megabytes\n",
      "train_y (labels) size RAW: 0.061424 megabytes\n",
      "test_x (text) size RAW: 0.321096 megabytes\n",
      "test_y (labels) size RAW: 0.321096 megabytes\n",
      "saved test_y\n",
      "train_x Size stays the same False\n",
      "train_y Size stays the same False\n",
      "test_x Size stays the same False\n",
      "test_y Size stays the same False\n",
      "train_xNPSize (text) size: 142.04 megabytes\n",
      "train_yNPSize (labels) size: 0.028408 megabytes\n",
      "test_xNPSize (text) size: 794.8 megabytes\n",
      "test_yNPSize (labels) size: 0.15896 megabytes\n",
      "train_xNP length  7102\n",
      "train_xNP dimension of element  2\n",
      "train_xNP size  35510000\n",
      "saving NP arrays\n",
      "NP arrays saved\n",
      "Initializing classifier\n",
      "Searching for a  RandomForestClassifier\n",
      "False\n",
      "file not found, creating new classifier\n",
      "this is the classifierName:  RandomForestClassifier\n",
      "Training...\n",
      "train_x (text) size: 142.04 megabytes\n",
      "train_y (labels) size: 0.028408 megabytes\n",
      "train_x (text) length: 7102\n",
      "train_y (labels) length: 7102\n",
      "[[1 0 0 ... 0 0 0]\n",
      " [0 1 1 ... 0 0 0]\n",
      " [0 0 1 ... 0 0 0]\n",
      " [0 1 0 ... 0 0 0]\n",
      " [0 1 1 ... 0 0 0]]\n",
      "[0 0 0 0 0]\n",
      "finished training, classifier size: 4.8e-05 megabytes\n",
      "Predicting...\n",
      "Analysing...\n",
      "analyse_results\n",
      "hello\n",
      "Precision\t0.2301711122294917\n",
      "Recall\t0.2301711122294917\n",
      "F1-score\t0.2301711122294917\n",
      "Accuracy\t0.2301711122294917\n",
      "classiferSaveFile:  emoint_crowdflowerRandomForestClassifier.pkl\n",
      "Saved Successfully\n",
      "Total: 475 GiB\n",
      "Used: 314 GiB\n",
      "Free: 160 GiB\n",
      "-----------------------------------------------------------------------------------------\n",
      "('emoint', 'affectivetext', 'tweets', 'headlines')\n",
      "Getting data\n",
      "get_train_test param:\n",
      "json  unified-dataset.jsonl\n",
      "train  emoint\n",
      "test  affectivetext\n",
      "there were  1250  entries that were in test and  220189 that were not in test and  7102  that were in train\n",
      "test was appended  1250  times\n",
      "single\n",
      "Detected mode: multi...\n",
      "7102 1250\n",
      "Getting wordlist...\n",
      "Getting emotions\n",
      "['joy', 'sadness', 'anger', 'fear']\n",
      "Making arrays\n",
      "checking for save files\n",
      "emotions in make_arrays:  {'joy': 0, 'sadness': 1, 'anger': 2, 'fear': 3}\n",
      "train super raw:  0.061424\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████| 7102/7102 [00:02<00:00, 2718.27it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████| 1250/1250 [00:00<00:00, 2853.36it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_x length  7102\n",
      "train_x dimension of element  5000\n",
      "train_x (text) size RAW: 0.061424 megabytes\n",
      "train_y (labels) size RAW: 0.061424 megabytes\n",
      "test_x (text) size RAW: 0.010192 megabytes\n",
      "test_y (labels) size RAW: 0.010192 megabytes\n",
      "saved test_y\n",
      "train_x Size stays the same False\n",
      "train_y Size stays the same False\n",
      "test_x Size stays the same False\n",
      "test_y Size stays the same False\n",
      "train_xNPSize (text) size: 142.04 megabytes\n",
      "train_yNPSize (labels) size: 0.113632 megabytes\n",
      "test_xNPSize (text) size: 25.0 megabytes\n",
      "test_yNPSize (labels) size: 0.02 megabytes\n",
      "train_xNP length  7102\n",
      "train_xNP dimension of element  2\n",
      "train_xNP size  35510000\n",
      "saving NP arrays\n",
      "NP arrays saved\n",
      "Initializing classifier\n",
      "Searching for a  RandomForestClassifier\n",
      "False\n",
      "file not found, creating new classifier\n",
      "this is the classifierName:  RandomForestClassifier\n",
      "Training...\n",
      "train_x (text) size: 142.04 megabytes\n",
      "train_y (labels) size: 0.113632 megabytes\n",
      "train_x (text) length: 7102\n",
      "train_y (labels) length: 7102\n",
      "[[1 0 0 ... 0 0 0]\n",
      " [0 1 1 ... 0 0 0]\n",
      " [0 0 1 ... 0 0 0]\n",
      " [0 1 0 ... 0 0 0]\n",
      " [0 1 1 ... 0 0 0]]\n",
      "[[0 0 1 0]\n",
      " [0 0 1 0]\n",
      " [0 0 1 0]\n",
      " [0 0 1 0]\n",
      " [0 0 1 0]]\n",
      "finished training, classifier size: 4.8e-05 megabytes\n",
      "Predicting...\n",
      "Analysing...\n",
      "analyse_results\n",
      "hello\n",
      "Precision\t0.44801512287334594\n",
      "Recall\t0.21743119266055047\n",
      "F1-score\t0.29277331686226066\n",
      "Accuracy\t0.0368\n",
      "classiferSaveFile:  emoint_affectivetextRandomForestClassifier.pkl\n",
      "Saved Successfully\n",
      "Total: 475 GiB\n",
      "Used: 314 GiB\n",
      "Free: 160 GiB\n",
      "-----------------------------------------------------------------------------------------\n",
      "('crowdflower', 'tec', 'tweets', 'tweets')\n",
      "Getting data\n",
      "get_train_test param:\n",
      "json  unified-dataset.jsonl\n",
      "train  crowdflower\n",
      "test  tec\n",
      "there were  21051  entries that were in test and  200388 that were not in test and  39740  that were in train\n",
      "test was appended  21051  times\n",
      "single\n",
      "oof\n",
      "Detected mode: single...\n",
      "39740 21051\n",
      "Getting wordlist...\n",
      "Getting emotions\n",
      "['anger', 'joy', 'noemo', 'surprise', 'disgust', 'sadness', 'fear']\n",
      "Making arrays\n",
      "checking for save files\n",
      "emotions in make_arrays:  {'anger': 0, 'joy': 1, 'noemo': 2, 'surprise': 3, 'disgust': 4, 'sadness': 5, 'fear': 6}\n",
      "train super raw:  0.321096\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████| 39740/39740 [00:15<00:00, 2561.66it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████| 21051/21051 [00:08<00:00, 2434.45it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_x length  39740\n",
      "train_x dimension of element  5000\n",
      "train_x (text) size RAW: 0.321096 megabytes\n",
      "train_y (labels) size RAW: 0.321096 megabytes\n",
      "test_x (text) size RAW: 0.178016 megabytes\n",
      "test_y (labels) size RAW: 0.178016 megabytes\n",
      "saved test_y\n",
      "train_x Size stays the same False\n",
      "train_y Size stays the same False\n",
      "test_x Size stays the same False\n",
      "test_y Size stays the same False\n",
      "train_xNPSize (text) size: 794.8 megabytes\n",
      "train_yNPSize (labels) size: 0.15896 megabytes\n",
      "test_xNPSize (text) size: 421.02 megabytes\n",
      "test_yNPSize (labels) size: 0.084204 megabytes\n",
      "train_xNP length  39740\n",
      "train_xNP dimension of element  2\n",
      "train_xNP size  198700000\n",
      "saving NP arrays\n",
      "NP arrays saved\n",
      "Initializing classifier\n",
      "Searching for a  RandomForestClassifier\n",
      "False\n",
      "file not found, creating new classifier\n",
      "this is the classifierName:  RandomForestClassifier\n",
      "Training...\n",
      "train_x (text) size: 794.8 megabytes\n",
      "train_y (labels) size: 0.15896 megabytes\n",
      "train_x (text) length: 39740\n",
      "train_y (labels) length: 39740\n",
      "[[1 1 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 1 0 ... 0 0 0]\n",
      " [0 1 0 ... 0 0 0]]\n",
      "[2 5 5 1 2]\n",
      "finished training, classifier size: 4.8e-05 megabytes\n",
      "Predicting...\n",
      "Analysing...\n",
      "analyse_results\n",
      "hello\n",
      "Precision\t0.11035105220654601\n",
      "Recall\t0.11035105220654601\n",
      "F1-score\t0.11035105220654601\n",
      "Accuracy\t0.11035105220654601\n",
      "classiferSaveFile:  crowdflower_tecRandomForestClassifier.pkl\n",
      "Saved Successfully\n",
      "Total: 475 GiB\n",
      "Used: 315 GiB\n",
      "Free: 159 GiB\n",
      "-----------------------------------------------------------------------------------------\n",
      "('crowdflower', 'tales-emotion', 'tweets', 'tales')\n",
      "Getting data\n",
      "get_train_test param:\n",
      "json  unified-dataset.jsonl\n",
      "train  crowdflower\n",
      "test  tales-emotion\n",
      "there were  14771  entries that were in test and  206668 that were not in test and  39740  that were in train\n",
      "test was appended  14771  times\n",
      "single\n",
      "oof\n",
      "Detected mode: single...\n",
      "39740 14771\n",
      "Getting wordlist...\n",
      "Getting emotions\n",
      "['noemo', 'surprise', 'disgust', 'anger', 'joy', 'sadness', 'fear']\n",
      "Making arrays\n",
      "checking for save files\n",
      "emotions in make_arrays:  {'noemo': 0, 'surprise': 1, 'disgust': 2, 'anger': 3, 'joy': 4, 'sadness': 5, 'fear': 6}\n",
      "train super raw:  0.321096\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████| 39740/39740 [00:15<00:00, 2590.00it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████| 14771/14771 [00:06<00:00, 2296.46it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_x length  39740\n",
      "train_x dimension of element  5000\n",
      "train_x (text) size RAW: 0.321096 megabytes\n",
      "train_y (labels) size RAW: 0.321096 megabytes\n",
      "test_x (text) size RAW: 0.124912 megabytes\n",
      "test_y (labels) size RAW: 0.124912 megabytes\n",
      "saved test_y\n",
      "train_x Size stays the same False\n",
      "train_y Size stays the same False\n",
      "test_x Size stays the same False\n",
      "test_y Size stays the same False\n",
      "train_xNPSize (text) size: 794.8 megabytes\n",
      "train_yNPSize (labels) size: 0.15896 megabytes\n",
      "test_xNPSize (text) size: 295.42 megabytes\n",
      "test_yNPSize (labels) size: 0.059084 megabytes\n",
      "train_xNP length  39740\n",
      "train_xNP dimension of element  2\n",
      "train_xNP size  198700000\n",
      "saving NP arrays\n",
      "NP arrays saved\n",
      "Initializing classifier\n",
      "Searching for a  RandomForestClassifier\n",
      "False\n",
      "file not found, creating new classifier\n",
      "this is the classifierName:  RandomForestClassifier\n",
      "Training...\n",
      "train_x (text) size: 794.8 megabytes\n",
      "train_y (labels) size: 0.15896 megabytes\n",
      "train_x (text) length: 39740\n",
      "train_y (labels) length: 39740\n",
      "[[1 1 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 1 0 ... 0 0 0]\n",
      " [0 1 0 ... 0 0 0]]\n",
      "[0 5 5 4 0]\n",
      "finished training, classifier size: 4.8e-05 megabytes\n",
      "Predicting...\n",
      "Analysing...\n",
      "analyse_results\n",
      "hello\n",
      "Precision\t0.5151309999322998\n",
      "Recall\t0.5151309999322998\n",
      "F1-score\t0.5151309999322998\n",
      "Accuracy\t0.5151309999322998\n",
      "classiferSaveFile:  crowdflower_tales-emotionRandomForestClassifier.pkl\n",
      "Saved Successfully\n",
      "Total: 475 GiB\n",
      "Used: 317 GiB\n",
      "Free: 157 GiB\n",
      "-----------------------------------------------------------------------------------------\n",
      "('crowdflower', 'ssec', 'tweets', 'tweets')\n",
      "Getting data\n",
      "get_train_test param:\n",
      "json  unified-dataset.jsonl\n",
      "train  crowdflower\n",
      "test  ssec\n",
      "there were  4868  entries that were in test and  216571 that were not in test and  39740  that were in train\n",
      "test was appended  4868  times\n",
      "single\n",
      "Detected mode: multi...\n",
      "39740 4868\n",
      "Getting wordlist...\n",
      "Getting emotions\n",
      "['anger', 'joy', 'surprise', 'disgust', 'sadness', 'fear']\n",
      "Making arrays\n",
      "checking for save files\n",
      "emotions in make_arrays:  {'anger': 0, 'joy': 1, 'surprise': 2, 'disgust': 3, 'sadness': 4, 'fear': 5}\n",
      "train super raw:  0.321096\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████| 39740/39740 [00:17<00:00, 2269.13it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████| 4868/4868 [00:01<00:00, 2495.59it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_x length  39740\n",
      "train_x dimension of element  5000\n",
      "train_x (text) size RAW: 0.321096 megabytes\n",
      "train_y (labels) size RAW: 0.321096 megabytes\n",
      "test_x (text) size RAW: 0.043032 megabytes\n",
      "test_y (labels) size RAW: 0.043032 megabytes\n",
      "saved test_y\n",
      "train_x Size stays the same False\n",
      "train_y Size stays the same False\n",
      "test_x Size stays the same False\n",
      "test_y Size stays the same False\n",
      "train_xNPSize (text) size: 794.8 megabytes\n",
      "train_yNPSize (labels) size: 0.95376 megabytes\n",
      "test_xNPSize (text) size: 97.36 megabytes\n",
      "test_yNPSize (labels) size: 0.116832 megabytes\n",
      "train_xNP length  39740\n",
      "train_xNP dimension of element  2\n",
      "train_xNP size  198700000\n",
      "saving NP arrays\n",
      "NP arrays saved\n",
      "Initializing classifier\n",
      "Searching for a  RandomForestClassifier\n",
      "False\n",
      "file not found, creating new classifier\n",
      "this is the classifierName:  RandomForestClassifier\n",
      "Training...\n",
      "train_x (text) size: 794.8 megabytes\n",
      "train_y (labels) size: 0.95376 megabytes\n",
      "train_x (text) length: 39740\n",
      "train_y (labels) length: 39740\n",
      "[[1 1 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 1 0 ... 0 0 0]\n",
      " [0 1 0 ... 0 0 0]]\n",
      "[[0 0 0 0 0 0]\n",
      " [0 0 0 0 1 0]\n",
      " [0 0 0 0 1 0]\n",
      " [0 1 0 0 0 0]\n",
      " [0 0 0 0 0 0]]\n",
      "finished training, classifier size: 4.8e-05 megabytes\n",
      "Predicting...\n",
      "Analysing...\n",
      "analyse_results\n",
      "hello\n",
      "Precision\t0.823076923076923\n",
      "Recall\t0.008396107972379158\n",
      "F1-score\t0.01662265030293615\n",
      "Accuracy\t0.049301561216105176\n",
      "classiferSaveFile:  crowdflower_ssecRandomForestClassifier.pkl\n",
      "Saved Successfully\n",
      "Total: 475 GiB\n",
      "Used: 318 GiB\n",
      "Free: 156 GiB\n",
      "-----------------------------------------------------------------------------------------\n",
      "('crowdflower', 'isear', 'tweets', 'descriptions')\n",
      "Getting data\n",
      "get_train_test param:\n",
      "json  unified-dataset.jsonl\n",
      "train  crowdflower\n",
      "test  isear\n",
      "there were  7666  entries that were in test and  213773 that were not in test and  39740  that were in train\n",
      "test was appended  7666  times\n",
      "single\n",
      "oof\n",
      "Detected mode: single...\n",
      "39740 7666\n",
      "Getting wordlist...\n",
      "Getting emotions\n",
      "['anger', 'joy', 'noemo', 'disgust', 'sadness', 'fear']\n",
      "Making arrays\n",
      "checking for save files\n",
      "emotions in make_arrays:  {'anger': 0, 'joy': 1, 'noemo': 2, 'disgust': 3, 'sadness': 4, 'fear': 5}\n",
      "train super raw:  0.321096\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████| 39740/39740 [00:16<00:00, 2350.57it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████| 7666/7666 [00:03<00:00, 2208.53it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_x length  39740\n",
      "train_x dimension of element  5000\n",
      "train_x (text) size RAW: 0.321096 megabytes\n",
      "train_y (labels) size RAW: 0.321096 megabytes\n",
      "test_x (text) size RAW: 0.061424 megabytes\n",
      "test_y (labels) size RAW: 0.061424 megabytes\n",
      "saved test_y\n",
      "train_x Size stays the same False\n",
      "train_y Size stays the same False\n",
      "test_x Size stays the same False\n",
      "test_y Size stays the same False\n",
      "train_xNPSize (text) size: 794.8 megabytes\n",
      "train_yNPSize (labels) size: 0.15896 megabytes\n",
      "test_xNPSize (text) size: 153.32 megabytes\n",
      "test_yNPSize (labels) size: 0.030664 megabytes\n",
      "train_xNP length  39740\n",
      "train_xNP dimension of element  2\n",
      "train_xNP size  198700000\n",
      "saving NP arrays\n",
      "NP arrays saved\n",
      "Initializing classifier\n",
      "Searching for a  RandomForestClassifier\n",
      "False\n",
      "file not found, creating new classifier\n",
      "this is the classifierName:  RandomForestClassifier\n",
      "Training...\n",
      "train_x (text) size: 794.8 megabytes\n",
      "train_y (labels) size: 0.15896 megabytes\n",
      "train_x (text) length: 39740\n",
      "train_y (labels) length: 39740\n",
      "[[1 1 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 1 0 ... 0 0 0]\n",
      " [0 1 0 ... 0 0 0]]\n",
      "[2 4 4 1 2]\n",
      "finished training, classifier size: 4.8e-05 megabytes\n",
      "Predicting...\n",
      "Analysing...\n",
      "analyse_results\n",
      "hello\n",
      "Precision\t0.28632924602139315\n",
      "Recall\t0.28632924602139315\n",
      "F1-score\t0.28632924602139315\n",
      "Accuracy\t0.28632924602139315\n",
      "classiferSaveFile:  crowdflower_isearRandomForestClassifier.pkl\n",
      "Saved Successfully\n",
      "Total: 475 GiB\n",
      "Used: 320 GiB\n",
      "Free: 154 GiB\n",
      "-----------------------------------------------------------------------------------------\n",
      "('crowdflower', 'grounded_emotions', 'tweets', 'tweets')\n",
      "Getting data\n",
      "get_train_test param:\n",
      "json  unified-dataset.jsonl\n",
      "train  crowdflower\n",
      "test  grounded_emotions\n",
      "there were  2585  entries that were in test and  218854 that were not in test and  39740  that were in train\n",
      "test was appended  2585  times\n",
      "single\n",
      "oof\n",
      "Detected mode: single...\n",
      "39740 2585\n",
      "Getting wordlist...\n",
      "Getting emotions\n",
      "['joy', 'noemo', 'sadness']\n",
      "Making arrays\n",
      "checking for save files\n",
      "emotions in make_arrays:  {'joy': 0, 'noemo': 1, 'sadness': 2}\n",
      "train super raw:  0.321096\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████| 39740/39740 [00:16<00:00, 2443.39it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████| 2585/2585 [00:01<00:00, 2255.96it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_x length  39740\n",
      "train_x dimension of element  5000\n",
      "train_x (text) size RAW: 0.321096 megabytes\n",
      "train_y (labels) size RAW: 0.321096 megabytes\n",
      "test_x (text) size RAW: 0.02104 megabytes\n",
      "test_y (labels) size RAW: 0.02104 megabytes\n",
      "saved test_y\n",
      "train_x Size stays the same False\n",
      "train_y Size stays the same False\n",
      "test_x Size stays the same False\n",
      "test_y Size stays the same False\n",
      "train_xNPSize (text) size: 794.8 megabytes\n",
      "train_yNPSize (labels) size: 0.15896 megabytes\n",
      "test_xNPSize (text) size: 51.7 megabytes\n",
      "test_yNPSize (labels) size: 0.01034 megabytes\n",
      "train_xNP length  39740\n",
      "train_xNP dimension of element  2\n",
      "train_xNP size  198700000\n",
      "saving NP arrays\n",
      "NP arrays saved\n",
      "Initializing classifier\n",
      "Searching for a  RandomForestClassifier\n",
      "False\n",
      "file not found, creating new classifier\n",
      "this is the classifierName:  RandomForestClassifier\n",
      "Training...\n",
      "train_x (text) size: 794.8 megabytes\n",
      "train_y (labels) size: 0.15896 megabytes\n",
      "train_x (text) length: 39740\n",
      "train_y (labels) length: 39740\n",
      "[[1 1 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 1 0 ... 0 0 0]\n",
      " [0 1 0 ... 0 0 0]]\n",
      "[1 2 2 0 1]\n",
      "finished training, classifier size: 4.8e-05 megabytes\n",
      "Predicting...\n",
      "Analysing...\n",
      "analyse_results\n",
      "hello\n",
      "Precision\t0.017408123791102514\n",
      "Recall\t0.017408123791102514\n",
      "F1-score\t0.017408123791102514\n",
      "Accuracy\t0.017408123791102514\n",
      "classiferSaveFile:  crowdflower_grounded_emotionsRandomForestClassifier.pkl\n",
      "Saved Successfully\n",
      "Total: 475 GiB\n",
      "Used: 321 GiB\n",
      "Free: 153 GiB\n",
      "-----------------------------------------------------------------------------------------\n",
      "('crowdflower', 'emotion-cause', 'tweets', 'paragraphs')\n",
      "Getting data\n",
      "get_train_test param:\n",
      "json  unified-dataset.jsonl\n",
      "train  crowdflower\n",
      "test  emotion-cause\n",
      "there were  2414  entries that were in test and  219025 that were not in test and  39740  that were in train\n",
      "test was appended  2414  times\n",
      "single\n",
      "oof\n",
      "Detected mode: single...\n",
      "39740 2414\n",
      "Getting wordlist...\n",
      "Getting emotions\n",
      "['anger', 'joy', 'noemo', 'surprise', 'disgust', 'sadness', 'fear']\n",
      "Making arrays\n",
      "checking for save files\n",
      "emotions in make_arrays:  {'anger': 0, 'joy': 1, 'noemo': 2, 'surprise': 3, 'disgust': 4, 'sadness': 5, 'fear': 6}\n",
      "train super raw:  0.321096\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████| 39740/39740 [00:16<00:00, 2383.12it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████| 2414/2414 [00:01<00:00, 2297.30it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_x length  39740\n",
      "train_x dimension of element  5000\n",
      "train_x (text) size RAW: 0.321096 megabytes\n",
      "train_y (labels) size RAW: 0.321096 megabytes\n",
      "test_x (text) size RAW: 0.02104 megabytes\n",
      "test_y (labels) size RAW: 0.02104 megabytes\n",
      "saved test_y\n",
      "train_x Size stays the same False\n",
      "train_y Size stays the same False\n",
      "test_x Size stays the same False\n",
      "test_y Size stays the same False\n",
      "train_xNPSize (text) size: 794.8 megabytes\n",
      "train_yNPSize (labels) size: 0.15896 megabytes\n",
      "test_xNPSize (text) size: 48.28 megabytes\n",
      "test_yNPSize (labels) size: 0.009656 megabytes\n",
      "train_xNP length  39740\n",
      "train_xNP dimension of element  2\n",
      "train_xNP size  198700000\n",
      "saving NP arrays\n",
      "NP arrays saved\n",
      "Initializing classifier\n",
      "Searching for a  RandomForestClassifier\n",
      "False\n",
      "file not found, creating new classifier\n",
      "this is the classifierName:  RandomForestClassifier\n",
      "Training...\n",
      "train_x (text) size: 794.8 megabytes\n",
      "train_y (labels) size: 0.15896 megabytes\n",
      "train_x (text) length: 39740\n",
      "train_y (labels) length: 39740\n",
      "[[1 1 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 1 0 ... 0 0 0]\n",
      " [0 1 0 ... 0 0 0]]\n",
      "[2 5 5 1 2]\n",
      "finished training, classifier size: 4.8e-05 megabytes\n",
      "Predicting...\n",
      "Analysing...\n",
      "analyse_results\n",
      "hello\n",
      "Precision\t0.13380281690140844\n",
      "Recall\t0.13380281690140844\n",
      "F1-score\t0.13380281690140844\n",
      "Accuracy\t0.13380281690140844\n",
      "classiferSaveFile:  crowdflower_emotion-causeRandomForestClassifier.pkl\n",
      "Saved Successfully\n",
      "Total: 475 GiB\n",
      "Used: 322 GiB\n",
      "Free: 152 GiB\n",
      "-----------------------------------------------------------------------------------------\n",
      "('crowdflower', 'emoint', 'tweets', 'tweets')\n",
      "Getting data\n",
      "get_train_test param:\n",
      "json  unified-dataset.jsonl\n",
      "train  crowdflower\n",
      "test  emoint\n",
      "there were  7102  entries that were in test and  214337 that were not in test and  39740  that were in train\n",
      "test was appended  7102  times\n",
      "single\n",
      "oof\n",
      "Detected mode: single...\n",
      "39740 7102\n",
      "Getting wordlist...\n",
      "Getting emotions\n",
      "['anger', 'joy', 'noemo', 'sadness', 'fear']\n",
      "Making arrays\n",
      "checking for save files\n",
      "emotions in make_arrays:  {'anger': 0, 'joy': 1, 'noemo': 2, 'sadness': 3, 'fear': 4}\n",
      "train super raw:  0.321096\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████| 39740/39740 [00:16<00:00, 2349.06it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████| 7102/7102 [00:03<00:00, 2289.43it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_x length  39740\n",
      "train_x dimension of element  5000\n",
      "train_x (text) size RAW: 0.321096 megabytes\n",
      "train_y (labels) size RAW: 0.321096 megabytes\n",
      "test_x (text) size RAW: 0.061424 megabytes\n",
      "test_y (labels) size RAW: 0.061424 megabytes\n",
      "saved test_y\n",
      "train_x Size stays the same False\n",
      "train_y Size stays the same False\n",
      "test_x Size stays the same False\n",
      "test_y Size stays the same False\n",
      "train_xNPSize (text) size: 794.8 megabytes\n",
      "train_yNPSize (labels) size: 0.15896 megabytes\n",
      "test_xNPSize (text) size: 142.04 megabytes\n",
      "test_yNPSize (labels) size: 0.028408 megabytes\n",
      "train_xNP length  39740\n",
      "train_xNP dimension of element  2\n",
      "train_xNP size  198700000\n",
      "saving NP arrays\n",
      "NP arrays saved\n",
      "Initializing classifier\n",
      "Searching for a  RandomForestClassifier\n",
      "False\n",
      "file not found, creating new classifier\n",
      "this is the classifierName:  RandomForestClassifier\n",
      "Training...\n",
      "train_x (text) size: 794.8 megabytes\n",
      "train_y (labels) size: 0.15896 megabytes\n",
      "train_x (text) length: 39740\n",
      "train_y (labels) length: 39740\n",
      "[[1 1 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 1 0 ... 0 0 0]\n",
      " [0 1 0 ... 0 0 0]]\n",
      "[2 3 3 1 2]\n",
      "finished training, classifier size: 4.8e-05 megabytes\n",
      "Predicting...\n",
      "Analysing...\n",
      "analyse_results\n",
      "hello\n",
      "Precision\t0.08462404956350324\n",
      "Recall\t0.08462404956350324\n",
      "F1-score\t0.08462404956350324\n",
      "Accuracy\t0.08462404956350324\n",
      "classiferSaveFile:  crowdflower_emointRandomForestClassifier.pkl\n",
      "Saved Successfully\n",
      "Total: 475 GiB\n",
      "Used: 323 GiB\n",
      "Free: 151 GiB\n",
      "-----------------------------------------------------------------------------------------\n",
      "('crowdflower', 'emobank', 'tweets', 'headlines')\n",
      "Getting data\n",
      "get_train_test param:\n",
      "json  unified-dataset.jsonl\n",
      "train  crowdflower\n",
      "test  emobank\n",
      "there were  10062  entries that were in test and  211377 that were not in test and  39740  that were in train\n",
      "test was appended  10062  times\n",
      "single\n",
      "Detected mode: multi...\n",
      "39740 10062\n",
      "Getting wordlist...\n",
      "Getting emotions\n",
      "[]\n",
      "Making arrays\n",
      "checking for save files\n",
      "emotions in make_arrays:  {}\n",
      "train super raw:  0.321096\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████| 39740/39740 [00:15<00:00, 2535.86it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████| 10062/10062 [00:04<00:00, 2202.11it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_x length  39740\n",
      "train_x dimension of element  5000\n",
      "train_x (text) size RAW: 0.321096 megabytes\n",
      "train_y (labels) size RAW: 0.321096 megabytes\n",
      "test_x (text) size RAW: 0.087616 megabytes\n",
      "test_y (labels) size RAW: 0.087616 megabytes\n",
      "saved test_y\n",
      "train_x Size stays the same False\n",
      "train_y Size stays the same False\n",
      "test_x Size stays the same False\n",
      "test_y Size stays the same False\n",
      "train_xNPSize (text) size: 794.8 megabytes\n",
      "train_yNPSize (labels) size: 0.0 megabytes\n",
      "test_xNPSize (text) size: 201.24 megabytes\n",
      "test_yNPSize (labels) size: 0.0 megabytes\n",
      "train_xNP length  39740\n",
      "train_xNP dimension of element  2\n",
      "train_xNP size  198700000\n",
      "Train or test empty. Did you misspell the dataset name?\n",
      "('crowdflower', 'dailydialog', 'tweets', 'conversations')\n",
      "Getting data\n",
      "get_train_test param:\n",
      "json  unified-dataset.jsonl\n",
      "train  crowdflower\n",
      "test  dailydialog\n",
      "there were  102979  entries that were in test and  118460 that were not in test and  39740  that were in train\n",
      "test was appended  102979  times\n",
      "single\n",
      "oof\n",
      "Detected mode: single...\n",
      "39740 102979\n",
      "Getting wordlist...\n",
      "Getting emotions\n",
      "['noemo', 'surprise', 'disgust', 'anger', 'joy', 'sadness', 'fear']\n",
      "Making arrays\n",
      "checking for save files\n",
      "emotions in make_arrays:  {'noemo': 0, 'surprise': 1, 'disgust': 2, 'anger': 3, 'joy': 4, 'sadness': 5, 'fear': 6}\n",
      "train super raw:  0.321096\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████| 39740/39740 [00:15<00:00, 2509.79it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████| 102979/102979 [00:46<00:00, 2194.18it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_x length  39740\n",
      "train_x dimension of element  5000\n",
      "train_x (text) size RAW: 0.321096 megabytes\n",
      "train_y (labels) size RAW: 0.321096 megabytes\n",
      "test_x (text) size RAW: 0.824456 megabytes\n",
      "test_y (labels) size RAW: 0.824456 megabytes\n",
      "saved test_y\n",
      "train_x Size stays the same False\n",
      "train_y Size stays the same False\n",
      "test_x Size stays the same False\n",
      "test_y Size stays the same False\n",
      "train_xNPSize (text) size: 794.8 megabytes\n",
      "train_yNPSize (labels) size: 0.15896 megabytes\n",
      "test_xNPSize (text) size: 2059.58 megabytes\n",
      "test_yNPSize (labels) size: 0.411916 megabytes\n",
      "train_xNP length  39740\n",
      "train_xNP dimension of element  2\n",
      "train_xNP size  198700000\n",
      "saving NP arrays\n",
      "NP arrays saved\n",
      "Initializing classifier\n",
      "Searching for a  RandomForestClassifier\n",
      "False\n",
      "file not found, creating new classifier\n",
      "this is the classifierName:  RandomForestClassifier\n",
      "Training...\n",
      "train_x (text) size: 794.8 megabytes\n",
      "train_y (labels) size: 0.15896 megabytes\n",
      "train_x (text) length: 39740\n",
      "train_y (labels) length: 39740\n",
      "[[1 1 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 1 0 ... 0 0 0]\n",
      " [0 1 0 ... 0 0 0]]\n",
      "[0 5 5 4 0]\n",
      "finished training, classifier size: 4.8e-05 megabytes\n",
      "Predicting...\n",
      "Analysing...\n",
      "analyse_results\n",
      "hello\n",
      "Precision\t0.6860136532691131\n",
      "Recall\t0.6860136532691131\n",
      "F1-score\t0.6860136532691131\n",
      "Accuracy\t0.6860136532691131\n",
      "classiferSaveFile:  crowdflower_dailydialogRandomForestClassifier.pkl\n",
      "Saved Successfully\n",
      "Total: 475 GiB\n",
      "Used: 326 GiB\n",
      "Free: 148 GiB\n",
      "-----------------------------------------------------------------------------------------\n",
      "('crowdflower', 'affectivetext', 'tweets', 'headlines')\n",
      "Getting data\n",
      "get_train_test param:\n",
      "json  unified-dataset.jsonl\n",
      "train  crowdflower\n",
      "test  affectivetext\n",
      "there were  1250  entries that were in test and  220189 that were not in test and  39740  that were in train\n",
      "test was appended  1250  times\n",
      "single\n",
      "Detected mode: multi...\n",
      "39740 1250\n",
      "Getting wordlist...\n",
      "Getting emotions\n",
      "['anger', 'joy', 'surprise', 'disgust', 'sadness', 'fear']\n",
      "Making arrays\n",
      "checking for save files\n",
      "emotions in make_arrays:  {'anger': 0, 'joy': 1, 'surprise': 2, 'disgust': 3, 'sadness': 4, 'fear': 5}\n",
      "train super raw:  0.321096\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████| 39740/39740 [00:16<00:00, 2468.56it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████| 1250/1250 [00:00<00:00, 2328.72it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_x length  39740\n",
      "train_x dimension of element  5000\n",
      "train_x (text) size RAW: 0.321096 megabytes\n",
      "train_y (labels) size RAW: 0.321096 megabytes\n",
      "test_x (text) size RAW: 0.010192 megabytes\n",
      "test_y (labels) size RAW: 0.010192 megabytes\n",
      "saved test_y\n",
      "train_x Size stays the same False\n",
      "train_y Size stays the same False\n",
      "test_x Size stays the same False\n",
      "test_y Size stays the same False\n",
      "train_xNPSize (text) size: 794.8 megabytes\n",
      "train_yNPSize (labels) size: 0.95376 megabytes\n",
      "test_xNPSize (text) size: 25.0 megabytes\n",
      "test_yNPSize (labels) size: 0.03 megabytes\n",
      "train_xNP length  39740\n",
      "train_xNP dimension of element  2\n",
      "train_xNP size  198700000\n",
      "saving NP arrays\n",
      "NP arrays saved\n",
      "Initializing classifier\n",
      "Searching for a  RandomForestClassifier\n",
      "False\n",
      "file not found, creating new classifier\n",
      "this is the classifierName:  RandomForestClassifier\n",
      "Training...\n",
      "train_x (text) size: 794.8 megabytes\n",
      "train_y (labels) size: 0.95376 megabytes\n",
      "train_x (text) length: 39740\n",
      "train_y (labels) length: 39740\n",
      "[[1 1 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 1 0 ... 0 0 0]\n",
      " [0 1 0 ... 0 0 0]]\n",
      "[[0 0 0 0 0 0]\n",
      " [0 0 0 0 1 0]\n",
      " [0 0 0 0 1 0]\n",
      " [0 1 0 0 0 0]\n",
      " [0 0 0 0 0 0]]\n",
      "finished training, classifier size: 4.8e-05 megabytes\n",
      "Predicting...\n",
      "Analysing...\n",
      "analyse_results\n",
      "hello\n",
      "Precision\t0.7755102040816326\n",
      "Recall\t0.011801242236024845\n",
      "F1-score\t0.023248699908228816\n",
      "Accuracy\t0.0344\n",
      "classiferSaveFile:  crowdflower_affectivetextRandomForestClassifier.pkl\n",
      "Saved Successfully\n",
      "Total: 475 GiB\n",
      "Used: 328 GiB\n",
      "Free: 146 GiB\n",
      "-----------------------------------------------------------------------------------------\n",
      "('tales-emotion', 'tec', 'tales', 'tweets')\n",
      "Getting data\n",
      "get_train_test param:\n",
      "json  unified-dataset.jsonl\n",
      "train  tales-emotion\n",
      "test  tec\n",
      "there were  21051  entries that were in test and  200388 that were not in test and  14771  that were in train\n",
      "test was appended  21051  times\n",
      "single\n",
      "oof\n",
      "Detected mode: single...\n",
      "14771 21051\n",
      "Getting wordlist...\n",
      "Getting emotions\n",
      "['anger', 'joy', 'noemo', 'surprise', 'disgust', 'sadness', 'fear']\n",
      "Making arrays\n",
      "checking for save files\n",
      "emotions in make_arrays:  {'anger': 0, 'joy': 1, 'noemo': 2, 'surprise': 3, 'disgust': 4, 'sadness': 5, 'fear': 6}\n",
      "train super raw:  0.124912\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████| 14771/14771 [00:07<00:00, 1998.75it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████| 21051/21051 [00:11<00:00, 1888.10it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_x length  14771\n",
      "train_x dimension of element  5000\n",
      "train_x (text) size RAW: 0.124912 megabytes\n",
      "train_y (labels) size RAW: 0.124912 megabytes\n",
      "test_x (text) size RAW: 0.178016 megabytes\n",
      "test_y (labels) size RAW: 0.178016 megabytes\n",
      "saved test_y\n",
      "train_x Size stays the same False\n",
      "train_y Size stays the same False\n",
      "test_x Size stays the same False\n",
      "test_y Size stays the same False\n",
      "train_xNPSize (text) size: 295.42 megabytes\n",
      "train_yNPSize (labels) size: 0.059084 megabytes\n",
      "test_xNPSize (text) size: 421.02 megabytes\n",
      "test_yNPSize (labels) size: 0.084204 megabytes\n",
      "train_xNP length  14771\n",
      "train_xNP dimension of element  2\n",
      "train_xNP size  73855000\n",
      "saving NP arrays\n",
      "NP arrays saved\n",
      "Initializing classifier\n",
      "Searching for a  RandomForestClassifier\n",
      "False\n",
      "file not found, creating new classifier\n",
      "this is the classifierName:  RandomForestClassifier\n",
      "Training...\n",
      "train_x (text) size: 295.42 megabytes\n",
      "train_y (labels) size: 0.059084 megabytes\n",
      "train_x (text) length: 14771\n",
      "train_y (labels) length: 14771\n",
      "[[0 0 0 ... 0 0 0]\n",
      " [1 1 0 ... 0 0 0]\n",
      " [1 1 0 ... 0 0 0]\n",
      " [1 0 0 ... 0 0 0]\n",
      " [0 1 0 ... 0 0 0]]\n",
      "[2 2 2 2 2]\n",
      "finished training, classifier size: 4.8e-05 megabytes\n",
      "Predicting...\n",
      "Analysing...\n",
      "analyse_results\n",
      "hello\n",
      "Precision\t0.02208921191392333\n",
      "Recall\t0.02208921191392333\n",
      "F1-score\t0.02208921191392333\n",
      "Accuracy\t0.02208921191392333\n",
      "classiferSaveFile:  tales-emotion_tecRandomForestClassifier.pkl\n",
      "Saved Successfully\n",
      "Total: 475 GiB\n",
      "Used: 328 GiB\n",
      "Free: 146 GiB\n",
      "-----------------------------------------------------------------------------------------\n",
      "('tales-emotion', 'ssec', 'tales', 'tweets')\n",
      "Getting data\n",
      "get_train_test param:\n",
      "json  unified-dataset.jsonl\n",
      "train  tales-emotion\n",
      "test  ssec\n",
      "there were  4868  entries that were in test and  216571 that were not in test and  14771  that were in train\n",
      "test was appended  4868  times\n",
      "single\n",
      "Detected mode: multi...\n",
      "14771 4868\n",
      "Getting wordlist...\n",
      "Getting emotions\n",
      "['anger', 'joy', 'surprise', 'disgust', 'sadness', 'fear']\n",
      "Making arrays\n",
      "checking for save files\n",
      "emotions in make_arrays:  {'anger': 0, 'joy': 1, 'surprise': 2, 'disgust': 3, 'sadness': 4, 'fear': 5}\n",
      "train super raw:  0.124912\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████| 14771/14771 [00:05<00:00, 2527.54it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████| 4868/4868 [00:02<00:00, 2270.49it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_x length  14771\n",
      "train_x dimension of element  5000\n",
      "train_x (text) size RAW: 0.124912 megabytes\n",
      "train_y (labels) size RAW: 0.124912 megabytes\n",
      "test_x (text) size RAW: 0.043032 megabytes\n",
      "test_y (labels) size RAW: 0.043032 megabytes\n",
      "saved test_y\n",
      "train_x Size stays the same False\n",
      "train_y Size stays the same False\n",
      "test_x Size stays the same False\n",
      "test_y Size stays the same False\n",
      "train_xNPSize (text) size: 295.42 megabytes\n",
      "train_yNPSize (labels) size: 0.354504 megabytes\n",
      "test_xNPSize (text) size: 97.36 megabytes\n",
      "test_yNPSize (labels) size: 0.116832 megabytes\n",
      "train_xNP length  14771\n",
      "train_xNP dimension of element  2\n",
      "train_xNP size  73855000\n",
      "saving NP arrays\n",
      "NP arrays saved\n",
      "Initializing classifier\n",
      "Searching for a  RandomForestClassifier\n",
      "False\n",
      "file not found, creating new classifier\n",
      "this is the classifierName:  RandomForestClassifier\n",
      "Training...\n",
      "train_x (text) size: 295.42 megabytes\n",
      "train_y (labels) size: 0.354504 megabytes\n",
      "train_x (text) length: 14771\n",
      "train_y (labels) length: 14771\n",
      "[[0 0 0 ... 0 0 0]\n",
      " [1 1 0 ... 0 0 0]\n",
      " [1 1 0 ... 0 0 0]\n",
      " [1 0 0 ... 0 0 0]\n",
      " [0 1 0 ... 0 0 0]]\n",
      "[[0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0]]\n",
      "finished training, classifier size: 4.8e-05 megabytes\n",
      "Predicting...\n",
      "Analysing...\n",
      "analyse_results\n",
      "hello\n",
      "Precision\t0.8045977011494253\n",
      "Recall\t0.00549278091650973\n",
      "F1-score\t0.010911074740861974\n",
      "Accuracy\t0.04498767460969597\n",
      "classiferSaveFile:  tales-emotion_ssecRandomForestClassifier.pkl\n",
      "Saved Successfully\n",
      "Total: 475 GiB\n",
      "Used: 329 GiB\n",
      "Free: 145 GiB\n",
      "-----------------------------------------------------------------------------------------\n",
      "('tales-emotion', 'isear', 'tales', 'descriptions')\n",
      "Getting data\n",
      "get_train_test param:\n",
      "json  unified-dataset.jsonl\n",
      "train  tales-emotion\n",
      "test  isear\n",
      "there were  7666  entries that were in test and  213773 that were not in test and  14771  that were in train\n",
      "test was appended  7666  times\n",
      "single\n",
      "oof\n",
      "Detected mode: single...\n",
      "14771 7666\n",
      "Getting wordlist...\n",
      "Getting emotions\n",
      "['anger', 'joy', 'noemo', 'disgust', 'sadness', 'fear']\n",
      "Making arrays\n",
      "checking for save files\n",
      "emotions in make_arrays:  {'anger': 0, 'joy': 1, 'noemo': 2, 'disgust': 3, 'sadness': 4, 'fear': 5}\n",
      "train super raw:  0.124912\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████| 14771/14771 [00:05<00:00, 2498.02it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████| 7666/7666 [00:03<00:00, 2194.18it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_x length  14771\n",
      "train_x dimension of element  5000\n",
      "train_x (text) size RAW: 0.124912 megabytes\n",
      "train_y (labels) size RAW: 0.124912 megabytes\n",
      "test_x (text) size RAW: 0.061424 megabytes\n",
      "test_y (labels) size RAW: 0.061424 megabytes\n",
      "saved test_y\n",
      "train_x Size stays the same False\n",
      "train_y Size stays the same False\n",
      "test_x Size stays the same False\n",
      "test_y Size stays the same False\n",
      "train_xNPSize (text) size: 295.42 megabytes\n",
      "train_yNPSize (labels) size: 0.059084 megabytes\n",
      "test_xNPSize (text) size: 153.32 megabytes\n",
      "test_yNPSize (labels) size: 0.030664 megabytes\n",
      "train_xNP length  14771\n",
      "train_xNP dimension of element  2\n",
      "train_xNP size  73855000\n",
      "saving NP arrays\n",
      "NP arrays saved\n",
      "Initializing classifier\n",
      "Searching for a  RandomForestClassifier\n",
      "False\n",
      "file not found, creating new classifier\n",
      "this is the classifierName:  RandomForestClassifier\n",
      "Training...\n",
      "train_x (text) size: 295.42 megabytes\n",
      "train_y (labels) size: 0.059084 megabytes\n",
      "train_x (text) length: 14771\n",
      "train_y (labels) length: 14771\n",
      "[[0 0 0 ... 0 0 0]\n",
      " [1 1 0 ... 0 0 0]\n",
      " [1 1 0 ... 0 0 0]\n",
      " [1 0 0 ... 0 0 0]\n",
      " [0 1 0 ... 0 0 0]]\n",
      "[2 2 2 2 2]\n",
      "finished training, classifier size: 4.8e-05 megabytes\n",
      "Predicting...\n",
      "Analysing...\n",
      "analyse_results\n",
      "hello\n",
      "Precision\t0.29715627445864856\n",
      "Recall\t0.29715627445864856\n",
      "F1-score\t0.29715627445864856\n",
      "Accuracy\t0.29715627445864856\n",
      "classiferSaveFile:  tales-emotion_isearRandomForestClassifier.pkl\n",
      "Saved Successfully\n",
      "Total: 475 GiB\n",
      "Used: 329 GiB\n",
      "Free: 145 GiB\n",
      "-----------------------------------------------------------------------------------------\n",
      "('tales-emotion', 'grounded_emotions', 'tales', 'tweets')\n",
      "Getting data\n",
      "get_train_test param:\n",
      "json  unified-dataset.jsonl\n",
      "train  tales-emotion\n",
      "test  grounded_emotions\n",
      "there were  2585  entries that were in test and  218854 that were not in test and  14771  that were in train\n",
      "test was appended  2585  times\n",
      "single\n",
      "oof\n",
      "Detected mode: single...\n",
      "14771 2585\n",
      "Getting wordlist...\n",
      "Getting emotions\n",
      "['joy', 'noemo', 'sadness']\n",
      "Making arrays\n",
      "checking for save files\n",
      "emotions in make_arrays:  {'joy': 0, 'noemo': 1, 'sadness': 2}\n",
      "train super raw:  0.124912\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████| 14771/14771 [00:05<00:00, 2556.89it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████| 2585/2585 [00:01<00:00, 2457.65it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_x length  14771\n",
      "train_x dimension of element  5000\n",
      "train_x (text) size RAW: 0.124912 megabytes\n",
      "train_y (labels) size RAW: 0.124912 megabytes\n",
      "test_x (text) size RAW: 0.02104 megabytes\n",
      "test_y (labels) size RAW: 0.02104 megabytes\n",
      "saved test_y\n",
      "train_x Size stays the same False\n",
      "train_y Size stays the same False\n",
      "test_x Size stays the same False\n",
      "test_y Size stays the same False\n",
      "train_xNPSize (text) size: 295.42 megabytes\n",
      "train_yNPSize (labels) size: 0.059084 megabytes\n",
      "test_xNPSize (text) size: 51.7 megabytes\n",
      "test_yNPSize (labels) size: 0.01034 megabytes\n",
      "train_xNP length  14771\n",
      "train_xNP dimension of element  2\n",
      "train_xNP size  73855000\n",
      "saving NP arrays\n",
      "NP arrays saved\n",
      "Initializing classifier\n",
      "Searching for a  RandomForestClassifier\n",
      "False\n",
      "file not found, creating new classifier\n",
      "this is the classifierName:  RandomForestClassifier\n",
      "Training...\n",
      "train_x (text) size: 295.42 megabytes\n",
      "train_y (labels) size: 0.059084 megabytes\n",
      "train_x (text) length: 14771\n",
      "train_y (labels) length: 14771\n",
      "[[0 0 0 ... 0 0 0]\n",
      " [1 1 0 ... 0 0 0]\n",
      " [1 1 0 ... 0 0 0]\n",
      " [1 0 0 ... 0 0 0]\n",
      " [0 1 0 ... 0 0 0]]\n",
      "[1 1 1 1 1]\n",
      "finished training, classifier size: 4.8e-05 megabytes\n",
      "Predicting...\n",
      "Analysing...\n",
      "analyse_results\n",
      "hello\n",
      "Precision\t0.06615087040618955\n",
      "Recall\t0.06615087040618955\n",
      "F1-score\t0.06615087040618955\n",
      "Accuracy\t0.06615087040618955\n",
      "classiferSaveFile:  tales-emotion_grounded_emotionsRandomForestClassifier.pkl\n",
      "Saved Successfully\n",
      "Total: 475 GiB\n",
      "Used: 330 GiB\n",
      "Free: 144 GiB\n",
      "-----------------------------------------------------------------------------------------\n",
      "('tales-emotion', 'emotion-cause', 'tales', 'paragraphs')\n",
      "Getting data\n",
      "get_train_test param:\n",
      "json  unified-dataset.jsonl\n",
      "train  tales-emotion\n",
      "test  emotion-cause\n",
      "there were  2414  entries that were in test and  219025 that were not in test and  14771  that were in train\n",
      "test was appended  2414  times\n",
      "single\n",
      "oof\n",
      "Detected mode: single...\n",
      "14771 2414\n",
      "Getting wordlist...\n",
      "Getting emotions\n",
      "['anger', 'joy', 'noemo', 'surprise', 'disgust', 'sadness', 'fear']\n",
      "Making arrays\n",
      "checking for save files\n",
      "emotions in make_arrays:  {'anger': 0, 'joy': 1, 'noemo': 2, 'surprise': 3, 'disgust': 4, 'sadness': 5, 'fear': 6}\n",
      "train super raw:  0.124912\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████| 14771/14771 [00:05<00:00, 2534.81it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████| 2414/2414 [00:01<00:00, 2308.08it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_x length  14771\n",
      "train_x dimension of element  5000\n",
      "train_x (text) size RAW: 0.124912 megabytes\n",
      "train_y (labels) size RAW: 0.124912 megabytes\n",
      "test_x (text) size RAW: 0.02104 megabytes\n",
      "test_y (labels) size RAW: 0.02104 megabytes\n",
      "saved test_y\n",
      "train_x Size stays the same False\n",
      "train_y Size stays the same False\n",
      "test_x Size stays the same False\n",
      "test_y Size stays the same False\n",
      "train_xNPSize (text) size: 295.42 megabytes\n",
      "train_yNPSize (labels) size: 0.059084 megabytes\n",
      "test_xNPSize (text) size: 48.28 megabytes\n",
      "test_yNPSize (labels) size: 0.009656 megabytes\n",
      "train_xNP length  14771\n",
      "train_xNP dimension of element  2\n",
      "train_xNP size  73855000\n",
      "saving NP arrays\n",
      "NP arrays saved\n",
      "Initializing classifier\n",
      "Searching for a  RandomForestClassifier\n",
      "False\n",
      "file not found, creating new classifier\n",
      "this is the classifierName:  RandomForestClassifier\n",
      "Training...\n",
      "train_x (text) size: 295.42 megabytes\n",
      "train_y (labels) size: 0.059084 megabytes\n",
      "train_x (text) length: 14771\n",
      "train_y (labels) length: 14771\n",
      "[[0 0 0 ... 0 0 0]\n",
      " [1 1 0 ... 0 0 0]\n",
      " [1 1 0 ... 0 0 0]\n",
      " [1 0 0 ... 0 0 0]\n",
      " [0 1 0 ... 0 0 0]]\n",
      "[2 2 2 2 2]\n",
      "finished training, classifier size: 4.8e-05 megabytes\n",
      "Predicting...\n",
      "Analysing...\n",
      "analyse_results\n",
      "hello\n",
      "Precision\t0.1383595691797846\n",
      "Recall\t0.1383595691797846\n",
      "F1-score\t0.1383595691797846\n",
      "Accuracy\t0.1383595691797846\n",
      "classiferSaveFile:  tales-emotion_emotion-causeRandomForestClassifier.pkl\n",
      "Saved Successfully\n",
      "Total: 475 GiB\n",
      "Used: 330 GiB\n",
      "Free: 144 GiB\n",
      "-----------------------------------------------------------------------------------------\n",
      "('tales-emotion', 'emoint', 'tales', 'tweets')\n",
      "Getting data\n",
      "get_train_test param:\n",
      "json  unified-dataset.jsonl\n",
      "train  tales-emotion\n",
      "test  emoint\n",
      "there were  7102  entries that were in test and  214337 that were not in test and  14771  that were in train\n",
      "test was appended  7102  times\n",
      "single\n",
      "oof\n",
      "Detected mode: single...\n",
      "14771 7102\n",
      "Getting wordlist...\n",
      "Getting emotions\n",
      "['anger', 'joy', 'noemo', 'sadness', 'fear']\n",
      "Making arrays\n",
      "checking for save files\n",
      "emotions in make_arrays:  {'anger': 0, 'joy': 1, 'noemo': 2, 'sadness': 3, 'fear': 4}\n",
      "train super raw:  0.124912\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████| 14771/14771 [00:09<00:00, 1618.97it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████| 7102/7102 [00:04<00:00, 1527.91it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_x length  14771\n",
      "train_x dimension of element  5000\n",
      "train_x (text) size RAW: 0.124912 megabytes\n",
      "train_y (labels) size RAW: 0.124912 megabytes\n",
      "test_x (text) size RAW: 0.061424 megabytes\n",
      "test_y (labels) size RAW: 0.061424 megabytes\n",
      "saved test_y\n",
      "train_x Size stays the same False\n",
      "train_y Size stays the same False\n",
      "test_x Size stays the same False\n",
      "test_y Size stays the same False\n",
      "train_xNPSize (text) size: 295.42 megabytes\n",
      "train_yNPSize (labels) size: 0.059084 megabytes\n",
      "test_xNPSize (text) size: 142.04 megabytes\n",
      "test_yNPSize (labels) size: 0.028408 megabytes\n",
      "train_xNP length  14771\n",
      "train_xNP dimension of element  2\n",
      "train_xNP size  73855000\n",
      "saving NP arrays\n",
      "NP arrays saved\n",
      "Initializing classifier\n",
      "Searching for a  RandomForestClassifier\n",
      "False\n",
      "file not found, creating new classifier\n",
      "this is the classifierName:  RandomForestClassifier\n",
      "Training...\n",
      "train_x (text) size: 295.42 megabytes\n",
      "train_y (labels) size: 0.059084 megabytes\n",
      "train_x (text) length: 14771\n",
      "train_y (labels) length: 14771\n",
      "[[0 0 0 ... 0 0 0]\n",
      " [1 1 0 ... 0 0 0]\n",
      " [1 1 0 ... 0 0 0]\n",
      " [1 0 0 ... 0 0 0]\n",
      " [0 1 0 ... 0 0 0]]\n",
      "[2 2 2 2 2]\n",
      "finished training, classifier size: 4.8e-05 megabytes\n",
      "Predicting...\n",
      "Analysing...\n",
      "analyse_results\n",
      "hello\n",
      "Precision\t0.036609405801182764\n",
      "Recall\t0.036609405801182764\n",
      "F1-score\t0.036609405801182764\n",
      "Accuracy\t0.036609405801182764\n",
      "classiferSaveFile:  tales-emotion_emointRandomForestClassifier.pkl\n",
      "Saved Successfully\n",
      "Total: 475 GiB\n",
      "Used: 331 GiB\n",
      "Free: 143 GiB\n",
      "-----------------------------------------------------------------------------------------\n",
      "('tales-emotion', 'emobank', 'tales', 'headlines')\n",
      "Getting data\n",
      "get_train_test param:\n",
      "json  unified-dataset.jsonl\n",
      "train  tales-emotion\n",
      "test  emobank\n",
      "there were  10062  entries that were in test and  211377 that were not in test and  14771  that were in train\n",
      "test was appended  10062  times\n",
      "single\n",
      "Detected mode: multi...\n",
      "14771 10062\n",
      "Getting wordlist...\n",
      "Getting emotions\n",
      "[]\n",
      "Making arrays\n",
      "checking for save files\n",
      "emotions in make_arrays:  {}\n",
      "train super raw:  0.124912\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████| 14771/14771 [00:06<00:00, 2425.18it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████| 10062/10062 [00:04<00:00, 2318.78it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_x length  14771\n",
      "train_x dimension of element  5000\n",
      "train_x (text) size RAW: 0.124912 megabytes\n",
      "train_y (labels) size RAW: 0.124912 megabytes\n",
      "test_x (text) size RAW: 0.087616 megabytes\n",
      "test_y (labels) size RAW: 0.087616 megabytes\n",
      "saved test_y\n",
      "train_x Size stays the same False\n",
      "train_y Size stays the same False\n",
      "test_x Size stays the same False\n",
      "test_y Size stays the same False\n",
      "train_xNPSize (text) size: 295.42 megabytes\n",
      "train_yNPSize (labels) size: 0.0 megabytes\n",
      "test_xNPSize (text) size: 201.24 megabytes\n",
      "test_yNPSize (labels) size: 0.0 megabytes\n",
      "train_xNP length  14771\n",
      "train_xNP dimension of element  2\n",
      "train_xNP size  73855000\n",
      "Train or test empty. Did you misspell the dataset name?\n",
      "('tales-emotion', 'dailydialog', 'tales', 'conversations')\n",
      "Getting data\n",
      "get_train_test param:\n",
      "json  unified-dataset.jsonl\n",
      "train  tales-emotion\n",
      "test  dailydialog\n",
      "there were  102979  entries that were in test and  118460 that were not in test and  14771  that were in train\n",
      "test was appended  102979  times\n",
      "single\n",
      "oof\n",
      "Detected mode: single...\n",
      "14771 102979\n",
      "Getting wordlist...\n",
      "Getting emotions\n",
      "['noemo', 'surprise', 'disgust', 'anger', 'joy', 'sadness', 'fear']\n",
      "Making arrays\n",
      "checking for save files\n",
      "emotions in make_arrays:  {'noemo': 0, 'surprise': 1, 'disgust': 2, 'anger': 3, 'joy': 4, 'sadness': 5, 'fear': 6}\n",
      "train super raw:  0.124912\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████| 14771/14771 [00:06<00:00, 2454.20it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████| 102979/102979 [00:43<00:00, 2348.05it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_x length  14771\n",
      "train_x dimension of element  5000\n",
      "train_x (text) size RAW: 0.124912 megabytes\n",
      "train_y (labels) size RAW: 0.124912 megabytes\n",
      "test_x (text) size RAW: 0.824456 megabytes\n",
      "test_y (labels) size RAW: 0.824456 megabytes\n",
      "saved test_y\n",
      "train_x Size stays the same False\n",
      "train_y Size stays the same False\n",
      "test_x Size stays the same False\n",
      "test_y Size stays the same False\n",
      "train_xNPSize (text) size: 295.42 megabytes\n",
      "train_yNPSize (labels) size: 0.059084 megabytes\n",
      "test_xNPSize (text) size: 2059.58 megabytes\n",
      "test_yNPSize (labels) size: 0.411916 megabytes\n",
      "train_xNP length  14771\n",
      "train_xNP dimension of element  2\n",
      "train_xNP size  73855000\n",
      "saving NP arrays\n",
      "NP arrays saved\n",
      "Initializing classifier\n",
      "Searching for a  RandomForestClassifier\n",
      "False\n",
      "file not found, creating new classifier\n",
      "this is the classifierName:  RandomForestClassifier\n",
      "Training...\n",
      "train_x (text) size: 295.42 megabytes\n",
      "train_y (labels) size: 0.059084 megabytes\n",
      "train_x (text) length: 14771\n",
      "train_y (labels) length: 14771\n",
      "[[0 0 0 ... 0 0 0]\n",
      " [1 1 0 ... 0 0 0]\n",
      " [1 1 0 ... 0 0 0]\n",
      " [1 0 0 ... 0 0 0]\n",
      " [0 1 0 ... 0 0 0]]\n",
      "[0 0 0 0 0]\n",
      "finished training, classifier size: 4.8e-05 megabytes\n",
      "Predicting...\n",
      "Analysing...\n",
      "analyse_results\n",
      "hello\n",
      "Precision\t0.8272657532118198\n",
      "Recall\t0.8272657532118198\n",
      "F1-score\t0.8272657532118198\n",
      "Accuracy\t0.8272657532118198\n",
      "classiferSaveFile:  tales-emotion_dailydialogRandomForestClassifier.pkl\n",
      "Saved Successfully\n",
      "Total: 475 GiB\n",
      "Used: 333 GiB\n",
      "Free: 141 GiB\n",
      "-----------------------------------------------------------------------------------------\n",
      "('tales-emotion', 'crowdflower', 'tales', 'tweets')\n",
      "Getting data\n",
      "get_train_test param:\n",
      "json  unified-dataset.jsonl\n",
      "train  tales-emotion\n",
      "test  crowdflower\n",
      "there were  39740  entries that were in test and  181699 that were not in test and  14771  that were in train\n",
      "test was appended  39740  times\n",
      "single\n",
      "oof\n",
      "Detected mode: single...\n",
      "14771 39740\n",
      "Getting wordlist...\n",
      "Getting emotions\n",
      "['noemo', 'surprise', 'disgust', 'anger', 'joy', 'sadness', 'fear']\n",
      "Making arrays\n",
      "checking for save files\n",
      "emotions in make_arrays:  {'noemo': 0, 'surprise': 1, 'disgust': 2, 'anger': 3, 'joy': 4, 'sadness': 5, 'fear': 6}\n",
      "train super raw:  0.124912\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████| 14771/14771 [00:06<00:00, 2454.19it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████| 39740/39740 [00:16<00:00, 2385.94it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_x length  14771\n",
      "train_x dimension of element  5000\n",
      "train_x (text) size RAW: 0.124912 megabytes\n",
      "train_y (labels) size RAW: 0.124912 megabytes\n",
      "test_x (text) size RAW: 0.321096 megabytes\n",
      "test_y (labels) size RAW: 0.321096 megabytes\n",
      "saved test_y\n",
      "train_x Size stays the same False\n",
      "train_y Size stays the same False\n",
      "test_x Size stays the same False\n",
      "test_y Size stays the same False\n",
      "train_xNPSize (text) size: 295.42 megabytes\n",
      "train_yNPSize (labels) size: 0.059084 megabytes\n",
      "test_xNPSize (text) size: 794.8 megabytes\n",
      "test_yNPSize (labels) size: 0.15896 megabytes\n",
      "train_xNP length  14771\n",
      "train_xNP dimension of element  2\n",
      "train_xNP size  73855000\n",
      "saving NP arrays\n",
      "NP arrays saved\n",
      "Initializing classifier\n",
      "Searching for a  RandomForestClassifier\n",
      "False\n",
      "file not found, creating new classifier\n",
      "this is the classifierName:  RandomForestClassifier\n",
      "Training...\n",
      "train_x (text) size: 295.42 megabytes\n",
      "train_y (labels) size: 0.059084 megabytes\n",
      "train_x (text) length: 14771\n",
      "train_y (labels) length: 14771\n",
      "[[0 0 0 ... 0 0 0]\n",
      " [1 1 0 ... 0 0 0]\n",
      " [1 1 0 ... 0 0 0]\n",
      " [1 0 0 ... 0 0 0]\n",
      " [0 1 0 ... 0 0 0]]\n",
      "[0 0 0 0 0]\n",
      "finished training, classifier size: 4.8e-05 megabytes\n",
      "Predicting...\n",
      "Analysing...\n",
      "analyse_results\n",
      "hello\n",
      "Precision\t0.32672370407649726\n",
      "Recall\t0.32672370407649726\n",
      "F1-score\t0.32672370407649726\n",
      "Accuracy\t0.32672370407649726\n",
      "classiferSaveFile:  tales-emotion_crowdflowerRandomForestClassifier.pkl\n",
      "Saved Successfully\n",
      "Total: 475 GiB\n",
      "Used: 334 GiB\n",
      "Free: 140 GiB\n",
      "-----------------------------------------------------------------------------------------\n",
      "('tales-emotion', 'affectivetext', 'tales', 'headlines')\n",
      "Getting data\n",
      "get_train_test param:\n",
      "json  unified-dataset.jsonl\n",
      "train  tales-emotion\n",
      "test  affectivetext\n",
      "there were  1250  entries that were in test and  220189 that were not in test and  14771  that were in train\n",
      "test was appended  1250  times\n",
      "single\n",
      "Detected mode: multi...\n",
      "14771 1250\n",
      "Getting wordlist...\n",
      "Getting emotions\n",
      "['anger', 'joy', 'surprise', 'disgust', 'sadness', 'fear']\n",
      "Making arrays\n",
      "checking for save files\n",
      "emotions in make_arrays:  {'anger': 0, 'joy': 1, 'surprise': 2, 'disgust': 3, 'sadness': 4, 'fear': 5}\n",
      "train super raw:  0.124912\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████| 14771/14771 [00:06<00:00, 2354.24it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████| 1250/1250 [00:00<00:00, 2129.23it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_x length  14771\n",
      "train_x dimension of element  5000\n",
      "train_x (text) size RAW: 0.124912 megabytes\n",
      "train_y (labels) size RAW: 0.124912 megabytes\n",
      "test_x (text) size RAW: 0.010192 megabytes\n",
      "test_y (labels) size RAW: 0.010192 megabytes\n",
      "saved test_y\n",
      "train_x Size stays the same False\n",
      "train_y Size stays the same False\n",
      "test_x Size stays the same False\n",
      "test_y Size stays the same False\n",
      "train_xNPSize (text) size: 295.42 megabytes\n",
      "train_yNPSize (labels) size: 0.354504 megabytes\n",
      "test_xNPSize (text) size: 25.0 megabytes\n",
      "test_yNPSize (labels) size: 0.03 megabytes\n",
      "train_xNP length  14771\n",
      "train_xNP dimension of element  2\n",
      "train_xNP size  73855000\n",
      "saving NP arrays\n",
      "NP arrays saved\n",
      "Initializing classifier\n",
      "Searching for a  RandomForestClassifier\n",
      "False\n",
      "file not found, creating new classifier\n",
      "this is the classifierName:  RandomForestClassifier\n",
      "Training...\n",
      "train_x (text) size: 295.42 megabytes\n",
      "train_y (labels) size: 0.354504 megabytes\n",
      "train_x (text) length: 14771\n",
      "train_y (labels) length: 14771\n",
      "[[0 0 0 ... 0 0 0]\n",
      " [1 1 0 ... 0 0 0]\n",
      " [1 1 0 ... 0 0 0]\n",
      " [1 0 0 ... 0 0 0]\n",
      " [0 1 0 ... 0 0 0]]\n",
      "[[0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0]]\n",
      "finished training, classifier size: 4.8e-05 megabytes\n",
      "Predicting...\n",
      "Analysing...\n",
      "analyse_results\n",
      "hello\n",
      "Precision\t0.8888888888888888\n",
      "Recall\t0.007453416149068323\n",
      "F1-score\t0.014782876501385893\n",
      "Accuracy\t0.0344\n",
      "classiferSaveFile:  tales-emotion_affectivetextRandomForestClassifier.pkl\n",
      "Saved Successfully\n",
      "Total: 475 GiB\n",
      "Used: 335 GiB\n",
      "Free: 139 GiB\n",
      "-----------------------------------------------------------------------------------------\n",
      "('emotion-cause', 'tec', 'paragraphs', 'tweets')\n",
      "Getting data\n",
      "get_train_test param:\n",
      "json  unified-dataset.jsonl\n",
      "train  emotion-cause\n",
      "test  tec\n",
      "there were  21051  entries that were in test and  200388 that were not in test and  2414  that were in train\n",
      "test was appended  21051  times\n",
      "single\n",
      "oof\n",
      "Detected mode: single...\n",
      "2414 21051\n",
      "Getting wordlist...\n",
      "Getting emotions\n",
      "['anger', 'joy', 'noemo', 'surprise', 'disgust', 'sadness', 'fear']\n",
      "Making arrays\n",
      "checking for save files\n",
      "emotions in make_arrays:  {'anger': 0, 'joy': 1, 'noemo': 2, 'surprise': 3, 'disgust': 4, 'sadness': 5, 'fear': 6}\n",
      "train super raw:  0.02104\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████| 2414/2414 [00:00<00:00, 2647.86it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████| 21051/21051 [00:08<00:00, 2489.85it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_x length  2414\n",
      "train_x dimension of element  5000\n",
      "train_x (text) size RAW: 0.02104 megabytes\n",
      "train_y (labels) size RAW: 0.02104 megabytes\n",
      "test_x (text) size RAW: 0.178016 megabytes\n",
      "test_y (labels) size RAW: 0.178016 megabytes\n",
      "saved test_y\n",
      "train_x Size stays the same False\n",
      "train_y Size stays the same False\n",
      "test_x Size stays the same False\n",
      "test_y Size stays the same False\n",
      "train_xNPSize (text) size: 48.28 megabytes\n",
      "train_yNPSize (labels) size: 0.009656 megabytes\n",
      "test_xNPSize (text) size: 421.02 megabytes\n",
      "test_yNPSize (labels) size: 0.084204 megabytes\n",
      "train_xNP length  2414\n",
      "train_xNP dimension of element  2\n",
      "train_xNP size  12070000\n",
      "saving NP arrays\n",
      "NP arrays saved\n",
      "Initializing classifier\n",
      "Searching for a  RandomForestClassifier\n",
      "False\n",
      "file not found, creating new classifier\n",
      "this is the classifierName:  RandomForestClassifier\n",
      "Training...\n",
      "train_x (text) size: 48.28 megabytes\n",
      "train_y (labels) size: 0.009656 megabytes\n",
      "train_x (text) length: 2414\n",
      "train_y (labels) length: 2414\n",
      "[[1 1 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " [1 1 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]]\n",
      "[1 1 1 1 1]\n",
      "finished training, classifier size: 4.8e-05 megabytes\n",
      "Predicting...\n",
      "Analysing...\n",
      "analyse_results\n",
      "hello\n",
      "Precision\t0.19799534463920954\n",
      "Recall\t0.19799534463920954\n",
      "F1-score\t0.19799534463920954\n",
      "Accuracy\t0.19799534463920954\n",
      "classiferSaveFile:  emotion-cause_tecRandomForestClassifier.pkl\n",
      "Saved Successfully\n",
      "Total: 475 GiB\n",
      "Used: 335 GiB\n",
      "Free: 139 GiB\n",
      "-----------------------------------------------------------------------------------------\n",
      "('emotion-cause', 'tales-emotion', 'paragraphs', 'tales')\n",
      "Getting data\n",
      "get_train_test param:\n",
      "json  unified-dataset.jsonl\n",
      "train  emotion-cause\n",
      "test  tales-emotion\n",
      "there were  14771  entries that were in test and  206668 that were not in test and  2414  that were in train\n",
      "test was appended  14771  times\n",
      "single\n",
      "oof\n",
      "Detected mode: single...\n",
      "2414 14771\n",
      "Getting wordlist...\n",
      "Getting emotions\n",
      "['anger', 'joy', 'noemo', 'surprise', 'disgust', 'sadness', 'fear']\n",
      "Making arrays\n",
      "checking for save files\n",
      "emotions in make_arrays:  {'anger': 0, 'joy': 1, 'noemo': 2, 'surprise': 3, 'disgust': 4, 'sadness': 5, 'fear': 6}\n",
      "train super raw:  0.02104\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████| 2414/2414 [00:00<00:00, 2958.43it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████| 14771/14771 [00:05<00:00, 2505.95it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_x length  2414\n",
      "train_x dimension of element  5000\n",
      "train_x (text) size RAW: 0.02104 megabytes\n",
      "train_y (labels) size RAW: 0.02104 megabytes\n",
      "test_x (text) size RAW: 0.124912 megabytes\n",
      "test_y (labels) size RAW: 0.124912 megabytes\n",
      "saved test_y\n",
      "train_x Size stays the same False\n",
      "train_y Size stays the same False\n",
      "test_x Size stays the same False\n",
      "test_y Size stays the same False\n",
      "train_xNPSize (text) size: 48.28 megabytes\n",
      "train_yNPSize (labels) size: 0.009656 megabytes\n",
      "test_xNPSize (text) size: 295.42 megabytes\n",
      "test_yNPSize (labels) size: 0.059084 megabytes\n",
      "train_xNP length  2414\n",
      "train_xNP dimension of element  2\n",
      "train_xNP size  12070000\n",
      "saving NP arrays\n",
      "NP arrays saved\n",
      "Initializing classifier\n",
      "Searching for a  RandomForestClassifier\n",
      "False\n",
      "file not found, creating new classifier\n",
      "this is the classifierName:  RandomForestClassifier\n",
      "Training...\n",
      "train_x (text) size: 48.28 megabytes\n",
      "train_y (labels) size: 0.009656 megabytes\n",
      "train_x (text) length: 2414\n",
      "train_y (labels) length: 2414\n",
      "[[1 1 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " [1 1 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]]\n",
      "[1 1 1 1 1]\n",
      "finished training, classifier size: 4.8e-05 megabytes\n",
      "Predicting...\n",
      "Analysing...\n",
      "analyse_results\n",
      "hello\n",
      "Precision\t0.08834879155101212\n",
      "Recall\t0.08834879155101212\n",
      "F1-score\t0.08834879155101212\n",
      "Accuracy\t0.08834879155101212\n",
      "classiferSaveFile:  emotion-cause_tales-emotionRandomForestClassifier.pkl\n",
      "Saved Successfully\n",
      "Total: 475 GiB\n",
      "Used: 335 GiB\n",
      "Free: 139 GiB\n",
      "-----------------------------------------------------------------------------------------\n",
      "('emotion-cause', 'ssec', 'paragraphs', 'tweets')\n",
      "Getting data\n",
      "get_train_test param:\n",
      "json  unified-dataset.jsonl\n",
      "train  emotion-cause\n",
      "test  ssec\n",
      "there were  4868  entries that were in test and  216571 that were not in test and  2414  that were in train\n",
      "test was appended  4868  times\n",
      "single\n",
      "Detected mode: multi...\n",
      "2414 4868\n",
      "Getting wordlist...\n",
      "Getting emotions\n",
      "['anger', 'joy', 'surprise', 'disgust', 'sadness', 'fear']\n",
      "Making arrays\n",
      "checking for save files\n",
      "emotions in make_arrays:  {'anger': 0, 'joy': 1, 'surprise': 2, 'disgust': 3, 'sadness': 4, 'fear': 5}\n",
      "train super raw:  0.02104\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████| 2414/2414 [00:00<00:00, 2527.43it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████| 4868/4868 [00:02<00:00, 2393.88it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_x length  2414\n",
      "train_x dimension of element  5000\n",
      "train_x (text) size RAW: 0.02104 megabytes\n",
      "train_y (labels) size RAW: 0.02104 megabytes\n",
      "test_x (text) size RAW: 0.043032 megabytes\n",
      "test_y (labels) size RAW: 0.043032 megabytes\n",
      "saved test_y\n",
      "train_x Size stays the same False\n",
      "train_y Size stays the same False\n",
      "test_x Size stays the same False\n",
      "test_y Size stays the same False\n",
      "train_xNPSize (text) size: 48.28 megabytes\n",
      "train_yNPSize (labels) size: 0.057936 megabytes\n",
      "test_xNPSize (text) size: 97.36 megabytes\n",
      "test_yNPSize (labels) size: 0.116832 megabytes\n",
      "train_xNP length  2414\n",
      "train_xNP dimension of element  2\n",
      "train_xNP size  12070000\n",
      "saving NP arrays\n",
      "NP arrays saved\n",
      "Initializing classifier\n",
      "Searching for a  RandomForestClassifier\n",
      "False\n",
      "file not found, creating new classifier\n",
      "this is the classifierName:  RandomForestClassifier\n",
      "Training...\n",
      "train_x (text) size: 48.28 megabytes\n",
      "train_y (labels) size: 0.057936 megabytes\n",
      "train_x (text) length: 2414\n",
      "train_y (labels) length: 2414\n",
      "[[1 1 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " [1 1 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]]\n",
      "[[0 1 0 0 0 0]\n",
      " [0 1 0 0 0 0]\n",
      " [0 1 0 0 0 0]\n",
      " [0 1 0 0 0 0]\n",
      " [0 1 0 0 0 0]]\n",
      "finished training, classifier size: 4.8e-05 megabytes\n",
      "Predicting...\n",
      "Analysing...\n",
      "analyse_results\n",
      "hello\n",
      "Precision\t0.8440366972477065\n",
      "Recall\t0.007219083490269931\n",
      "F1-score\t0.014315723955496771\n",
      "Accuracy\t0.04601479046836483\n",
      "classiferSaveFile:  emotion-cause_ssecRandomForestClassifier.pkl\n",
      "Saved Successfully\n",
      "Total: 475 GiB\n",
      "Used: 336 GiB\n",
      "Free: 138 GiB\n",
      "-----------------------------------------------------------------------------------------\n",
      "('emotion-cause', 'isear', 'paragraphs', 'descriptions')\n",
      "Getting data\n",
      "get_train_test param:\n",
      "json  unified-dataset.jsonl\n",
      "train  emotion-cause\n",
      "test  isear\n",
      "there were  7666  entries that were in test and  213773 that were not in test and  2414  that were in train\n",
      "test was appended  7666  times\n",
      "single\n",
      "oof\n",
      "Detected mode: single...\n",
      "2414 7666\n",
      "Getting wordlist...\n",
      "Getting emotions\n",
      "['anger', 'joy', 'noemo', 'disgust', 'sadness', 'fear']\n",
      "Making arrays\n",
      "checking for save files\n",
      "emotions in make_arrays:  {'anger': 0, 'joy': 1, 'noemo': 2, 'disgust': 3, 'sadness': 4, 'fear': 5}\n",
      "train super raw:  0.02104\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████| 2414/2414 [00:00<00:00, 2983.68it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████| 7666/7666 [00:02<00:00, 2948.58it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_x length  2414\n",
      "train_x dimension of element  5000\n",
      "train_x (text) size RAW: 0.02104 megabytes\n",
      "train_y (labels) size RAW: 0.02104 megabytes\n",
      "test_x (text) size RAW: 0.061424 megabytes\n",
      "test_y (labels) size RAW: 0.061424 megabytes\n",
      "saved test_y\n",
      "train_x Size stays the same False\n",
      "train_y Size stays the same False\n",
      "test_x Size stays the same False\n",
      "test_y Size stays the same False\n",
      "train_xNPSize (text) size: 48.28 megabytes\n",
      "train_yNPSize (labels) size: 0.009656 megabytes\n",
      "test_xNPSize (text) size: 153.32 megabytes\n",
      "test_yNPSize (labels) size: 0.030664 megabytes\n",
      "train_xNP length  2414\n",
      "train_xNP dimension of element  2\n",
      "train_xNP size  12070000\n",
      "saving NP arrays\n",
      "NP arrays saved\n",
      "Initializing classifier\n",
      "Searching for a  RandomForestClassifier\n",
      "False\n",
      "file not found, creating new classifier\n",
      "this is the classifierName:  RandomForestClassifier\n",
      "Training...\n",
      "train_x (text) size: 48.28 megabytes\n",
      "train_y (labels) size: 0.009656 megabytes\n",
      "train_x (text) length: 2414\n",
      "train_y (labels) length: 2414\n",
      "[[1 1 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " [1 1 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]]\n",
      "[1 1 1 1 1]\n",
      "finished training, classifier size: 4.8e-05 megabytes\n",
      "Predicting...\n",
      "Analysing...\n",
      "analyse_results\n",
      "hello\n",
      "Precision\t0.24315157839812157\n",
      "Recall\t0.24315157839812157\n",
      "F1-score\t0.24315157839812157\n",
      "Accuracy\t0.24315157839812157\n",
      "classiferSaveFile:  emotion-cause_isearRandomForestClassifier.pkl\n",
      "Saved Successfully\n",
      "Total: 475 GiB\n",
      "Used: 336 GiB\n",
      "Free: 138 GiB\n",
      "-----------------------------------------------------------------------------------------\n",
      "('emotion-cause', 'grounded_emotions', 'paragraphs', 'tweets')\n",
      "Getting data\n",
      "get_train_test param:\n",
      "json  unified-dataset.jsonl\n",
      "train  emotion-cause\n",
      "test  grounded_emotions\n",
      "there were  2585  entries that were in test and  218854 that were not in test and  2414  that were in train\n",
      "test was appended  2585  times\n",
      "single\n",
      "oof\n",
      "Detected mode: single...\n",
      "2414 2585\n",
      "Getting wordlist...\n",
      "Getting emotions\n",
      "['joy', 'noemo', 'sadness']\n",
      "Making arrays\n",
      "checking for save files\n",
      "emotions in make_arrays:  {'joy': 0, 'noemo': 1, 'sadness': 2}\n",
      "train super raw:  0.02104\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████| 2414/2414 [00:00<00:00, 2937.13it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████| 2585/2585 [00:00<00:00, 3093.14it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_x length  2414\n",
      "train_x dimension of element  5000\n",
      "train_x (text) size RAW: 0.02104 megabytes\n",
      "train_y (labels) size RAW: 0.02104 megabytes\n",
      "test_x (text) size RAW: 0.02104 megabytes\n",
      "test_y (labels) size RAW: 0.02104 megabytes\n",
      "saved test_y\n",
      "train_x Size stays the same False\n",
      "train_y Size stays the same False\n",
      "test_x Size stays the same False\n",
      "test_y Size stays the same False\n",
      "train_xNPSize (text) size: 48.28 megabytes\n",
      "train_yNPSize (labels) size: 0.009656 megabytes\n",
      "test_xNPSize (text) size: 51.7 megabytes\n",
      "test_yNPSize (labels) size: 0.01034 megabytes\n",
      "train_xNP length  2414\n",
      "train_xNP dimension of element  2\n",
      "train_xNP size  12070000\n",
      "saving NP arrays\n",
      "NP arrays saved\n",
      "Initializing classifier\n",
      "Searching for a  RandomForestClassifier\n",
      "False\n",
      "file not found, creating new classifier\n",
      "this is the classifierName:  RandomForestClassifier\n",
      "Training...\n",
      "train_x (text) size: 48.28 megabytes\n",
      "train_y (labels) size: 0.009656 megabytes\n",
      "train_x (text) length: 2414\n",
      "train_y (labels) length: 2414\n",
      "[[1 1 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " [1 1 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]]\n",
      "[0 0 0 0 0]\n",
      "finished training, classifier size: 4.8e-05 megabytes\n",
      "Predicting...\n",
      "Analysing...\n",
      "analyse_results\n",
      "hello\n",
      "Precision\t0.06344294003868473\n",
      "Recall\t0.06344294003868473\n",
      "F1-score\t0.06344294003868473\n",
      "Accuracy\t0.06344294003868473\n",
      "classiferSaveFile:  emotion-cause_grounded_emotionsRandomForestClassifier.pkl\n",
      "Saved Successfully\n",
      "Total: 475 GiB\n",
      "Used: 336 GiB\n",
      "Free: 138 GiB\n",
      "-----------------------------------------------------------------------------------------\n",
      "('emotion-cause', 'emoint', 'paragraphs', 'tweets')\n",
      "Getting data\n",
      "get_train_test param:\n",
      "json  unified-dataset.jsonl\n",
      "train  emotion-cause\n",
      "test  emoint\n",
      "there were  7102  entries that were in test and  214337 that were not in test and  2414  that were in train\n",
      "test was appended  7102  times\n",
      "single\n",
      "oof\n",
      "Detected mode: single...\n",
      "2414 7102\n",
      "Getting wordlist...\n",
      "Getting emotions\n",
      "['anger', 'joy', 'noemo', 'sadness', 'fear']\n",
      "Making arrays\n",
      "checking for save files\n",
      "emotions in make_arrays:  {'anger': 0, 'joy': 1, 'noemo': 2, 'sadness': 3, 'fear': 4}\n",
      "train super raw:  0.02104\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████| 2414/2414 [00:00<00:00, 2954.86it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████| 7102/7102 [00:02<00:00, 2797.51it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_x length  2414\n",
      "train_x dimension of element  5000\n",
      "train_x (text) size RAW: 0.02104 megabytes\n",
      "train_y (labels) size RAW: 0.02104 megabytes\n",
      "test_x (text) size RAW: 0.061424 megabytes\n",
      "test_y (labels) size RAW: 0.061424 megabytes\n",
      "saved test_y\n",
      "train_x Size stays the same False\n",
      "train_y Size stays the same False\n",
      "test_x Size stays the same False\n",
      "test_y Size stays the same False\n",
      "train_xNPSize (text) size: 48.28 megabytes\n",
      "train_yNPSize (labels) size: 0.009656 megabytes\n",
      "test_xNPSize (text) size: 142.04 megabytes\n",
      "test_yNPSize (labels) size: 0.028408 megabytes\n",
      "train_xNP length  2414\n",
      "train_xNP dimension of element  2\n",
      "train_xNP size  12070000\n",
      "saving NP arrays\n",
      "NP arrays saved\n",
      "Initializing classifier\n",
      "Searching for a  RandomForestClassifier\n",
      "False\n",
      "file not found, creating new classifier\n",
      "this is the classifierName:  RandomForestClassifier\n",
      "Training...\n",
      "train_x (text) size: 48.28 megabytes\n",
      "train_y (labels) size: 0.009656 megabytes\n",
      "train_x (text) length: 2414\n",
      "train_y (labels) length: 2414\n",
      "[[1 1 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " [1 1 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]]\n",
      "[1 1 1 1 1]\n",
      "finished training, classifier size: 4.8e-05 megabytes\n",
      "Predicting...\n",
      "Analysing...\n",
      "analyse_results\n",
      "hello\n",
      "Precision\t0.3321599549422698\n",
      "Recall\t0.3321599549422698\n",
      "F1-score\t0.3321599549422698\n",
      "Accuracy\t0.3321599549422698\n",
      "classiferSaveFile:  emotion-cause_emointRandomForestClassifier.pkl\n",
      "Saved Successfully\n",
      "Total: 475 GiB\n",
      "Used: 336 GiB\n",
      "Free: 138 GiB\n",
      "-----------------------------------------------------------------------------------------\n",
      "('emotion-cause', 'emobank', 'paragraphs', 'headlines')\n",
      "Getting data\n",
      "get_train_test param:\n",
      "json  unified-dataset.jsonl\n",
      "train  emotion-cause\n",
      "test  emobank\n",
      "there were  10062  entries that were in test and  211377 that were not in test and  2414  that were in train\n",
      "test was appended  10062  times\n",
      "single\n",
      "Detected mode: multi...\n",
      "2414 10062\n",
      "Getting wordlist...\n",
      "Getting emotions\n",
      "[]\n",
      "Making arrays\n",
      "checking for save files\n",
      "emotions in make_arrays:  {}\n",
      "train super raw:  0.02104\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████| 2414/2414 [00:00<00:00, 2745.85it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████| 10062/10062 [00:03<00:00, 2662.64it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_x length  2414\n",
      "train_x dimension of element  5000\n",
      "train_x (text) size RAW: 0.02104 megabytes\n",
      "train_y (labels) size RAW: 0.02104 megabytes\n",
      "test_x (text) size RAW: 0.087616 megabytes\n",
      "test_y (labels) size RAW: 0.087616 megabytes\n",
      "saved test_y\n",
      "train_x Size stays the same False\n",
      "train_y Size stays the same False\n",
      "test_x Size stays the same False\n",
      "test_y Size stays the same False\n",
      "train_xNPSize (text) size: 48.28 megabytes\n",
      "train_yNPSize (labels) size: 0.0 megabytes\n",
      "test_xNPSize (text) size: 201.24 megabytes\n",
      "test_yNPSize (labels) size: 0.0 megabytes\n",
      "train_xNP length  2414\n",
      "train_xNP dimension of element  2\n",
      "train_xNP size  12070000\n",
      "Train or test empty. Did you misspell the dataset name?\n",
      "('emotion-cause', 'dailydialog', 'paragraphs', 'conversations')\n",
      "Getting data\n",
      "get_train_test param:\n",
      "json  unified-dataset.jsonl\n",
      "train  emotion-cause\n",
      "test  dailydialog\n",
      "there were  102979  entries that were in test and  118460 that were not in test and  2414  that were in train\n",
      "test was appended  102979  times\n",
      "single\n",
      "oof\n",
      "Detected mode: single...\n",
      "2414 102979\n",
      "Getting wordlist...\n",
      "Getting emotions\n",
      "['anger', 'joy', 'noemo', 'surprise', 'disgust', 'sadness', 'fear']\n",
      "Making arrays\n",
      "checking for save files\n",
      "emotions in make_arrays:  {'anger': 0, 'joy': 1, 'noemo': 2, 'surprise': 3, 'disgust': 4, 'sadness': 5, 'fear': 6}\n",
      "train super raw:  0.02104\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████| 2414/2414 [00:01<00:00, 2248.68it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████| 102979/102979 [00:41<00:00, 2488.16it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_x length  2414\n",
      "train_x dimension of element  5000\n",
      "train_x (text) size RAW: 0.02104 megabytes\n",
      "train_y (labels) size RAW: 0.02104 megabytes\n",
      "test_x (text) size RAW: 0.824456 megabytes\n",
      "test_y (labels) size RAW: 0.824456 megabytes\n",
      "saved test_y\n",
      "train_x Size stays the same False\n",
      "train_y Size stays the same False\n",
      "test_x Size stays the same False\n",
      "test_y Size stays the same False\n",
      "train_xNPSize (text) size: 48.28 megabytes\n",
      "train_yNPSize (labels) size: 0.009656 megabytes\n",
      "test_xNPSize (text) size: 2059.58 megabytes\n",
      "test_yNPSize (labels) size: 0.411916 megabytes\n",
      "train_xNP length  2414\n",
      "train_xNP dimension of element  2\n",
      "train_xNP size  12070000\n",
      "saving NP arrays\n",
      "NP arrays saved\n",
      "Initializing classifier\n",
      "Searching for a  RandomForestClassifier\n",
      "False\n",
      "file not found, creating new classifier\n",
      "this is the classifierName:  RandomForestClassifier\n",
      "Training...\n",
      "train_x (text) size: 48.28 megabytes\n",
      "train_y (labels) size: 0.009656 megabytes\n",
      "train_x (text) length: 2414\n",
      "train_y (labels) length: 2414\n",
      "[[1 1 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " [1 1 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]]\n",
      "[1 1 1 1 1]\n",
      "finished training, classifier size: 4.8e-05 megabytes\n",
      "Predicting...\n",
      "Analysing...\n",
      "analyse_results\n",
      "hello\n",
      "Precision\t0.026228648559415025\n",
      "Recall\t0.026228648559415025\n",
      "F1-score\t0.026228648559415025\n",
      "Accuracy\t0.026228648559415025\n",
      "classiferSaveFile:  emotion-cause_dailydialogRandomForestClassifier.pkl\n",
      "Saved Successfully\n",
      "Total: 475 GiB\n",
      "Used: 338 GiB\n",
      "Free: 136 GiB\n",
      "-----------------------------------------------------------------------------------------\n",
      "('emotion-cause', 'crowdflower', 'paragraphs', 'tweets')\n",
      "Getting data\n",
      "get_train_test param:\n",
      "json  unified-dataset.jsonl\n",
      "train  emotion-cause\n",
      "test  crowdflower\n",
      "there were  39740  entries that were in test and  181699 that were not in test and  2414  that were in train\n",
      "test was appended  39740  times\n",
      "single\n",
      "oof\n",
      "Detected mode: single...\n",
      "2414 39740\n",
      "Getting wordlist...\n",
      "Getting emotions\n",
      "['anger', 'joy', 'noemo', 'surprise', 'disgust', 'sadness', 'fear']\n",
      "Making arrays\n",
      "checking for save files\n",
      "emotions in make_arrays:  {'anger': 0, 'joy': 1, 'noemo': 2, 'surprise': 3, 'disgust': 4, 'sadness': 5, 'fear': 6}\n",
      "train super raw:  0.02104\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████| 2414/2414 [00:00<00:00, 2783.41it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████| 39740/39740 [00:15<00:00, 2596.01it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_x length  2414\n",
      "train_x dimension of element  5000\n",
      "train_x (text) size RAW: 0.02104 megabytes\n",
      "train_y (labels) size RAW: 0.02104 megabytes\n",
      "test_x (text) size RAW: 0.321096 megabytes\n",
      "test_y (labels) size RAW: 0.321096 megabytes\n",
      "saved test_y\n",
      "train_x Size stays the same False\n",
      "train_y Size stays the same False\n",
      "test_x Size stays the same False\n",
      "test_y Size stays the same False\n",
      "train_xNPSize (text) size: 48.28 megabytes\n",
      "train_yNPSize (labels) size: 0.009656 megabytes\n",
      "test_xNPSize (text) size: 794.8 megabytes\n",
      "test_yNPSize (labels) size: 0.15896 megabytes\n",
      "train_xNP length  2414\n",
      "train_xNP dimension of element  2\n",
      "train_xNP size  12070000\n",
      "saving NP arrays\n",
      "NP arrays saved\n",
      "Initializing classifier\n",
      "Searching for a  RandomForestClassifier\n",
      "False\n",
      "file not found, creating new classifier\n",
      "this is the classifierName:  RandomForestClassifier\n",
      "Training...\n",
      "train_x (text) size: 48.28 megabytes\n",
      "train_y (labels) size: 0.009656 megabytes\n",
      "train_x (text) length: 2414\n",
      "train_y (labels) length: 2414\n",
      "[[1 1 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " [1 1 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]]\n",
      "[1 1 1 1 1]\n",
      "finished training, classifier size: 4.8e-05 megabytes\n",
      "Predicting...\n",
      "Analysing...\n",
      "analyse_results\n",
      "hello\n",
      "Precision\t0.14386009058882737\n",
      "Recall\t0.14386009058882737\n",
      "F1-score\t0.14386009058882737\n",
      "Accuracy\t0.14386009058882737\n",
      "classiferSaveFile:  emotion-cause_crowdflowerRandomForestClassifier.pkl\n",
      "Saved Successfully\n",
      "Total: 475 GiB\n",
      "Used: 339 GiB\n",
      "Free: 135 GiB\n",
      "-----------------------------------------------------------------------------------------\n",
      "('emotion-cause', 'affectivetext', 'paragraphs', 'headlines')\n",
      "Getting data\n",
      "get_train_test param:\n",
      "json  unified-dataset.jsonl\n",
      "train  emotion-cause\n",
      "test  affectivetext\n",
      "there were  1250  entries that were in test and  220189 that were not in test and  2414  that were in train\n",
      "test was appended  1250  times\n",
      "single\n",
      "Detected mode: multi...\n",
      "2414 1250\n",
      "Getting wordlist...\n",
      "Getting emotions\n",
      "['anger', 'joy', 'surprise', 'disgust', 'sadness', 'fear']\n",
      "Making arrays\n",
      "checking for save files\n",
      "emotions in make_arrays:  {'anger': 0, 'joy': 1, 'surprise': 2, 'disgust': 3, 'sadness': 4, 'fear': 5}\n",
      "train super raw:  0.02104\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████| 2414/2414 [00:01<00:00, 2013.64it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████| 1250/1250 [00:00<00:00, 2100.99it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_x length  2414\n",
      "train_x dimension of element  5000\n",
      "train_x (text) size RAW: 0.02104 megabytes\n",
      "train_y (labels) size RAW: 0.02104 megabytes\n",
      "test_x (text) size RAW: 0.010192 megabytes\n",
      "test_y (labels) size RAW: 0.010192 megabytes\n",
      "saved test_y\n",
      "train_x Size stays the same False\n",
      "train_y Size stays the same False\n",
      "test_x Size stays the same False\n",
      "test_y Size stays the same False\n",
      "train_xNPSize (text) size: 48.28 megabytes\n",
      "train_yNPSize (labels) size: 0.057936 megabytes\n",
      "test_xNPSize (text) size: 25.0 megabytes\n",
      "test_yNPSize (labels) size: 0.03 megabytes\n",
      "train_xNP length  2414\n",
      "train_xNP dimension of element  2\n",
      "train_xNP size  12070000\n",
      "saving NP arrays\n",
      "NP arrays saved\n",
      "Initializing classifier\n",
      "Searching for a  RandomForestClassifier\n",
      "False\n",
      "file not found, creating new classifier\n",
      "this is the classifierName:  RandomForestClassifier\n",
      "Training...\n",
      "train_x (text) size: 48.28 megabytes\n",
      "train_y (labels) size: 0.057936 megabytes\n",
      "train_x (text) length: 2414\n",
      "train_y (labels) length: 2414\n",
      "[[1 1 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " [1 1 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]]\n",
      "[[0 1 0 0 0 0]\n",
      " [0 1 0 0 0 0]\n",
      " [0 1 0 0 0 0]\n",
      " [0 1 0 0 0 0]\n",
      " [0 1 0 0 0 0]]\n",
      "finished training, classifier size: 4.8e-05 megabytes\n",
      "Predicting...\n",
      "Analysing...\n",
      "analyse_results\n",
      "hello\n",
      "Precision\t0.8571428571428571\n",
      "Recall\t0.0018633540372670807\n",
      "F1-score\t0.00371862410907964\n",
      "Accuracy\t0.0328\n",
      "classiferSaveFile:  emotion-cause_affectivetextRandomForestClassifier.pkl\n",
      "Saved Successfully\n",
      "Total: 475 GiB\n",
      "Used: 339 GiB\n",
      "Free: 135 GiB\n",
      "-----------------------------------------------------------------------------------------\n",
      "('emobank', 'tec', 'headlines', 'tweets')\n",
      "Getting data\n",
      "get_train_test param:\n",
      "json  unified-dataset.jsonl\n",
      "train  emobank\n",
      "test  tec\n",
      "there were  21051  entries that were in test and  200388 that were not in test and  10062  that were in train\n",
      "test was appended  21051  times\n",
      "multi\n",
      "oof\n",
      "Detected mode: multi...\n",
      "10062 21051\n",
      "Getting wordlist...\n",
      "Getting emotions\n",
      "[]\n",
      "Making arrays\n",
      "checking for save files\n",
      "emotions in make_arrays:  {}\n",
      "train super raw:  0.087616\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████| 10062/10062 [00:04<00:00, 2433.31it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████| 21051/21051 [00:09<00:00, 2295.12it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_x length  10062\n",
      "train_x dimension of element  5000\n",
      "train_x (text) size RAW: 0.087616 megabytes\n",
      "train_y (labels) size RAW: 0.087616 megabytes\n",
      "test_x (text) size RAW: 0.178016 megabytes\n",
      "test_y (labels) size RAW: 0.178016 megabytes\n",
      "saved test_y\n",
      "train_x Size stays the same False\n",
      "train_y Size stays the same False\n",
      "test_x Size stays the same False\n",
      "test_y Size stays the same False\n",
      "train_xNPSize (text) size: 201.24 megabytes\n",
      "train_yNPSize (labels) size: 0.0 megabytes\n",
      "test_xNPSize (text) size: 421.02 megabytes\n",
      "test_yNPSize (labels) size: 0.0 megabytes\n",
      "train_xNP length  10062\n",
      "train_xNP dimension of element  2\n",
      "train_xNP size  50310000\n",
      "Train or test empty. Did you misspell the dataset name?\n",
      "('emobank', 'tales-emotion', 'headlines', 'tales')\n",
      "Getting data\n",
      "get_train_test param:\n",
      "json  unified-dataset.jsonl\n",
      "train  emobank\n",
      "test  tales-emotion\n",
      "there were  14771  entries that were in test and  206668 that were not in test and  10062  that were in train\n",
      "test was appended  14771  times\n",
      "multi\n",
      "oof\n",
      "Detected mode: multi...\n",
      "10062 14771\n",
      "Getting wordlist...\n",
      "Getting emotions\n",
      "[]\n",
      "Making arrays\n",
      "checking for save files\n",
      "emotions in make_arrays:  {}\n",
      "train super raw:  0.087616\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████| 10062/10062 [00:04<00:00, 2434.45it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████| 14771/14771 [00:06<00:00, 2436.22it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_x length  10062\n",
      "train_x dimension of element  5000\n",
      "train_x (text) size RAW: 0.087616 megabytes\n",
      "train_y (labels) size RAW: 0.087616 megabytes\n",
      "test_x (text) size RAW: 0.124912 megabytes\n",
      "test_y (labels) size RAW: 0.124912 megabytes\n",
      "saved test_y\n",
      "train_x Size stays the same False\n",
      "train_y Size stays the same False\n",
      "test_x Size stays the same False\n",
      "test_y Size stays the same False\n",
      "train_xNPSize (text) size: 201.24 megabytes\n",
      "train_yNPSize (labels) size: 0.0 megabytes\n",
      "test_xNPSize (text) size: 295.42 megabytes\n",
      "test_yNPSize (labels) size: 0.0 megabytes\n",
      "train_xNP length  10062\n",
      "train_xNP dimension of element  2\n",
      "train_xNP size  50310000\n",
      "Train or test empty. Did you misspell the dataset name?\n",
      "('emobank', 'ssec', 'headlines', 'tweets')\n",
      "Getting data\n",
      "get_train_test param:\n",
      "json  unified-dataset.jsonl\n",
      "train  emobank\n",
      "test  ssec\n",
      "there were  4868  entries that were in test and  216571 that were not in test and  10062  that were in train\n",
      "test was appended  4868  times\n",
      "multi\n",
      "Detected mode: multi...\n",
      "10062 4868\n",
      "Getting wordlist...\n",
      "Getting emotions\n",
      "[]\n",
      "Making arrays\n",
      "checking for save files\n",
      "emotions in make_arrays:  {}\n",
      "train super raw:  0.087616\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████| 10062/10062 [00:03<00:00, 2564.88it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████| 4868/4868 [00:02<00:00, 2410.25it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_x length  10062\n",
      "train_x dimension of element  5000\n",
      "train_x (text) size RAW: 0.087616 megabytes\n",
      "train_y (labels) size RAW: 0.087616 megabytes\n",
      "test_x (text) size RAW: 0.043032 megabytes\n",
      "test_y (labels) size RAW: 0.043032 megabytes\n",
      "saved test_y\n",
      "train_x Size stays the same False\n",
      "train_y Size stays the same False\n",
      "test_x Size stays the same False\n",
      "test_y Size stays the same False\n",
      "train_xNPSize (text) size: 201.24 megabytes\n",
      "train_yNPSize (labels) size: 0.0 megabytes\n",
      "test_xNPSize (text) size: 97.36 megabytes\n",
      "test_yNPSize (labels) size: 0.0 megabytes\n",
      "train_xNP length  10062\n",
      "train_xNP dimension of element  2\n",
      "train_xNP size  50310000\n",
      "Train or test empty. Did you misspell the dataset name?\n",
      "('emobank', 'isear', 'headlines', 'descriptions')\n",
      "Getting data\n",
      "get_train_test param:\n",
      "json  unified-dataset.jsonl\n",
      "train  emobank\n",
      "test  isear\n",
      "there were  7666  entries that were in test and  213773 that were not in test and  10062  that were in train\n",
      "test was appended  7666  times\n",
      "multi\n",
      "oof\n",
      "Detected mode: multi...\n",
      "10062 7666\n",
      "Getting wordlist...\n",
      "Getting emotions\n",
      "[]\n",
      "Making arrays\n",
      "checking for save files\n",
      "emotions in make_arrays:  {}\n",
      "train super raw:  0.087616\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████| 10062/10062 [00:04<00:00, 2484.28it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████| 7666/7666 [00:05<00:00, 1478.52it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_x length  10062\n",
      "train_x dimension of element  5000\n",
      "train_x (text) size RAW: 0.087616 megabytes\n",
      "train_y (labels) size RAW: 0.087616 megabytes\n",
      "test_x (text) size RAW: 0.061424 megabytes\n",
      "test_y (labels) size RAW: 0.061424 megabytes\n",
      "saved test_y\n",
      "train_x Size stays the same False\n",
      "train_y Size stays the same False\n",
      "test_x Size stays the same False\n",
      "test_y Size stays the same False\n",
      "train_xNPSize (text) size: 201.24 megabytes\n",
      "train_yNPSize (labels) size: 0.0 megabytes\n",
      "test_xNPSize (text) size: 153.32 megabytes\n",
      "test_yNPSize (labels) size: 0.0 megabytes\n",
      "train_xNP length  10062\n",
      "train_xNP dimension of element  2\n",
      "train_xNP size  50310000\n",
      "Train or test empty. Did you misspell the dataset name?\n",
      "('emobank', 'grounded_emotions', 'headlines', 'tweets')\n",
      "Getting data\n",
      "get_train_test param:\n",
      "json  unified-dataset.jsonl\n",
      "train  emobank\n",
      "test  grounded_emotions\n",
      "there were  2585  entries that were in test and  218854 that were not in test and  10062  that were in train\n",
      "test was appended  2585  times\n",
      "multi\n",
      "oof\n",
      "Detected mode: multi...\n",
      "10062 2585\n",
      "Getting wordlist...\n",
      "Getting emotions\n",
      "[]\n",
      "Making arrays\n",
      "checking for save files\n",
      "emotions in make_arrays:  {}\n",
      "train super raw:  0.087616\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████| 10062/10062 [00:04<00:00, 2458.53it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████| 2585/2585 [00:01<00:00, 1870.05it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_x length  10062\n",
      "train_x dimension of element  5000\n",
      "train_x (text) size RAW: 0.087616 megabytes\n",
      "train_y (labels) size RAW: 0.087616 megabytes\n",
      "test_x (text) size RAW: 0.02104 megabytes\n",
      "test_y (labels) size RAW: 0.02104 megabytes\n",
      "saved test_y\n",
      "train_x Size stays the same False\n",
      "train_y Size stays the same False\n",
      "test_x Size stays the same False\n",
      "test_y Size stays the same False\n",
      "train_xNPSize (text) size: 201.24 megabytes\n",
      "train_yNPSize (labels) size: 0.0 megabytes\n",
      "test_xNPSize (text) size: 51.7 megabytes\n",
      "test_yNPSize (labels) size: 0.0 megabytes\n",
      "train_xNP length  10062\n",
      "train_xNP dimension of element  2\n",
      "train_xNP size  50310000\n",
      "Train or test empty. Did you misspell the dataset name?\n",
      "('emobank', 'emotion-cause', 'headlines', 'paragraphs')\n",
      "Getting data\n",
      "get_train_test param:\n",
      "json  unified-dataset.jsonl\n",
      "train  emobank\n",
      "test  emotion-cause\n",
      "there were  2414  entries that were in test and  219025 that were not in test and  10062  that were in train\n",
      "test was appended  2414  times\n",
      "multi\n",
      "oof\n",
      "Detected mode: multi...\n",
      "10062 2414\n",
      "Getting wordlist...\n",
      "Getting emotions\n",
      "[]\n",
      "Making arrays\n",
      "checking for save files\n",
      "emotions in make_arrays:  {}\n",
      "train super raw:  0.087616\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████| 10062/10062 [00:04<00:00, 2302.01it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████| 2414/2414 [00:01<00:00, 2398.65it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_x length  10062\n",
      "train_x dimension of element  5000\n",
      "train_x (text) size RAW: 0.087616 megabytes\n",
      "train_y (labels) size RAW: 0.087616 megabytes\n",
      "test_x (text) size RAW: 0.02104 megabytes\n",
      "test_y (labels) size RAW: 0.02104 megabytes\n",
      "saved test_y\n",
      "train_x Size stays the same False\n",
      "train_y Size stays the same False\n",
      "test_x Size stays the same False\n",
      "test_y Size stays the same False\n",
      "train_xNPSize (text) size: 201.24 megabytes\n",
      "train_yNPSize (labels) size: 0.0 megabytes\n",
      "test_xNPSize (text) size: 48.28 megabytes\n",
      "test_yNPSize (labels) size: 0.0 megabytes\n",
      "train_xNP length  10062\n",
      "train_xNP dimension of element  2\n",
      "train_xNP size  50310000\n",
      "Train or test empty. Did you misspell the dataset name?\n",
      "('emobank', 'emoint', 'headlines', 'tweets')\n",
      "Getting data\n",
      "get_train_test param:\n",
      "json  unified-dataset.jsonl\n",
      "train  emobank\n",
      "test  emoint\n",
      "there were  7102  entries that were in test and  214337 that were not in test and  10062  that were in train\n",
      "test was appended  7102  times\n",
      "multi\n",
      "oof\n",
      "Detected mode: multi...\n",
      "10062 7102\n",
      "Getting wordlist...\n",
      "Getting emotions\n",
      "[]\n",
      "Making arrays\n",
      "checking for save files\n",
      "emotions in make_arrays:  {}\n",
      "train super raw:  0.087616\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████| 10062/10062 [00:04<00:00, 2410.85it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████| 7102/7102 [00:02<00:00, 2497.56it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_x length  10062\n",
      "train_x dimension of element  5000\n",
      "train_x (text) size RAW: 0.087616 megabytes\n",
      "train_y (labels) size RAW: 0.087616 megabytes\n",
      "test_x (text) size RAW: 0.061424 megabytes\n",
      "test_y (labels) size RAW: 0.061424 megabytes\n",
      "saved test_y\n",
      "train_x Size stays the same False\n",
      "train_y Size stays the same False\n",
      "test_x Size stays the same False\n",
      "test_y Size stays the same False\n",
      "train_xNPSize (text) size: 201.24 megabytes\n",
      "train_yNPSize (labels) size: 0.0 megabytes\n",
      "test_xNPSize (text) size: 142.04 megabytes\n",
      "test_yNPSize (labels) size: 0.0 megabytes\n",
      "train_xNP length  10062\n",
      "train_xNP dimension of element  2\n",
      "train_xNP size  50310000\n",
      "Train or test empty. Did you misspell the dataset name?\n",
      "('emobank', 'dailydialog', 'headlines', 'conversations')\n",
      "Getting data\n",
      "get_train_test param:\n",
      "json  unified-dataset.jsonl\n",
      "train  emobank\n",
      "test  dailydialog\n",
      "there were  102979  entries that were in test and  118460 that were not in test and  10062  that were in train\n",
      "test was appended  102979  times\n",
      "multi\n",
      "oof\n",
      "Detected mode: multi...\n",
      "10062 102979\n",
      "Getting wordlist...\n",
      "Getting emotions\n",
      "[]\n",
      "Making arrays\n",
      "checking for save files\n",
      "emotions in make_arrays:  {}\n",
      "train super raw:  0.087616\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████| 10062/10062 [00:04<00:00, 2449.08it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████| 102979/102979 [00:44<00:00, 2315.64it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_x length  10062\n",
      "train_x dimension of element  5000\n",
      "train_x (text) size RAW: 0.087616 megabytes\n",
      "train_y (labels) size RAW: 0.087616 megabytes\n",
      "test_x (text) size RAW: 0.824456 megabytes\n",
      "test_y (labels) size RAW: 0.824456 megabytes\n",
      "saved test_y\n",
      "train_x Size stays the same False\n",
      "train_y Size stays the same False\n",
      "test_x Size stays the same False\n",
      "test_y Size stays the same False\n",
      "train_xNPSize (text) size: 201.24 megabytes\n",
      "train_yNPSize (labels) size: 0.0 megabytes\n",
      "test_xNPSize (text) size: 2059.58 megabytes\n",
      "test_yNPSize (labels) size: 0.0 megabytes\n",
      "train_xNP length  10062\n",
      "train_xNP dimension of element  2\n",
      "train_xNP size  50310000\n",
      "Train or test empty. Did you misspell the dataset name?\n",
      "('emobank', 'crowdflower', 'headlines', 'tweets')\n",
      "Getting data\n",
      "get_train_test param:\n",
      "json  unified-dataset.jsonl\n",
      "train  emobank\n",
      "test  crowdflower\n",
      "there were  39740  entries that were in test and  181699 that were not in test and  10062  that were in train\n",
      "test was appended  39740  times\n",
      "multi\n",
      "oof\n",
      "Detected mode: multi...\n",
      "10062 39740\n",
      "Getting wordlist...\n",
      "Getting emotions\n",
      "[]\n",
      "Making arrays\n",
      "checking for save files\n",
      "emotions in make_arrays:  {}\n",
      "train super raw:  0.087616\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████| 10062/10062 [00:03<00:00, 2619.57it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████| 39740/39740 [00:16<00:00, 2362.43it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_x length  10062\n",
      "train_x dimension of element  5000\n",
      "train_x (text) size RAW: 0.087616 megabytes\n",
      "train_y (labels) size RAW: 0.087616 megabytes\n",
      "test_x (text) size RAW: 0.321096 megabytes\n",
      "test_y (labels) size RAW: 0.321096 megabytes\n",
      "saved test_y\n",
      "train_x Size stays the same False\n",
      "train_y Size stays the same False\n",
      "test_x Size stays the same False\n",
      "test_y Size stays the same False\n",
      "train_xNPSize (text) size: 201.24 megabytes\n",
      "train_yNPSize (labels) size: 0.0 megabytes\n",
      "test_xNPSize (text) size: 794.8 megabytes\n",
      "test_yNPSize (labels) size: 0.0 megabytes\n",
      "train_xNP length  10062\n",
      "train_xNP dimension of element  2\n",
      "train_xNP size  50310000\n",
      "Train or test empty. Did you misspell the dataset name?\n",
      "('emobank', 'affectivetext', 'headlines', 'headlines')\n",
      "Getting data\n",
      "get_train_test param:\n",
      "json  unified-dataset.jsonl\n",
      "train  emobank\n",
      "test  affectivetext\n",
      "there were  1250  entries that were in test and  220189 that were not in test and  10062  that were in train\n",
      "test was appended  1250  times\n",
      "multi\n",
      "Detected mode: multi...\n",
      "10062 1250\n",
      "Getting wordlist...\n",
      "Getting emotions\n",
      "[]\n",
      "Making arrays\n",
      "checking for save files\n",
      "emotions in make_arrays:  {}\n",
      "train super raw:  0.087616\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████| 10062/10062 [00:04<00:00, 2446.73it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████| 1250/1250 [00:00<00:00, 2230.41it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_x length  10062\n",
      "train_x dimension of element  5000\n",
      "train_x (text) size RAW: 0.087616 megabytes\n",
      "train_y (labels) size RAW: 0.087616 megabytes\n",
      "test_x (text) size RAW: 0.010192 megabytes\n",
      "test_y (labels) size RAW: 0.010192 megabytes\n",
      "saved test_y\n",
      "train_x Size stays the same False\n",
      "train_y Size stays the same False\n",
      "test_x Size stays the same False\n",
      "test_y Size stays the same False\n",
      "train_xNPSize (text) size: 201.24 megabytes\n",
      "train_yNPSize (labels) size: 0.0 megabytes\n",
      "test_xNPSize (text) size: 25.0 megabytes\n",
      "test_yNPSize (labels) size: 0.0 megabytes\n",
      "train_xNP length  10062\n",
      "train_xNP dimension of element  2\n",
      "train_xNP size  50310000\n",
      "Train or test empty. Did you misspell the dataset name?\n",
      "('affectivetext', 'tec', 'headlines', 'tweets')\n",
      "Getting data\n",
      "get_train_test param:\n",
      "json  unified-dataset.jsonl\n",
      "train  affectivetext\n",
      "test  tec\n",
      "there were  21051  entries that were in test and  200388 that were not in test and  1250  that were in train\n",
      "test was appended  21051  times\n",
      "multi\n",
      "oof\n",
      "Detected mode: multi...\n",
      "1250 21051\n",
      "Getting wordlist...\n",
      "Getting emotions\n",
      "['anger', 'joy', 'surprise', 'disgust', 'sadness', 'fear']\n",
      "Making arrays\n",
      "checking for save files\n",
      "emotions in make_arrays:  {'anger': 0, 'joy': 1, 'surprise': 2, 'disgust': 3, 'sadness': 4, 'fear': 5}\n",
      "train super raw:  0.010192\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████| 1250/1250 [00:00<00:00, 3959.05it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████| 21051/21051 [00:05<00:00, 3664.63it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_x length  1250\n",
      "train_x dimension of element  3321\n",
      "train_x (text) size RAW: 0.010192 megabytes\n",
      "train_y (labels) size RAW: 0.010192 megabytes\n",
      "test_x (text) size RAW: 0.178016 megabytes\n",
      "test_y (labels) size RAW: 0.178016 megabytes\n",
      "saved test_y\n",
      "train_x Size stays the same False\n",
      "train_y Size stays the same False\n",
      "test_x Size stays the same False\n",
      "test_y Size stays the same False\n",
      "train_xNPSize (text) size: 16.605 megabytes\n",
      "train_yNPSize (labels) size: 0.03 megabytes\n",
      "test_xNPSize (text) size: 279.641484 megabytes\n",
      "test_yNPSize (labels) size: 0.505224 megabytes\n",
      "train_xNP length  1250\n",
      "train_xNP dimension of element  2\n",
      "train_xNP size  4151250\n",
      "saving NP arrays\n",
      "NP arrays saved\n",
      "Initializing classifier\n",
      "Searching for a  RandomForestClassifier\n",
      "False\n",
      "file not found, creating new classifier\n",
      "this is the classifierName:  RandomForestClassifier\n",
      "Training...\n",
      "train_x (text) size: 16.605 megabytes\n",
      "train_y (labels) size: 0.03 megabytes\n",
      "train_x (text) length: 1250\n",
      "train_y (labels) length: 1250\n",
      "[[0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]]\n",
      "[[1 0 0 0 1 1]\n",
      " [0 1 1 0 0 0]\n",
      " [1 1 1 0 1 1]\n",
      " [1 0 0 1 1 1]\n",
      " [0 1 1 0 0 1]]\n",
      "finished training, classifier size: 4.8e-05 megabytes\n",
      "Predicting...\n",
      "Analysing...\n",
      "analyse_results\n",
      "hello\n",
      "Precision\t0.2756715514746507\n",
      "Recall\t0.4978145191942227\n",
      "F1-score\t0.35484362564979594\n",
      "Accuracy\t0.04750368153531899\n",
      "classiferSaveFile:  affectivetext_tecRandomForestClassifier.pkl\n",
      "Saved Successfully\n",
      "Total: 475 GiB\n",
      "Used: 339 GiB\n",
      "Free: 135 GiB\n",
      "-----------------------------------------------------------------------------------------\n",
      "('affectivetext', 'tales-emotion', 'headlines', 'tales')\n",
      "Getting data\n",
      "get_train_test param:\n",
      "json  unified-dataset.jsonl\n",
      "train  affectivetext\n",
      "test  tales-emotion\n",
      "there were  14771  entries that were in test and  206668 that were not in test and  1250  that were in train\n",
      "test was appended  14771  times\n",
      "multi\n",
      "oof\n",
      "Detected mode: multi...\n",
      "1250 14771\n",
      "Getting wordlist...\n",
      "Getting emotions\n",
      "['anger', 'joy', 'surprise', 'disgust', 'sadness', 'fear']\n",
      "Making arrays\n",
      "checking for save files\n",
      "emotions in make_arrays:  {'anger': 0, 'joy': 1, 'surprise': 2, 'disgust': 3, 'sadness': 4, 'fear': 5}\n",
      "train super raw:  0.010192\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████| 1250/1250 [00:00<00:00, 4508.53it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████| 14771/14771 [00:03<00:00, 3936.53it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_x length  1250\n",
      "train_x dimension of element  3321\n",
      "train_x (text) size RAW: 0.010192 megabytes\n",
      "train_y (labels) size RAW: 0.010192 megabytes\n",
      "test_x (text) size RAW: 0.124912 megabytes\n",
      "test_y (labels) size RAW: 0.124912 megabytes\n",
      "saved test_y\n",
      "train_x Size stays the same False\n",
      "train_y Size stays the same False\n",
      "test_x Size stays the same False\n",
      "test_y Size stays the same False\n",
      "train_xNPSize (text) size: 16.605 megabytes\n",
      "train_yNPSize (labels) size: 0.03 megabytes\n",
      "test_xNPSize (text) size: 196.217964 megabytes\n",
      "test_yNPSize (labels) size: 0.354504 megabytes\n",
      "train_xNP length  1250\n",
      "train_xNP dimension of element  2\n",
      "train_xNP size  4151250\n",
      "saving NP arrays\n",
      "NP arrays saved\n",
      "Initializing classifier\n",
      "Searching for a  RandomForestClassifier\n",
      "False\n",
      "file not found, creating new classifier\n",
      "this is the classifierName:  RandomForestClassifier\n",
      "Training...\n",
      "train_x (text) size: 16.605 megabytes\n",
      "train_y (labels) size: 0.03 megabytes\n",
      "train_x (text) length: 1250\n",
      "train_y (labels) length: 1250\n",
      "[[0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]]\n",
      "[[1 0 0 0 1 1]\n",
      " [0 1 1 0 0 0]\n",
      " [1 1 1 0 1 1]\n",
      " [1 0 0 1 1 1]\n",
      " [0 1 1 0 0 1]]\n",
      "finished training, classifier size: 4.8e-05 megabytes\n",
      "Predicting...\n",
      "Analysing...\n",
      "analyse_results\n",
      "hello\n",
      "Precision\t0.08686350021394951\n",
      "Recall\t0.4153645833333333\n",
      "F1-score\t0.14367982498471835\n",
      "Accuracy\t0.03628731974815517\n",
      "classiferSaveFile:  affectivetext_tales-emotionRandomForestClassifier.pkl\n",
      "Saved Successfully\n",
      "Total: 475 GiB\n",
      "Used: 340 GiB\n",
      "Free: 135 GiB\n",
      "-----------------------------------------------------------------------------------------\n",
      "('affectivetext', 'ssec', 'headlines', 'tweets')\n",
      "Getting data\n",
      "get_train_test param:\n",
      "json  unified-dataset.jsonl\n",
      "train  affectivetext\n",
      "test  ssec\n",
      "there were  4868  entries that were in test and  216571 that were not in test and  1250  that were in train\n",
      "test was appended  4868  times\n",
      "multi\n",
      "Detected mode: multi...\n",
      "1250 4868\n",
      "Getting wordlist...\n",
      "Getting emotions\n",
      "['anger', 'joy', 'surprise', 'disgust', 'sadness', 'fear']\n",
      "Making arrays\n",
      "checking for save files\n",
      "emotions in make_arrays:  {'anger': 0, 'joy': 1, 'surprise': 2, 'disgust': 3, 'sadness': 4, 'fear': 5}\n",
      "train super raw:  0.010192\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████| 1250/1250 [00:00<00:00, 4153.33it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████| 4868/4868 [00:01<00:00, 3994.88it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_x length  1250\n",
      "train_x dimension of element  3321\n",
      "train_x (text) size RAW: 0.010192 megabytes\n",
      "train_y (labels) size RAW: 0.010192 megabytes\n",
      "test_x (text) size RAW: 0.043032 megabytes\n",
      "test_y (labels) size RAW: 0.043032 megabytes\n",
      "saved test_y\n",
      "train_x Size stays the same False\n",
      "train_y Size stays the same False\n",
      "test_x Size stays the same False\n",
      "test_y Size stays the same False\n",
      "train_xNPSize (text) size: 16.605 megabytes\n",
      "train_yNPSize (labels) size: 0.03 megabytes\n",
      "test_xNPSize (text) size: 64.666512 megabytes\n",
      "test_yNPSize (labels) size: 0.116832 megabytes\n",
      "train_xNP length  1250\n",
      "train_xNP dimension of element  2\n",
      "train_xNP size  4151250\n",
      "saving NP arrays\n",
      "NP arrays saved\n",
      "Initializing classifier\n",
      "Searching for a  RandomForestClassifier\n",
      "False\n",
      "file not found, creating new classifier\n",
      "this is the classifierName:  RandomForestClassifier\n",
      "Training...\n",
      "train_x (text) size: 16.605 megabytes\n",
      "train_y (labels) size: 0.03 megabytes\n",
      "train_x (text) length: 1250\n",
      "train_y (labels) length: 1250\n",
      "[[0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]]\n",
      "[[1 0 0 0 1 1]\n",
      " [0 1 1 0 0 0]\n",
      " [1 1 1 0 1 1]\n",
      " [1 0 0 1 1 1]\n",
      " [0 1 1 0 0 1]]\n",
      "finished training, classifier size: 4.8e-05 megabytes\n",
      "Predicting...\n",
      "Analysing...\n",
      "analyse_results\n",
      "hello\n",
      "Precision\t0.36470721486012003\n",
      "Recall\t0.25266792215944756\n",
      "F1-score\t0.29852129977286423\n",
      "Accuracy\t0.03184059161873459\n",
      "classiferSaveFile:  affectivetext_ssecRandomForestClassifier.pkl\n",
      "Saved Successfully\n",
      "Total: 475 GiB\n",
      "Used: 340 GiB\n",
      "Free: 134 GiB\n",
      "-----------------------------------------------------------------------------------------\n",
      "('affectivetext', 'isear', 'headlines', 'descriptions')\n",
      "Getting data\n",
      "get_train_test param:\n",
      "json  unified-dataset.jsonl\n",
      "train  affectivetext\n",
      "test  isear\n",
      "there were  7666  entries that were in test and  213773 that were not in test and  1250  that were in train\n",
      "test was appended  7666  times\n",
      "multi\n",
      "oof\n",
      "Detected mode: multi...\n",
      "1250 7666\n",
      "Getting wordlist...\n",
      "Getting emotions\n",
      "['anger', 'joy', 'disgust', 'sadness', 'fear']\n",
      "Making arrays\n",
      "checking for save files\n",
      "emotions in make_arrays:  {'anger': 0, 'joy': 1, 'disgust': 2, 'sadness': 3, 'fear': 4}\n",
      "train super raw:  0.010192\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████| 1250/1250 [00:00<00:00, 3499.70it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████| 7666/7666 [00:02<00:00, 3808.58it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_x length  1250\n",
      "train_x dimension of element  3321\n",
      "train_x (text) size RAW: 0.010192 megabytes\n",
      "train_y (labels) size RAW: 0.010192 megabytes\n",
      "test_x (text) size RAW: 0.061424 megabytes\n",
      "test_y (labels) size RAW: 0.061424 megabytes\n",
      "saved test_y\n",
      "train_x Size stays the same False\n",
      "train_y Size stays the same False\n",
      "test_x Size stays the same False\n",
      "test_y Size stays the same False\n",
      "train_xNPSize (text) size: 16.605 megabytes\n",
      "train_yNPSize (labels) size: 0.025 megabytes\n",
      "test_xNPSize (text) size: 101.835144 megabytes\n",
      "test_yNPSize (labels) size: 0.15332 megabytes\n",
      "train_xNP length  1250\n",
      "train_xNP dimension of element  2\n",
      "train_xNP size  4151250\n",
      "saving NP arrays\n",
      "NP arrays saved\n",
      "Initializing classifier\n",
      "Searching for a  RandomForestClassifier\n",
      "False\n",
      "file not found, creating new classifier\n",
      "this is the classifierName:  RandomForestClassifier\n",
      "Training...\n",
      "train_x (text) size: 16.605 megabytes\n",
      "train_y (labels) size: 0.025 megabytes\n",
      "train_x (text) length: 1250\n",
      "train_y (labels) length: 1250\n",
      "[[0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]]\n",
      "[[1 0 0 1 1]\n",
      " [0 1 0 0 0]\n",
      " [1 1 0 1 1]\n",
      " [1 0 1 1 1]\n",
      " [0 1 0 0 1]]\n",
      "finished training, classifier size: 4.8e-05 megabytes\n",
      "Predicting...\n",
      "Analysing...\n",
      "analyse_results\n",
      "hello\n",
      "Precision\t0.16235906331309627\n",
      "Recall\t0.17089647617308745\n",
      "F1-score\t0.16651841309375556\n",
      "Accuracy\t0.20414818679885208\n",
      "classiferSaveFile:  affectivetext_isearRandomForestClassifier.pkl\n",
      "Saved Successfully\n",
      "Total: 475 GiB\n",
      "Used: 340 GiB\n",
      "Free: 134 GiB\n",
      "-----------------------------------------------------------------------------------------\n",
      "('affectivetext', 'grounded_emotions', 'headlines', 'tweets')\n",
      "Getting data\n",
      "get_train_test param:\n",
      "json  unified-dataset.jsonl\n",
      "train  affectivetext\n",
      "test  grounded_emotions\n",
      "there were  2585  entries that were in test and  218854 that were not in test and  1250  that were in train\n",
      "test was appended  2585  times\n",
      "multi\n",
      "oof\n",
      "Detected mode: multi...\n",
      "1250 2585\n",
      "Getting wordlist...\n",
      "Getting emotions\n",
      "['joy', 'sadness']\n",
      "Making arrays\n",
      "checking for save files\n",
      "emotions in make_arrays:  {'joy': 0, 'sadness': 1}\n",
      "train super raw:  0.010192\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████| 1250/1250 [00:00<00:00, 4280.01it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████| 2585/2585 [00:00<00:00, 4309.10it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_x length  1250\n",
      "train_x dimension of element  3321\n",
      "train_x (text) size RAW: 0.010192 megabytes\n",
      "train_y (labels) size RAW: 0.010192 megabytes\n",
      "test_x (text) size RAW: 0.02104 megabytes\n",
      "test_y (labels) size RAW: 0.02104 megabytes\n",
      "saved test_y\n",
      "train_x Size stays the same False\n",
      "train_y Size stays the same False\n",
      "test_x Size stays the same False\n",
      "test_y Size stays the same False\n",
      "train_xNPSize (text) size: 16.605 megabytes\n",
      "train_yNPSize (labels) size: 0.01 megabytes\n",
      "test_xNPSize (text) size: 34.33914 megabytes\n",
      "test_yNPSize (labels) size: 0.02068 megabytes\n",
      "train_xNP length  1250\n",
      "train_xNP dimension of element  2\n",
      "train_xNP size  4151250\n",
      "saving NP arrays\n",
      "NP arrays saved\n",
      "Initializing classifier\n",
      "Searching for a  RandomForestClassifier\n",
      "False\n",
      "file not found, creating new classifier\n",
      "this is the classifierName:  RandomForestClassifier\n",
      "Training...\n",
      "train_x (text) size: 16.605 megabytes\n",
      "train_y (labels) size: 0.01 megabytes\n",
      "train_x (text) length: 1250\n",
      "train_y (labels) length: 1250\n",
      "[[0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]]\n",
      "[[0 1]\n",
      " [1 0]\n",
      " [1 1]\n",
      " [0 1]\n",
      " [1 0]]\n",
      "finished training, classifier size: 4.8e-05 megabytes\n",
      "Predicting...\n",
      "Analysing...\n",
      "analyse_results\n",
      "hello\n",
      "Precision\t0.5201072386058981\n",
      "Recall\t0.37524177949709864\n",
      "F1-score\t0.43595505617977526\n",
      "Accuracy\t0.3624758220502901\n",
      "classiferSaveFile:  affectivetext_grounded_emotionsRandomForestClassifier.pkl\n",
      "Saved Successfully\n",
      "Total: 475 GiB\n",
      "Used: 340 GiB\n",
      "Free: 134 GiB\n",
      "-----------------------------------------------------------------------------------------\n",
      "('affectivetext', 'emotion-cause', 'headlines', 'paragraphs')\n",
      "Getting data\n",
      "get_train_test param:\n",
      "json  unified-dataset.jsonl\n",
      "train  affectivetext\n",
      "test  emotion-cause\n",
      "there were  2414  entries that were in test and  219025 that were not in test and  1250  that were in train\n",
      "test was appended  2414  times\n",
      "multi\n",
      "oof\n",
      "Detected mode: multi...\n",
      "1250 2414\n",
      "Getting wordlist...\n",
      "Getting emotions\n",
      "['anger', 'joy', 'surprise', 'disgust', 'sadness', 'fear']\n",
      "Making arrays\n",
      "checking for save files\n",
      "emotions in make_arrays:  {'anger': 0, 'joy': 1, 'surprise': 2, 'disgust': 3, 'sadness': 4, 'fear': 5}\n",
      "train super raw:  0.010192\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████| 1250/1250 [00:00<00:00, 4099.63it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████| 2414/2414 [00:00<00:00, 4269.75it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_x length  1250\n",
      "train_x dimension of element  3321\n",
      "train_x (text) size RAW: 0.010192 megabytes\n",
      "train_y (labels) size RAW: 0.010192 megabytes\n",
      "test_x (text) size RAW: 0.02104 megabytes\n",
      "test_y (labels) size RAW: 0.02104 megabytes\n",
      "saved test_y\n",
      "train_x Size stays the same False\n",
      "train_y Size stays the same False\n",
      "test_x Size stays the same False\n",
      "test_y Size stays the same False\n",
      "train_xNPSize (text) size: 16.605 megabytes\n",
      "train_yNPSize (labels) size: 0.03 megabytes\n",
      "test_xNPSize (text) size: 32.067576 megabytes\n",
      "test_yNPSize (labels) size: 0.057936 megabytes\n",
      "train_xNP length  1250\n",
      "train_xNP dimension of element  2\n",
      "train_xNP size  4151250\n",
      "saving NP arrays\n",
      "NP arrays saved\n",
      "Initializing classifier\n",
      "Searching for a  RandomForestClassifier\n",
      "False\n",
      "file not found, creating new classifier\n",
      "this is the classifierName:  RandomForestClassifier\n",
      "Training...\n",
      "train_x (text) size: 16.605 megabytes\n",
      "train_y (labels) size: 0.03 megabytes\n",
      "train_x (text) length: 1250\n",
      "train_y (labels) length: 1250\n",
      "[[0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]]\n",
      "[[1 0 0 0 1 1]\n",
      " [0 1 1 0 0 0]\n",
      " [1 1 1 0 1 1]\n",
      " [1 0 0 1 1 1]\n",
      " [0 1 1 0 0 1]]\n",
      "finished training, classifier size: 4.8e-05 megabytes\n",
      "Predicting...\n",
      "Analysing...\n",
      "analyse_results\n",
      "hello\n",
      "Precision\t0.15339023233760077\n",
      "Recall\t0.28527336860670194\n",
      "F1-score\t0.1995066296638915\n",
      "Accuracy\t0.03603976801988401\n",
      "classiferSaveFile:  affectivetext_emotion-causeRandomForestClassifier.pkl\n",
      "Saved Successfully\n",
      "Total: 475 GiB\n",
      "Used: 340 GiB\n",
      "Free: 134 GiB\n",
      "-----------------------------------------------------------------------------------------\n",
      "('affectivetext', 'emoint', 'headlines', 'tweets')\n",
      "Getting data\n",
      "get_train_test param:\n",
      "json  unified-dataset.jsonl\n",
      "train  affectivetext\n",
      "test  emoint\n",
      "there were  7102  entries that were in test and  214337 that were not in test and  1250  that were in train\n",
      "test was appended  7102  times\n",
      "multi\n",
      "oof\n",
      "Detected mode: multi...\n",
      "1250 7102\n",
      "Getting wordlist...\n",
      "Getting emotions\n",
      "['joy', 'sadness', 'anger', 'fear']\n",
      "Making arrays\n",
      "checking for save files\n",
      "emotions in make_arrays:  {'joy': 0, 'sadness': 1, 'anger': 2, 'fear': 3}\n",
      "train super raw:  0.010192\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████| 1250/1250 [00:00<00:00, 4508.07it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████| 7102/7102 [00:01<00:00, 4338.75it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_x length  1250\n",
      "train_x dimension of element  3321\n",
      "train_x (text) size RAW: 0.010192 megabytes\n",
      "train_y (labels) size RAW: 0.010192 megabytes\n",
      "test_x (text) size RAW: 0.061424 megabytes\n",
      "test_y (labels) size RAW: 0.061424 megabytes\n",
      "saved test_y\n",
      "train_x Size stays the same False\n",
      "train_y Size stays the same False\n",
      "test_x Size stays the same False\n",
      "test_y Size stays the same False\n",
      "train_xNPSize (text) size: 16.605 megabytes\n",
      "train_yNPSize (labels) size: 0.02 megabytes\n",
      "test_xNPSize (text) size: 94.342968 megabytes\n",
      "test_yNPSize (labels) size: 0.113632 megabytes\n",
      "train_xNP length  1250\n",
      "train_xNP dimension of element  2\n",
      "train_xNP size  4151250\n",
      "saving NP arrays\n",
      "NP arrays saved\n",
      "Initializing classifier\n",
      "Searching for a  RandomForestClassifier\n",
      "False\n",
      "file not found, creating new classifier\n",
      "this is the classifierName:  RandomForestClassifier\n",
      "Training...\n",
      "train_x (text) size: 16.605 megabytes\n",
      "train_y (labels) size: 0.02 megabytes\n",
      "train_x (text) length: 1250\n",
      "train_y (labels) length: 1250\n",
      "[[0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]]\n",
      "[[0 1 1 1]\n",
      " [1 0 0 0]\n",
      " [1 1 1 1]\n",
      " [0 1 1 1]\n",
      " [1 0 0 1]]\n",
      "finished training, classifier size: 4.8e-05 megabytes\n",
      "Predicting...\n",
      "Analysing...\n",
      "analyse_results\n",
      "hello\n",
      "Precision\t0.2605894669028829\n",
      "Recall\t0.2278231484088989\n",
      "F1-score\t0.24310720456765084\n",
      "Accuracy\t0.1829062235989862\n",
      "classiferSaveFile:  affectivetext_emointRandomForestClassifier.pkl\n",
      "Saved Successfully\n",
      "Total: 475 GiB\n",
      "Used: 340 GiB\n",
      "Free: 134 GiB\n",
      "-----------------------------------------------------------------------------------------\n",
      "('affectivetext', 'emobank', 'headlines', 'headlines')\n",
      "Getting data\n",
      "get_train_test param:\n",
      "json  unified-dataset.jsonl\n",
      "train  affectivetext\n",
      "test  emobank\n",
      "there were  10062  entries that were in test and  211377 that were not in test and  1250  that were in train\n",
      "test was appended  10062  times\n",
      "multi\n",
      "Detected mode: multi...\n",
      "1250 10062\n",
      "Getting wordlist...\n",
      "Getting emotions\n",
      "[]\n",
      "Making arrays\n",
      "checking for save files\n",
      "emotions in make_arrays:  {}\n",
      "train super raw:  0.010192\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████| 1250/1250 [00:00<00:00, 4265.63it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████| 10062/10062 [00:02<00:00, 3920.77it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_x length  1250\n",
      "train_x dimension of element  3321\n",
      "train_x (text) size RAW: 0.010192 megabytes\n",
      "train_y (labels) size RAW: 0.010192 megabytes\n",
      "test_x (text) size RAW: 0.087616 megabytes\n",
      "test_y (labels) size RAW: 0.087616 megabytes\n",
      "saved test_y\n",
      "train_x Size stays the same False\n",
      "train_y Size stays the same False\n",
      "test_x Size stays the same False\n",
      "test_y Size stays the same False\n",
      "train_xNPSize (text) size: 16.605 megabytes\n",
      "train_yNPSize (labels) size: 0.0 megabytes\n",
      "test_xNPSize (text) size: 133.663608 megabytes\n",
      "test_yNPSize (labels) size: 0.0 megabytes\n",
      "train_xNP length  1250\n",
      "train_xNP dimension of element  2\n",
      "train_xNP size  4151250\n",
      "Train or test empty. Did you misspell the dataset name?\n",
      "('affectivetext', 'dailydialog', 'headlines', 'conversations')\n",
      "Getting data\n",
      "get_train_test param:\n",
      "json  unified-dataset.jsonl\n",
      "train  affectivetext\n",
      "test  dailydialog\n",
      "there were  102979  entries that were in test and  118460 that were not in test and  1250  that were in train\n",
      "test was appended  102979  times\n",
      "multi\n",
      "oof\n",
      "Detected mode: multi...\n",
      "1250 102979\n",
      "Getting wordlist...\n",
      "Getting emotions\n",
      "['anger', 'joy', 'surprise', 'disgust', 'sadness', 'fear']\n",
      "Making arrays\n",
      "checking for save files\n",
      "emotions in make_arrays:  {'anger': 0, 'joy': 1, 'surprise': 2, 'disgust': 3, 'sadness': 4, 'fear': 5}\n",
      "train super raw:  0.010192\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████| 1250/1250 [00:00<00:00, 4383.31it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████| 102979/102979 [00:26<00:00, 3871.02it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_x length  1250\n",
      "train_x dimension of element  3321\n",
      "train_x (text) size RAW: 0.010192 megabytes\n",
      "train_y (labels) size RAW: 0.010192 megabytes\n",
      "test_x (text) size RAW: 0.824456 megabytes\n",
      "test_y (labels) size RAW: 0.824456 megabytes\n",
      "saved test_y\n",
      "train_x Size stays the same False\n",
      "train_y Size stays the same False\n",
      "test_x Size stays the same False\n",
      "test_y Size stays the same False\n",
      "train_xNPSize (text) size: 16.605 megabytes\n",
      "train_yNPSize (labels) size: 0.03 megabytes\n",
      "test_xNPSize (text) size: 1367.973036 megabytes\n",
      "test_yNPSize (labels) size: 2.471496 megabytes\n",
      "train_xNP length  1250\n",
      "train_xNP dimension of element  2\n",
      "train_xNP size  4151250\n",
      "saving NP arrays\n",
      "NP arrays saved\n",
      "Initializing classifier\n",
      "Searching for a  RandomForestClassifier\n",
      "False\n",
      "file not found, creating new classifier\n",
      "this is the classifierName:  RandomForestClassifier\n",
      "Training...\n",
      "train_x (text) size: 16.605 megabytes\n",
      "train_y (labels) size: 0.03 megabytes\n",
      "train_x (text) length: 1250\n",
      "train_y (labels) length: 1250\n",
      "[[0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]]\n",
      "[[1 0 0 0 1 1]\n",
      " [0 1 1 0 0 0]\n",
      " [1 1 1 0 1 1]\n",
      " [1 0 0 1 1 1]\n",
      " [0 1 1 0 0 1]]\n",
      "finished training, classifier size: 4.8e-05 megabytes\n",
      "Predicting...\n",
      "Analysing...\n",
      "analyse_results\n",
      "hello\n",
      "Precision\t0.05832143021702069\n",
      "Recall\t0.5817199977020738\n",
      "F1-score\t0.10601420711821641\n",
      "Accuracy\t0.01877081735111042\n",
      "classiferSaveFile:  affectivetext_dailydialogRandomForestClassifier.pkl\n",
      "Saved Successfully\n",
      "Total: 475 GiB\n",
      "Used: 341 GiB\n",
      "Free: 133 GiB\n",
      "-----------------------------------------------------------------------------------------\n",
      "('affectivetext', 'crowdflower', 'headlines', 'tweets')\n",
      "Getting data\n",
      "get_train_test param:\n",
      "json  unified-dataset.jsonl\n",
      "train  affectivetext\n",
      "test  crowdflower\n",
      "there were  39740  entries that were in test and  181699 that were not in test and  1250  that were in train\n",
      "test was appended  39740  times\n",
      "multi\n",
      "oof\n",
      "Detected mode: multi...\n",
      "1250 39740\n",
      "Getting wordlist...\n",
      "Getting emotions\n",
      "['anger', 'joy', 'surprise', 'disgust', 'sadness', 'fear']\n",
      "Making arrays\n",
      "checking for save files\n",
      "emotions in make_arrays:  {'anger': 0, 'joy': 1, 'surprise': 2, 'disgust': 3, 'sadness': 4, 'fear': 5}\n",
      "train super raw:  0.010192\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████| 1250/1250 [00:00<00:00, 4208.94it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████| 39740/39740 [00:10<00:00, 3866.83it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_x length  1250\n",
      "train_x dimension of element  3321\n",
      "train_x (text) size RAW: 0.010192 megabytes\n",
      "train_y (labels) size RAW: 0.010192 megabytes\n",
      "test_x (text) size RAW: 0.321096 megabytes\n",
      "test_y (labels) size RAW: 0.321096 megabytes\n",
      "saved test_y\n",
      "train_x Size stays the same False\n",
      "train_y Size stays the same False\n",
      "test_x Size stays the same False\n",
      "test_y Size stays the same False\n",
      "train_xNPSize (text) size: 16.605 megabytes\n",
      "train_yNPSize (labels) size: 0.03 megabytes\n",
      "test_xNPSize (text) size: 527.90616 megabytes\n",
      "test_yNPSize (labels) size: 0.95376 megabytes\n",
      "train_xNP length  1250\n",
      "train_xNP dimension of element  2\n",
      "train_xNP size  4151250\n",
      "saving NP arrays\n",
      "NP arrays saved\n",
      "Initializing classifier\n",
      "Searching for a  RandomForestClassifier\n",
      "False\n",
      "file not found, creating new classifier\n",
      "this is the classifierName:  RandomForestClassifier\n",
      "Training...\n",
      "train_x (text) size: 16.605 megabytes\n",
      "train_y (labels) size: 0.03 megabytes\n",
      "train_x (text) length: 1250\n",
      "train_y (labels) length: 1250\n",
      "[[0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]]\n",
      "[[1 0 0 0 1 1]\n",
      " [0 1 1 0 0 0]\n",
      " [1 1 1 0 1 1]\n",
      " [1 0 0 1 1 1]\n",
      " [0 1 1 0 0 1]]\n",
      "finished training, classifier size: 4.8e-05 megabytes\n",
      "Predicting...\n",
      "Analysing...\n",
      "analyse_results\n",
      "hello\n",
      "Precision\t0.1351516119199338\n",
      "Recall\t0.3506967984934087\n",
      "F1-score\t0.19511121821401253\n",
      "Accuracy\t0.026950176144942124\n",
      "classiferSaveFile:  affectivetext_crowdflowerRandomForestClassifier.pkl\n",
      "Saved Successfully\n",
      "Total: 475 GiB\n",
      "Used: 342 GiB\n",
      "Free: 132 GiB\n",
      "-----------------------------------------------------------------------------------------\n",
      "('isear', 'tec', 'descriptions', 'tweets')\n",
      "Getting data\n",
      "get_train_test param:\n",
      "json  unified-dataset.jsonl\n",
      "train  isear\n",
      "test  tec\n",
      "there were  21051  entries that were in test and  200388 that were not in test and  7666  that were in train\n",
      "test was appended  21051  times\n",
      "single\n",
      "oof\n",
      "Detected mode: single...\n",
      "7666 21051\n",
      "Getting wordlist...\n",
      "Getting emotions\n",
      "['anger', 'joy', 'noemo', 'disgust', 'sadness', 'fear']\n",
      "Making arrays\n",
      "checking for save files\n",
      "emotions in make_arrays:  {'anger': 0, 'joy': 1, 'noemo': 2, 'disgust': 3, 'sadness': 4, 'fear': 5}\n",
      "train super raw:  0.061424\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████| 7666/7666 [00:03<00:00, 2516.88it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████| 21051/21051 [00:08<00:00, 2508.29it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_x length  7666\n",
      "train_x dimension of element  5000\n",
      "train_x (text) size RAW: 0.061424 megabytes\n",
      "train_y (labels) size RAW: 0.061424 megabytes\n",
      "test_x (text) size RAW: 0.178016 megabytes\n",
      "test_y (labels) size RAW: 0.178016 megabytes\n",
      "saved test_y\n",
      "train_x Size stays the same False\n",
      "train_y Size stays the same False\n",
      "test_x Size stays the same False\n",
      "test_y Size stays the same False\n",
      "train_xNPSize (text) size: 153.32 megabytes\n",
      "train_yNPSize (labels) size: 0.030664 megabytes\n",
      "test_xNPSize (text) size: 421.02 megabytes\n",
      "test_yNPSize (labels) size: 0.084204 megabytes\n",
      "train_xNP length  7666\n",
      "train_xNP dimension of element  2\n",
      "train_xNP size  38330000\n",
      "saving NP arrays\n",
      "NP arrays saved\n",
      "Initializing classifier\n",
      "Searching for a  RandomForestClassifier\n",
      "False\n",
      "file not found, creating new classifier\n",
      "this is the classifierName:  RandomForestClassifier\n",
      "Training...\n",
      "train_x (text) size: 153.32 megabytes\n",
      "train_y (labels) size: 0.030664 megabytes\n",
      "train_x (text) length: 7666\n",
      "train_y (labels) length: 7666\n",
      "[[0 1 1 ... 0 0 0]\n",
      " [1 1 0 ... 0 0 0]\n",
      " [1 1 0 ... 0 0 0]\n",
      " [1 0 1 ... 0 0 0]\n",
      " [1 1 1 ... 0 0 0]]\n",
      "[1 5 0 4 3]\n",
      "finished training, classifier size: 4.8e-05 megabytes\n",
      "Predicting...\n",
      "Analysing...\n",
      "analyse_results\n",
      "hello\n",
      "Precision\t0.23362310579069878\n",
      "Recall\t0.23362310579069878\n",
      "F1-score\t0.23362310579069878\n",
      "Accuracy\t0.23362310579069878\n",
      "classiferSaveFile:  isear_tecRandomForestClassifier.pkl\n",
      "Saved Successfully\n",
      "Total: 475 GiB\n",
      "Used: 342 GiB\n",
      "Free: 132 GiB\n",
      "-----------------------------------------------------------------------------------------\n",
      "('isear', 'tales-emotion', 'descriptions', 'tales')\n",
      "Getting data\n",
      "get_train_test param:\n",
      "json  unified-dataset.jsonl\n",
      "train  isear\n",
      "test  tales-emotion\n",
      "there were  14771  entries that were in test and  206668 that were not in test and  7666  that were in train\n",
      "test was appended  14771  times\n",
      "single\n",
      "oof\n",
      "Detected mode: single...\n",
      "7666 14771\n",
      "Getting wordlist...\n",
      "Getting emotions\n",
      "['anger', 'joy', 'noemo', 'disgust', 'sadness', 'fear']\n",
      "Making arrays\n",
      "checking for save files\n",
      "emotions in make_arrays:  {'anger': 0, 'joy': 1, 'noemo': 2, 'disgust': 3, 'sadness': 4, 'fear': 5}\n",
      "train super raw:  0.061424\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████| 7666/7666 [00:02<00:00, 2595.06it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████| 14771/14771 [00:05<00:00, 2524.13it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_x length  7666\n",
      "train_x dimension of element  5000\n",
      "train_x (text) size RAW: 0.061424 megabytes\n",
      "train_y (labels) size RAW: 0.061424 megabytes\n",
      "test_x (text) size RAW: 0.124912 megabytes\n",
      "test_y (labels) size RAW: 0.124912 megabytes\n",
      "saved test_y\n",
      "train_x Size stays the same False\n",
      "train_y Size stays the same False\n",
      "test_x Size stays the same False\n",
      "test_y Size stays the same False\n",
      "train_xNPSize (text) size: 153.32 megabytes\n",
      "train_yNPSize (labels) size: 0.030664 megabytes\n",
      "test_xNPSize (text) size: 295.42 megabytes\n",
      "test_yNPSize (labels) size: 0.059084 megabytes\n",
      "train_xNP length  7666\n",
      "train_xNP dimension of element  2\n",
      "train_xNP size  38330000\n",
      "saving NP arrays\n",
      "NP arrays saved\n",
      "Initializing classifier\n",
      "Searching for a  RandomForestClassifier\n",
      "False\n",
      "file not found, creating new classifier\n",
      "this is the classifierName:  RandomForestClassifier\n",
      "Training...\n",
      "train_x (text) size: 153.32 megabytes\n",
      "train_y (labels) size: 0.030664 megabytes\n",
      "train_x (text) length: 7666\n",
      "train_y (labels) length: 7666\n",
      "[[0 1 1 ... 0 0 0]\n",
      " [1 1 0 ... 0 0 0]\n",
      " [1 1 0 ... 0 0 0]\n",
      " [1 0 1 ... 0 0 0]\n",
      " [1 1 1 ... 0 0 0]]\n",
      "[1 5 0 4 3]\n",
      "finished training, classifier size: 4.8e-05 megabytes\n",
      "Predicting...\n",
      "Analysing...\n",
      "analyse_results\n",
      "hello\n",
      "Precision\t0.350687157267619\n",
      "Recall\t0.350687157267619\n",
      "F1-score\t0.350687157267619\n",
      "Accuracy\t0.350687157267619\n",
      "classiferSaveFile:  isear_tales-emotionRandomForestClassifier.pkl\n",
      "Saved Successfully\n",
      "Total: 475 GiB\n",
      "Used: 343 GiB\n",
      "Free: 131 GiB\n",
      "-----------------------------------------------------------------------------------------\n",
      "('isear', 'ssec', 'descriptions', 'tweets')\n",
      "Getting data\n",
      "get_train_test param:\n",
      "json  unified-dataset.jsonl\n",
      "train  isear\n",
      "test  ssec\n",
      "there were  4868  entries that were in test and  216571 that were not in test and  7666  that were in train\n",
      "test was appended  4868  times\n",
      "single\n",
      "Detected mode: multi...\n",
      "7666 4868\n",
      "Getting wordlist...\n",
      "Getting emotions\n",
      "['anger', 'joy', 'disgust', 'sadness', 'fear']\n",
      "Making arrays\n",
      "checking for save files\n",
      "emotions in make_arrays:  {'anger': 0, 'joy': 1, 'disgust': 2, 'sadness': 3, 'fear': 4}\n",
      "train super raw:  0.061424\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████| 7666/7666 [00:02<00:00, 2679.17it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████| 4868/4868 [00:01<00:00, 2509.56it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_x length  7666\n",
      "train_x dimension of element  5000\n",
      "train_x (text) size RAW: 0.061424 megabytes\n",
      "train_y (labels) size RAW: 0.061424 megabytes\n",
      "test_x (text) size RAW: 0.043032 megabytes\n",
      "test_y (labels) size RAW: 0.043032 megabytes\n",
      "saved test_y\n",
      "train_x Size stays the same False\n",
      "train_y Size stays the same False\n",
      "test_x Size stays the same False\n",
      "test_y Size stays the same False\n",
      "train_xNPSize (text) size: 153.32 megabytes\n",
      "train_yNPSize (labels) size: 0.15332 megabytes\n",
      "test_xNPSize (text) size: 97.36 megabytes\n",
      "test_yNPSize (labels) size: 0.09736 megabytes\n",
      "train_xNP length  7666\n",
      "train_xNP dimension of element  2\n",
      "train_xNP size  38330000\n",
      "saving NP arrays\n",
      "NP arrays saved\n",
      "Initializing classifier\n",
      "Searching for a  RandomForestClassifier\n",
      "False\n",
      "file not found, creating new classifier\n",
      "this is the classifierName:  RandomForestClassifier\n",
      "Training...\n",
      "train_x (text) size: 153.32 megabytes\n",
      "train_y (labels) size: 0.15332 megabytes\n",
      "train_x (text) length: 7666\n",
      "train_y (labels) length: 7666\n",
      "[[0 1 1 ... 0 0 0]\n",
      " [1 1 0 ... 0 0 0]\n",
      " [1 1 0 ... 0 0 0]\n",
      " [1 0 1 ... 0 0 0]\n",
      " [1 1 1 ... 0 0 0]]\n",
      "[[0 1 0 0 0]\n",
      " [0 0 0 0 1]\n",
      " [1 0 0 0 0]\n",
      " [0 0 0 1 0]\n",
      " [0 0 1 0 0]]\n",
      "finished training, classifier size: 4.8e-05 megabytes\n",
      "Predicting...\n",
      "Analysing...\n",
      "analyse_results\n",
      "hello\n",
      "Precision\t0.6038647342995169\n",
      "Recall\t0.010742523203850121\n",
      "F1-score\t0.021109516169889386\n",
      "Accuracy\t0.05341002465078061\n",
      "classiferSaveFile:  isear_ssecRandomForestClassifier.pkl\n",
      "Saved Successfully\n",
      "Total: 475 GiB\n",
      "Used: 343 GiB\n",
      "Free: 131 GiB\n",
      "-----------------------------------------------------------------------------------------\n",
      "('isear', 'grounded_emotions', 'descriptions', 'tweets')\n",
      "Getting data\n",
      "get_train_test param:\n",
      "json  unified-dataset.jsonl\n",
      "train  isear\n",
      "test  grounded_emotions\n",
      "there were  2585  entries that were in test and  218854 that were not in test and  7666  that were in train\n",
      "test was appended  2585  times\n",
      "single\n",
      "oof\n",
      "Detected mode: single...\n",
      "7666 2585\n",
      "Getting wordlist...\n",
      "Getting emotions\n",
      "['joy', 'noemo', 'sadness']\n",
      "Making arrays\n",
      "checking for save files\n",
      "emotions in make_arrays:  {'joy': 0, 'noemo': 1, 'sadness': 2}\n",
      "train super raw:  0.061424\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████| 7666/7666 [00:03<00:00, 2525.06it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████| 2585/2585 [00:01<00:00, 2536.24it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_x length  7666\n",
      "train_x dimension of element  5000\n",
      "train_x (text) size RAW: 0.061424 megabytes\n",
      "train_y (labels) size RAW: 0.061424 megabytes\n",
      "test_x (text) size RAW: 0.02104 megabytes\n",
      "test_y (labels) size RAW: 0.02104 megabytes\n",
      "saved test_y\n",
      "train_x Size stays the same False\n",
      "train_y Size stays the same False\n",
      "test_x Size stays the same False\n",
      "test_y Size stays the same False\n",
      "train_xNPSize (text) size: 153.32 megabytes\n",
      "train_yNPSize (labels) size: 0.030664 megabytes\n",
      "test_xNPSize (text) size: 51.7 megabytes\n",
      "test_yNPSize (labels) size: 0.01034 megabytes\n",
      "train_xNP length  7666\n",
      "train_xNP dimension of element  2\n",
      "train_xNP size  38330000\n",
      "saving NP arrays\n",
      "NP arrays saved\n",
      "Initializing classifier\n",
      "Searching for a  RandomForestClassifier\n",
      "False\n",
      "file not found, creating new classifier\n",
      "this is the classifierName:  RandomForestClassifier\n",
      "Training...\n",
      "train_x (text) size: 153.32 megabytes\n",
      "train_y (labels) size: 0.030664 megabytes\n",
      "train_x (text) length: 7666\n",
      "train_y (labels) length: 7666\n",
      "[[0 1 1 ... 0 0 0]\n",
      " [1 1 0 ... 0 0 0]\n",
      " [1 1 0 ... 0 0 0]\n",
      " [1 0 1 ... 0 0 0]\n",
      " [1 1 1 ... 0 0 0]]\n",
      "[0 1 1 2 1]\n",
      "finished training, classifier size: 4.8e-05 megabytes\n",
      "Predicting...\n",
      "Analysing...\n",
      "analyse_results\n",
      "hello\n",
      "Precision\t0.08317214700193423\n",
      "Recall\t0.08317214700193423\n",
      "F1-score\t0.08317214700193423\n",
      "Accuracy\t0.08317214700193423\n",
      "classiferSaveFile:  isear_grounded_emotionsRandomForestClassifier.pkl\n",
      "Saved Successfully\n",
      "Total: 475 GiB\n",
      "Used: 343 GiB\n",
      "Free: 131 GiB\n",
      "-----------------------------------------------------------------------------------------\n",
      "('isear', 'emotion-cause', 'descriptions', 'paragraphs')\n",
      "Getting data\n",
      "get_train_test param:\n",
      "json  unified-dataset.jsonl\n",
      "train  isear\n",
      "test  emotion-cause\n",
      "there were  2414  entries that were in test and  219025 that were not in test and  7666  that were in train\n",
      "test was appended  2414  times\n",
      "single\n",
      "oof\n",
      "Detected mode: single...\n",
      "7666 2414\n",
      "Getting wordlist...\n",
      "Getting emotions\n",
      "['anger', 'joy', 'noemo', 'disgust', 'sadness', 'fear']\n",
      "Making arrays\n",
      "checking for save files\n",
      "emotions in make_arrays:  {'anger': 0, 'joy': 1, 'noemo': 2, 'disgust': 3, 'sadness': 4, 'fear': 5}\n",
      "train super raw:  0.061424\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████| 7666/7666 [00:02<00:00, 2575.25it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████| 2414/2414 [00:01<00:00, 2361.55it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_x length  7666\n",
      "train_x dimension of element  5000\n",
      "train_x (text) size RAW: 0.061424 megabytes\n",
      "train_y (labels) size RAW: 0.061424 megabytes\n",
      "test_x (text) size RAW: 0.02104 megabytes\n",
      "test_y (labels) size RAW: 0.02104 megabytes\n",
      "saved test_y\n",
      "train_x Size stays the same False\n",
      "train_y Size stays the same False\n",
      "test_x Size stays the same False\n",
      "test_y Size stays the same False\n",
      "train_xNPSize (text) size: 153.32 megabytes\n",
      "train_yNPSize (labels) size: 0.030664 megabytes\n",
      "test_xNPSize (text) size: 48.28 megabytes\n",
      "test_yNPSize (labels) size: 0.009656 megabytes\n",
      "train_xNP length  7666\n",
      "train_xNP dimension of element  2\n",
      "train_xNP size  38330000\n",
      "saving NP arrays\n",
      "NP arrays saved\n",
      "Initializing classifier\n",
      "Searching for a  RandomForestClassifier\n",
      "False\n",
      "file not found, creating new classifier\n",
      "this is the classifierName:  RandomForestClassifier\n",
      "Training...\n",
      "train_x (text) size: 153.32 megabytes\n",
      "train_y (labels) size: 0.030664 megabytes\n",
      "train_x (text) length: 7666\n",
      "train_y (labels) length: 7666\n",
      "[[0 1 1 ... 0 0 0]\n",
      " [1 1 0 ... 0 0 0]\n",
      " [1 1 0 ... 0 0 0]\n",
      " [1 0 1 ... 0 0 0]\n",
      " [1 1 1 ... 0 0 0]]\n",
      "[1 5 0 4 3]\n",
      "finished training, classifier size: 4.8e-05 megabytes\n",
      "Predicting...\n",
      "Analysing...\n",
      "analyse_results\n",
      "hello\n",
      "Precision\t0.24979287489643745\n",
      "Recall\t0.24979287489643745\n",
      "F1-score\t0.24979287489643745\n",
      "Accuracy\t0.24979287489643745\n",
      "classiferSaveFile:  isear_emotion-causeRandomForestClassifier.pkl\n",
      "Saved Successfully\n",
      "Total: 475 GiB\n",
      "Used: 344 GiB\n",
      "Free: 130 GiB\n",
      "-----------------------------------------------------------------------------------------\n",
      "('isear', 'emoint', 'descriptions', 'tweets')\n",
      "Getting data\n",
      "get_train_test param:\n",
      "json  unified-dataset.jsonl\n",
      "train  isear\n",
      "test  emoint\n",
      "there were  7102  entries that were in test and  214337 that were not in test and  7666  that were in train\n",
      "test was appended  7102  times\n",
      "single\n",
      "oof\n",
      "Detected mode: single...\n",
      "7666 7102\n",
      "Getting wordlist...\n",
      "Getting emotions\n",
      "['anger', 'joy', 'noemo', 'sadness', 'fear']\n",
      "Making arrays\n",
      "checking for save files\n",
      "emotions in make_arrays:  {'anger': 0, 'joy': 1, 'noemo': 2, 'sadness': 3, 'fear': 4}\n",
      "train super raw:  0.061424\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████| 7666/7666 [00:03<00:00, 2534.92it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████| 7102/7102 [00:02<00:00, 2603.25it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_x length  7666\n",
      "train_x dimension of element  5000\n",
      "train_x (text) size RAW: 0.061424 megabytes\n",
      "train_y (labels) size RAW: 0.061424 megabytes\n",
      "test_x (text) size RAW: 0.061424 megabytes\n",
      "test_y (labels) size RAW: 0.061424 megabytes\n",
      "saved test_y\n",
      "train_x Size stays the same False\n",
      "train_y Size stays the same False\n",
      "test_x Size stays the same False\n",
      "test_y Size stays the same False\n",
      "train_xNPSize (text) size: 153.32 megabytes\n",
      "train_yNPSize (labels) size: 0.030664 megabytes\n",
      "test_xNPSize (text) size: 142.04 megabytes\n",
      "test_yNPSize (labels) size: 0.028408 megabytes\n",
      "train_xNP length  7666\n",
      "train_xNP dimension of element  2\n",
      "train_xNP size  38330000\n",
      "saving NP arrays\n",
      "NP arrays saved\n",
      "Initializing classifier\n",
      "Searching for a  RandomForestClassifier\n",
      "False\n",
      "file not found, creating new classifier\n",
      "this is the classifierName:  RandomForestClassifier\n",
      "Training...\n",
      "train_x (text) size: 153.32 megabytes\n",
      "train_y (labels) size: 0.030664 megabytes\n",
      "train_x (text) length: 7666\n",
      "train_y (labels) length: 7666\n",
      "[[0 1 1 ... 0 0 0]\n",
      " [1 1 0 ... 0 0 0]\n",
      " [1 1 0 ... 0 0 0]\n",
      " [1 0 1 ... 0 0 0]\n",
      " [1 1 1 ... 0 0 0]]\n",
      "[1 4 0 3 2]\n",
      "finished training, classifier size: 4.8e-05 megabytes\n",
      "Predicting...\n",
      "Analysing...\n",
      "analyse_results\n",
      "hello\n",
      "Precision\t0.11137707687975218\n",
      "Recall\t0.11137707687975218\n",
      "F1-score\t0.11137707687975218\n",
      "Accuracy\t0.11137707687975218\n",
      "classiferSaveFile:  isear_emointRandomForestClassifier.pkl\n",
      "Saved Successfully\n",
      "Total: 475 GiB\n",
      "Used: 344 GiB\n",
      "Free: 130 GiB\n",
      "-----------------------------------------------------------------------------------------\n",
      "('isear', 'emobank', 'descriptions', 'headlines')\n",
      "Getting data\n",
      "get_train_test param:\n",
      "json  unified-dataset.jsonl\n",
      "train  isear\n",
      "test  emobank\n",
      "there were  10062  entries that were in test and  211377 that were not in test and  7666  that were in train\n",
      "test was appended  10062  times\n",
      "single\n",
      "Detected mode: multi...\n",
      "7666 10062\n",
      "Getting wordlist...\n",
      "Getting emotions\n",
      "[]\n",
      "Making arrays\n",
      "checking for save files\n",
      "emotions in make_arrays:  {}\n",
      "train super raw:  0.061424\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████| 7666/7666 [00:03<00:00, 2466.52it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████| 10062/10062 [00:04<00:00, 2435.03it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_x length  7666\n",
      "train_x dimension of element  5000\n",
      "train_x (text) size RAW: 0.061424 megabytes\n",
      "train_y (labels) size RAW: 0.061424 megabytes\n",
      "test_x (text) size RAW: 0.087616 megabytes\n",
      "test_y (labels) size RAW: 0.087616 megabytes\n",
      "saved test_y\n",
      "train_x Size stays the same False\n",
      "train_y Size stays the same False\n",
      "test_x Size stays the same False\n",
      "test_y Size stays the same False\n",
      "train_xNPSize (text) size: 153.32 megabytes\n",
      "train_yNPSize (labels) size: 0.0 megabytes\n",
      "test_xNPSize (text) size: 201.24 megabytes\n",
      "test_yNPSize (labels) size: 0.0 megabytes\n",
      "train_xNP length  7666\n",
      "train_xNP dimension of element  2\n",
      "train_xNP size  38330000\n",
      "Train or test empty. Did you misspell the dataset name?\n",
      "('isear', 'dailydialog', 'descriptions', 'conversations')\n",
      "Getting data\n",
      "get_train_test param:\n",
      "json  unified-dataset.jsonl\n",
      "train  isear\n",
      "test  dailydialog\n",
      "there were  102979  entries that were in test and  118460 that were not in test and  7666  that were in train\n",
      "test was appended  102979  times\n",
      "single\n",
      "oof\n",
      "Detected mode: single...\n",
      "7666 102979\n",
      "Getting wordlist...\n",
      "Getting emotions\n",
      "['anger', 'joy', 'noemo', 'disgust', 'sadness', 'fear']\n",
      "Making arrays\n",
      "checking for save files\n",
      "emotions in make_arrays:  {'anger': 0, 'joy': 1, 'noemo': 2, 'disgust': 3, 'sadness': 4, 'fear': 5}\n",
      "train super raw:  0.061424\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████| 7666/7666 [00:03<00:00, 2486.24it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████| 102979/102979 [00:45<00:00, 2277.39it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_x length  7666\n",
      "train_x dimension of element  5000\n",
      "train_x (text) size RAW: 0.061424 megabytes\n",
      "train_y (labels) size RAW: 0.061424 megabytes\n",
      "test_x (text) size RAW: 0.824456 megabytes\n",
      "test_y (labels) size RAW: 0.824456 megabytes\n",
      "saved test_y\n",
      "train_x Size stays the same False\n",
      "train_y Size stays the same False\n",
      "test_x Size stays the same False\n",
      "test_y Size stays the same False\n",
      "train_xNPSize (text) size: 153.32 megabytes\n",
      "train_yNPSize (labels) size: 0.030664 megabytes\n",
      "test_xNPSize (text) size: 2059.58 megabytes\n",
      "test_yNPSize (labels) size: 0.411916 megabytes\n",
      "train_xNP length  7666\n",
      "train_xNP dimension of element  2\n",
      "train_xNP size  38330000\n",
      "saving NP arrays\n",
      "NP arrays saved\n",
      "Initializing classifier\n",
      "Searching for a  RandomForestClassifier\n",
      "False\n",
      "file not found, creating new classifier\n",
      "this is the classifierName:  RandomForestClassifier\n",
      "Training...\n",
      "train_x (text) size: 153.32 megabytes\n",
      "train_y (labels) size: 0.030664 megabytes\n",
      "train_x (text) length: 7666\n",
      "train_y (labels) length: 7666\n",
      "[[0 1 1 ... 0 0 0]\n",
      " [1 1 0 ... 0 0 0]\n",
      " [1 1 0 ... 0 0 0]\n",
      " [1 0 1 ... 0 0 0]\n",
      " [1 1 1 ... 0 0 0]]\n",
      "[1 5 0 4 3]\n",
      "finished training, classifier size: 4.8e-05 megabytes\n",
      "Predicting...\n",
      "Analysing...\n",
      "analyse_results\n",
      "hello\n",
      "Precision\t0.5018790238786549\n",
      "Recall\t0.5018790238786549\n",
      "F1-score\t0.5018790238786549\n",
      "Accuracy\t0.5018790238786549\n",
      "classiferSaveFile:  isear_dailydialogRandomForestClassifier.pkl\n",
      "Saved Successfully\n",
      "Total: 475 GiB\n",
      "Used: 346 GiB\n",
      "Free: 128 GiB\n",
      "-----------------------------------------------------------------------------------------\n",
      "('isear', 'crowdflower', 'descriptions', 'tweets')\n",
      "Getting data\n",
      "get_train_test param:\n",
      "json  unified-dataset.jsonl\n",
      "train  isear\n",
      "test  crowdflower\n",
      "there were  39740  entries that were in test and  181699 that were not in test and  7666  that were in train\n",
      "test was appended  39740  times\n",
      "single\n",
      "oof\n",
      "Detected mode: single...\n",
      "7666 39740\n",
      "Getting wordlist...\n",
      "Getting emotions\n",
      "['anger', 'joy', 'noemo', 'disgust', 'sadness', 'fear']\n",
      "Making arrays\n",
      "checking for save files\n",
      "saved train_xNP as isear_crowdflowertrain_xNP.npy\n",
      "saved train_yNP as isear_crowdflowertrain_yNP.npy\n",
      "saved test_xNP as isear_crowdflowertest_xNP.npy\n",
      "saved test_yNP as isear_crowdflowertest_yNP.npy\n",
      "loading from np\n",
      "loaded directly from NP.load\n",
      "train_xNPSize (text) size loaded: 153.32 megabytes\n",
      "train_yNPSize (labels) size loaded: 0.030664 megabytes\n",
      "test_xNPSize (text) size loaded: 794.8 megabytes\n",
      "test_yNPSize (labels) size loaded: 0.15896 megabytes\n",
      "Initializing classifier\n",
      "Searching for a  RandomForestClassifier\n",
      "True\n",
      "Loading classifier from file\n",
      "classifier loaded successfully\n",
      "Predicting...\n",
      "Analysing...\n",
      "analyse_results\n",
      "hello\n",
      "Precision\t0.09079013588324107\n",
      "Recall\t0.09079013588324107\n",
      "F1-score\t0.09079013588324107\n",
      "Accuracy\t0.09079013588324107\n",
      "classifier already saved\n",
      "Total: 475 GiB\n",
      "Used: 346 GiB\n",
      "Free: 128 GiB\n",
      "-----------------------------------------------------------------------------------------\n",
      "('isear', 'affectivetext', 'descriptions', 'headlines')\n",
      "Getting data\n",
      "get_train_test param:\n",
      "json  unified-dataset.jsonl\n",
      "train  isear\n",
      "test  affectivetext\n",
      "there were  1250  entries that were in test and  220189 that were not in test and  7666  that were in train\n",
      "test was appended  1250  times\n",
      "single\n",
      "Detected mode: multi...\n",
      "7666 1250\n",
      "Getting wordlist...\n",
      "Getting emotions\n",
      "['anger', 'joy', 'disgust', 'sadness', 'fear']\n",
      "Making arrays\n",
      "checking for save files\n",
      "emotions in make_arrays:  {'anger': 0, 'joy': 1, 'disgust': 2, 'sadness': 3, 'fear': 4}\n",
      "train super raw:  0.061424\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████| 7666/7666 [00:02<00:00, 2606.37it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████| 1250/1250 [00:00<00:00, 2176.79it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_x length  7666\n",
      "train_x dimension of element  5000\n",
      "train_x (text) size RAW: 0.061424 megabytes\n",
      "train_y (labels) size RAW: 0.061424 megabytes\n",
      "test_x (text) size RAW: 0.010192 megabytes\n",
      "test_y (labels) size RAW: 0.010192 megabytes\n",
      "saved test_y\n",
      "train_x Size stays the same False\n",
      "train_y Size stays the same False\n",
      "test_x Size stays the same False\n",
      "test_y Size stays the same False\n",
      "train_xNPSize (text) size: 153.32 megabytes\n",
      "train_yNPSize (labels) size: 0.15332 megabytes\n",
      "test_xNPSize (text) size: 25.0 megabytes\n",
      "test_yNPSize (labels) size: 0.025 megabytes\n",
      "train_xNP length  7666\n",
      "train_xNP dimension of element  2\n",
      "train_xNP size  38330000\n",
      "saving NP arrays\n",
      "NP arrays saved\n",
      "Initializing classifier\n",
      "Searching for a  RandomForestClassifier\n",
      "False\n",
      "file not found, creating new classifier\n",
      "this is the classifierName:  RandomForestClassifier\n",
      "Training...\n",
      "train_x (text) size: 153.32 megabytes\n",
      "train_y (labels) size: 0.15332 megabytes\n",
      "train_x (text) length: 7666\n",
      "train_y (labels) length: 7666\n",
      "[[0 1 1 ... 0 0 0]\n",
      " [1 1 0 ... 0 0 0]\n",
      " [1 1 0 ... 0 0 0]\n",
      " [1 0 1 ... 0 0 0]\n",
      " [1 1 1 ... 0 0 0]]\n",
      "[[0 1 0 0 0]\n",
      " [0 0 0 0 1]\n",
      " [1 0 0 0 0]\n",
      " [0 0 0 1 0]\n",
      " [0 0 1 0 0]]\n",
      "finished training, classifier size: 4.8e-05 megabytes\n",
      "Predicting...\n",
      "Analysing...\n",
      "analyse_results\n",
      "hello\n",
      "Precision\t0.5476190476190477\n",
      "Recall\t0.07562679819153309\n",
      "F1-score\t0.1328999638858794\n",
      "Accuracy\t0.0784\n",
      "classiferSaveFile:  isear_affectivetextRandomForestClassifier.pkl\n",
      "Saved Successfully\n",
      "Total: 475 GiB\n",
      "Used: 346 GiB\n",
      "Free: 128 GiB\n",
      "-----------------------------------------------------------------------------------------\n",
      "('dailydialog', 'tec', 'conversations', 'tweets')\n",
      "Getting data\n",
      "get_train_test param:\n",
      "json  unified-dataset.jsonl\n",
      "train  dailydialog\n",
      "test  tec\n",
      "there were  21051  entries that were in test and  200388 that were not in test and  102979  that were in train\n",
      "test was appended  21051  times\n",
      "single\n",
      "oof\n",
      "Detected mode: single...\n",
      "102979 21051\n",
      "Getting wordlist...\n",
      "Getting emotions\n",
      "['anger', 'joy', 'noemo', 'surprise', 'disgust', 'sadness', 'fear']\n",
      "Making arrays\n",
      "checking for save files\n",
      "emotions in make_arrays:  {'anger': 0, 'joy': 1, 'noemo': 2, 'surprise': 3, 'disgust': 4, 'sadness': 5, 'fear': 6}\n",
      "train super raw:  0.824456\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████| 102979/102979 [00:45<00:00, 2248.06it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████| 21051/21051 [00:08<00:00, 2370.60it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_x length  102979\n",
      "train_x dimension of element  5000\n",
      "train_x (text) size RAW: 0.824456 megabytes\n",
      "train_y (labels) size RAW: 0.824456 megabytes\n",
      "test_x (text) size RAW: 0.178016 megabytes\n",
      "test_y (labels) size RAW: 0.178016 megabytes\n",
      "saved test_y\n",
      "train_x Size stays the same False\n",
      "train_y Size stays the same False\n",
      "test_x Size stays the same False\n",
      "test_y Size stays the same False\n",
      "train_xNPSize (text) size: 2059.58 megabytes\n",
      "train_yNPSize (labels) size: 0.411916 megabytes\n",
      "test_xNPSize (text) size: 421.02 megabytes\n",
      "test_yNPSize (labels) size: 0.084204 megabytes\n",
      "train_xNP length  102979\n",
      "train_xNP dimension of element  2\n",
      "train_xNP size  514895000\n",
      "saving NP arrays\n",
      "NP arrays saved\n",
      "Initializing classifier\n",
      "Searching for a  RandomForestClassifier\n",
      "False\n",
      "file not found, creating new classifier\n",
      "this is the classifierName:  RandomForestClassifier\n",
      "Training...\n",
      "train_x (text) size: 2059.58 megabytes\n",
      "train_y (labels) size: 0.411916 megabytes\n",
      "train_x (text) length: 102979\n",
      "train_y (labels) length: 102979\n",
      "[[0 0 1 ... 0 0 0]\n",
      " [1 0 1 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " [1 0 0 ... 0 0 0]\n",
      " [0 1 0 ... 0 0 0]]\n",
      "[4 2 1 4 2]\n",
      "finished training, classifier size: 4.8e-05 megabytes\n",
      "Predicting...\n",
      "Analysing...\n",
      "analyse_results\n",
      "hello\n",
      "Precision\t0.021424160372428863\n",
      "Recall\t0.021424160372428863\n",
      "F1-score\t0.021424160372428863\n",
      "Accuracy\t0.021424160372428863\n",
      "classiferSaveFile:  dailydialog_tecRandomForestClassifier.pkl\n",
      "Saved Successfully\n",
      "Total: 475 GiB\n",
      "Used: 349 GiB\n",
      "Free: 125 GiB\n",
      "-----------------------------------------------------------------------------------------\n",
      "('dailydialog', 'tales-emotion', 'conversations', 'tales')\n",
      "Getting data\n",
      "get_train_test param:\n",
      "json  unified-dataset.jsonl\n",
      "train  dailydialog\n",
      "test  tales-emotion\n",
      "there were  14771  entries that were in test and  206668 that were not in test and  102979  that were in train\n",
      "test was appended  14771  times\n",
      "single\n",
      "oof\n",
      "Detected mode: single...\n",
      "102979 14771\n",
      "Getting wordlist...\n",
      "Getting emotions\n",
      "['noemo', 'surprise', 'disgust', 'anger', 'joy', 'sadness', 'fear']\n",
      "Making arrays\n",
      "checking for save files\n",
      "emotions in make_arrays:  {'noemo': 0, 'surprise': 1, 'disgust': 2, 'anger': 3, 'joy': 4, 'sadness': 5, 'fear': 6}\n",
      "train super raw:  0.824456\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████| 102979/102979 [00:38<00:00, 2674.80it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████| 14771/14771 [00:05<00:00, 2615.85it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_x length  102979\n",
      "train_x dimension of element  5000\n",
      "train_x (text) size RAW: 0.824456 megabytes\n",
      "train_y (labels) size RAW: 0.824456 megabytes\n",
      "test_x (text) size RAW: 0.124912 megabytes\n",
      "test_y (labels) size RAW: 0.124912 megabytes\n",
      "saved test_y\n",
      "train_x Size stays the same False\n",
      "train_y Size stays the same False\n",
      "test_x Size stays the same False\n",
      "test_y Size stays the same False\n",
      "train_xNPSize (text) size: 2059.58 megabytes\n",
      "train_yNPSize (labels) size: 0.411916 megabytes\n",
      "test_xNPSize (text) size: 295.42 megabytes\n",
      "test_yNPSize (labels) size: 0.059084 megabytes\n",
      "train_xNP length  102979\n",
      "train_xNP dimension of element  2\n",
      "train_xNP size  514895000\n",
      "saving NP arrays\n",
      "NP arrays saved\n",
      "Initializing classifier\n",
      "Searching for a  RandomForestClassifier\n",
      "False\n",
      "file not found, creating new classifier\n",
      "this is the classifierName:  RandomForestClassifier\n",
      "Training...\n",
      "train_x (text) size: 2059.58 megabytes\n",
      "train_y (labels) size: 0.411916 megabytes\n",
      "train_x (text) length: 102979\n",
      "train_y (labels) length: 102979\n",
      "[[0 0 1 ... 0 0 0]\n",
      " [1 0 1 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " [1 0 0 ... 0 0 0]\n",
      " [0 1 0 ... 0 0 0]]\n",
      "[2 0 4 2 0]\n",
      "finished training, classifier size: 4.8e-05 megabytes\n",
      "Predicting...\n",
      "Analysing...\n",
      "analyse_results\n",
      "hello\n",
      "Precision\t0.6365852007311624\n",
      "Recall\t0.6365852007311624\n",
      "F1-score\t0.6365852007311624\n",
      "Accuracy\t0.6365852007311624\n",
      "classiferSaveFile:  dailydialog_tales-emotionRandomForestClassifier.pkl\n",
      "Saved Successfully\n",
      "Total: 475 GiB\n",
      "Used: 352 GiB\n",
      "Free: 122 GiB\n",
      "-----------------------------------------------------------------------------------------\n",
      "('dailydialog', 'ssec', 'conversations', 'tweets')\n",
      "Getting data\n",
      "get_train_test param:\n",
      "json  unified-dataset.jsonl\n",
      "train  dailydialog\n",
      "test  ssec\n",
      "there were  4868  entries that were in test and  216571 that were not in test and  102979  that were in train\n",
      "test was appended  4868  times\n",
      "single\n",
      "Detected mode: multi...\n",
      "102979 4868\n",
      "Getting wordlist...\n",
      "Getting emotions\n",
      "['anger', 'joy', 'surprise', 'disgust', 'sadness', 'fear']\n",
      "Making arrays\n",
      "checking for save files\n",
      "emotions in make_arrays:  {'anger': 0, 'joy': 1, 'surprise': 2, 'disgust': 3, 'sadness': 4, 'fear': 5}\n",
      "train super raw:  0.824456\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████| 102979/102979 [00:42<00:00, 2429.94it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████| 4868/4868 [00:01<00:00, 2457.03it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_x length  102979\n",
      "train_x dimension of element  5000\n",
      "train_x (text) size RAW: 0.824456 megabytes\n",
      "train_y (labels) size RAW: 0.824456 megabytes\n",
      "test_x (text) size RAW: 0.043032 megabytes\n",
      "test_y (labels) size RAW: 0.043032 megabytes\n",
      "saved test_y\n",
      "train_x Size stays the same False\n",
      "train_y Size stays the same False\n",
      "test_x Size stays the same False\n",
      "test_y Size stays the same False\n",
      "train_xNPSize (text) size: 2059.58 megabytes\n",
      "train_yNPSize (labels) size: 2.471496 megabytes\n",
      "test_xNPSize (text) size: 97.36 megabytes\n",
      "test_yNPSize (labels) size: 0.116832 megabytes\n",
      "train_xNP length  102979\n",
      "train_xNP dimension of element  2\n",
      "train_xNP size  514895000\n",
      "saving NP arrays\n",
      "NP arrays saved\n",
      "Initializing classifier\n",
      "Searching for a  RandomForestClassifier\n",
      "False\n",
      "file not found, creating new classifier\n",
      "this is the classifierName:  RandomForestClassifier\n",
      "Training...\n",
      "train_x (text) size: 2059.58 megabytes\n",
      "train_y (labels) size: 2.471496 megabytes\n",
      "train_x (text) length: 102979\n",
      "train_y (labels) length: 102979\n",
      "[[0 0 1 ... 0 0 0]\n",
      " [1 0 1 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " [1 0 0 ... 0 0 0]\n",
      " [0 1 0 ... 0 0 0]]\n",
      "[[0 0 0 1 0 0]\n",
      " [0 0 0 0 0 0]\n",
      " [0 1 0 0 0 0]\n",
      " [0 0 0 1 0 0]\n",
      " [0 0 0 0 0 0]]\n",
      "finished training, classifier size: 4.8e-05 megabytes\n",
      "Predicting...\n",
      "Analysing...\n",
      "analyse_results\n",
      "hello\n",
      "Precision\t0.9507042253521126\n",
      "Recall\t0.01059322033898305\n",
      "F1-score\t0.020952972217910912\n",
      "Accuracy\t0.0571076417419885\n",
      "classiferSaveFile:  dailydialog_ssecRandomForestClassifier.pkl\n",
      "Saved Successfully\n",
      "Total: 475 GiB\n",
      "Used: 355 GiB\n",
      "Free: 119 GiB\n",
      "-----------------------------------------------------------------------------------------\n",
      "('dailydialog', 'isear', 'conversations', 'descriptions')\n",
      "Getting data\n",
      "get_train_test param:\n",
      "json  unified-dataset.jsonl\n",
      "train  dailydialog\n",
      "test  isear\n",
      "there were  7666  entries that were in test and  213773 that were not in test and  102979  that were in train\n",
      "test was appended  7666  times\n",
      "single\n",
      "oof\n",
      "Detected mode: single...\n",
      "102979 7666\n",
      "Getting wordlist...\n",
      "Getting emotions\n",
      "['anger', 'joy', 'noemo', 'disgust', 'sadness', 'fear']\n",
      "Making arrays\n",
      "checking for save files\n",
      "emotions in make_arrays:  {'anger': 0, 'joy': 1, 'noemo': 2, 'disgust': 3, 'sadness': 4, 'fear': 5}\n",
      "train super raw:  0.824456\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████| 102979/102979 [00:45<00:00, 2267.10it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████| 7666/7666 [00:03<00:00, 2247.50it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_x length  102979\n",
      "train_x dimension of element  5000\n",
      "train_x (text) size RAW: 0.824456 megabytes\n",
      "train_y (labels) size RAW: 0.824456 megabytes\n",
      "test_x (text) size RAW: 0.061424 megabytes\n",
      "test_y (labels) size RAW: 0.061424 megabytes\n",
      "saved test_y\n",
      "train_x Size stays the same False\n",
      "train_y Size stays the same False\n",
      "test_x Size stays the same False\n",
      "test_y Size stays the same False\n",
      "train_xNPSize (text) size: 2059.58 megabytes\n",
      "train_yNPSize (labels) size: 0.411916 megabytes\n",
      "test_xNPSize (text) size: 153.32 megabytes\n",
      "test_yNPSize (labels) size: 0.030664 megabytes\n",
      "train_xNP length  102979\n",
      "train_xNP dimension of element  2\n",
      "train_xNP size  514895000\n",
      "saving NP arrays\n",
      "NP arrays saved\n",
      "Initializing classifier\n",
      "Searching for a  RandomForestClassifier\n",
      "False\n",
      "file not found, creating new classifier\n",
      "this is the classifierName:  RandomForestClassifier\n",
      "Training...\n",
      "train_x (text) size: 2059.58 megabytes\n",
      "train_y (labels) size: 0.411916 megabytes\n",
      "train_x (text) length: 102979\n",
      "train_y (labels) length: 102979\n",
      "[[0 0 1 ... 0 0 0]\n",
      " [1 0 1 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " [1 0 0 ... 0 0 0]\n",
      " [0 1 0 ... 0 0 0]]\n",
      "[3 2 1 3 2]\n",
      "finished training, classifier size: 4.8e-05 megabytes\n",
      "Predicting...\n",
      "Analysing...\n",
      "analyse_results\n",
      "hello\n",
      "Precision\t0.2885468301591443\n",
      "Recall\t0.2885468301591443\n",
      "F1-score\t0.2885468301591443\n",
      "Accuracy\t0.2885468301591443\n",
      "classiferSaveFile:  dailydialog_isearRandomForestClassifier.pkl\n",
      "Saved Successfully\n",
      "Total: 475 GiB\n",
      "Used: 358 GiB\n",
      "Free: 116 GiB\n",
      "-----------------------------------------------------------------------------------------\n",
      "('dailydialog', 'grounded_emotions', 'conversations', 'tweets')\n",
      "Getting data\n",
      "get_train_test param:\n",
      "json  unified-dataset.jsonl\n",
      "train  dailydialog\n",
      "test  grounded_emotions\n",
      "there were  2585  entries that were in test and  218854 that were not in test and  102979  that were in train\n",
      "test was appended  2585  times\n",
      "single\n",
      "oof\n",
      "Detected mode: single...\n",
      "102979 2585\n",
      "Getting wordlist...\n",
      "Getting emotions\n",
      "['joy', 'noemo', 'sadness']\n",
      "Making arrays\n",
      "checking for save files\n",
      "emotions in make_arrays:  {'joy': 0, 'noemo': 1, 'sadness': 2}\n",
      "train super raw:  0.824456\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████| 102979/102979 [00:45<00:00, 2276.25it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████| 2585/2585 [00:01<00:00, 2324.69it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_x length  102979\n",
      "train_x dimension of element  5000\n",
      "train_x (text) size RAW: 0.824456 megabytes\n",
      "train_y (labels) size RAW: 0.824456 megabytes\n",
      "test_x (text) size RAW: 0.02104 megabytes\n",
      "test_y (labels) size RAW: 0.02104 megabytes\n",
      "saved test_y\n",
      "train_x Size stays the same False\n",
      "train_y Size stays the same False\n",
      "test_x Size stays the same False\n",
      "test_y Size stays the same False\n",
      "train_xNPSize (text) size: 2059.58 megabytes\n",
      "train_yNPSize (labels) size: 0.411916 megabytes\n",
      "test_xNPSize (text) size: 51.7 megabytes\n",
      "test_yNPSize (labels) size: 0.01034 megabytes\n",
      "train_xNP length  102979\n",
      "train_xNP dimension of element  2\n",
      "train_xNP size  514895000\n",
      "saving NP arrays\n",
      "NP arrays saved\n",
      "Initializing classifier\n",
      "Searching for a  RandomForestClassifier\n",
      "False\n",
      "file not found, creating new classifier\n",
      "this is the classifierName:  RandomForestClassifier\n",
      "Training...\n",
      "train_x (text) size: 2059.58 megabytes\n",
      "train_y (labels) size: 0.411916 megabytes\n",
      "train_x (text) length: 102979\n",
      "train_y (labels) length: 102979\n",
      "[[0 0 1 ... 0 0 0]\n",
      " [1 0 1 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " [1 0 0 ... 0 0 0]\n",
      " [0 1 0 ... 0 0 0]]\n",
      "[1 1 0 1 1]\n",
      "finished training, classifier size: 4.8e-05 megabytes\n",
      "Predicting...\n",
      "Analysing...\n",
      "analyse_results\n",
      "hello\n",
      "Precision\t0.025145067698259187\n",
      "Recall\t0.025145067698259187\n",
      "F1-score\t0.025145067698259187\n",
      "Accuracy\t0.025145067698259187\n",
      "classiferSaveFile:  dailydialog_grounded_emotionsRandomForestClassifier.pkl\n",
      "Saved Successfully\n",
      "Total: 475 GiB\n",
      "Used: 360 GiB\n",
      "Free: 114 GiB\n",
      "-----------------------------------------------------------------------------------------\n",
      "('dailydialog', 'emotion-cause', 'conversations', 'paragraphs')\n",
      "Getting data\n",
      "get_train_test param:\n",
      "json  unified-dataset.jsonl\n",
      "train  dailydialog\n",
      "test  emotion-cause\n",
      "there were  2414  entries that were in test and  219025 that were not in test and  102979  that were in train\n",
      "test was appended  2414  times\n",
      "single\n",
      "oof\n",
      "Detected mode: single...\n",
      "102979 2414\n",
      "Getting wordlist...\n",
      "Getting emotions\n",
      "['anger', 'joy', 'noemo', 'surprise', 'disgust', 'sadness', 'fear']\n",
      "Making arrays\n",
      "checking for save files\n",
      "emotions in make_arrays:  {'anger': 0, 'joy': 1, 'noemo': 2, 'surprise': 3, 'disgust': 4, 'sadness': 5, 'fear': 6}\n",
      "train super raw:  0.824456\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████| 102979/102979 [00:38<00:00, 2640.56it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████| 2414/2414 [00:00<00:00, 2700.38it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_x length  102979\n",
      "train_x dimension of element  5000\n",
      "train_x (text) size RAW: 0.824456 megabytes\n",
      "train_y (labels) size RAW: 0.824456 megabytes\n",
      "test_x (text) size RAW: 0.02104 megabytes\n",
      "test_y (labels) size RAW: 0.02104 megabytes\n",
      "saved test_y\n",
      "train_x Size stays the same False\n",
      "train_y Size stays the same False\n",
      "test_x Size stays the same False\n",
      "test_y Size stays the same False\n",
      "train_xNPSize (text) size: 2059.58 megabytes\n",
      "train_yNPSize (labels) size: 0.411916 megabytes\n",
      "test_xNPSize (text) size: 48.28 megabytes\n",
      "test_yNPSize (labels) size: 0.009656 megabytes\n",
      "train_xNP length  102979\n",
      "train_xNP dimension of element  2\n",
      "train_xNP size  514895000\n",
      "saving NP arrays\n",
      "NP arrays saved\n",
      "Initializing classifier\n",
      "Searching for a  RandomForestClassifier\n",
      "False\n",
      "file not found, creating new classifier\n",
      "this is the classifierName:  RandomForestClassifier\n",
      "Training...\n",
      "train_x (text) size: 2059.58 megabytes\n",
      "train_y (labels) size: 0.411916 megabytes\n",
      "train_x (text) length: 102979\n",
      "train_y (labels) length: 102979\n",
      "[[0 0 1 ... 0 0 0]\n",
      " [1 0 1 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " [1 0 0 ... 0 0 0]\n",
      " [0 1 0 ... 0 0 0]]\n",
      "[4 2 1 4 2]\n",
      "finished training, classifier size: 4.8e-05 megabytes\n",
      "Predicting...\n",
      "Analysing...\n",
      "analyse_results\n",
      "hello\n",
      "Precision\t0.06545153272576636\n",
      "Recall\t0.06545153272576636\n",
      "F1-score\t0.06545153272576636\n",
      "Accuracy\t0.06545153272576636\n",
      "classiferSaveFile:  dailydialog_emotion-causeRandomForestClassifier.pkl\n",
      "Saved Successfully\n",
      "Total: 475 GiB\n",
      "Used: 362 GiB\n",
      "Free: 112 GiB\n",
      "-----------------------------------------------------------------------------------------\n",
      "('dailydialog', 'emoint', 'conversations', 'tweets')\n",
      "Getting data\n",
      "get_train_test param:\n",
      "json  unified-dataset.jsonl\n",
      "train  dailydialog\n",
      "test  emoint\n",
      "there were  7102  entries that were in test and  214337 that were not in test and  102979  that were in train\n",
      "test was appended  7102  times\n",
      "single\n",
      "oof\n",
      "Detected mode: single...\n",
      "102979 7102\n",
      "Getting wordlist...\n",
      "Getting emotions\n",
      "['anger', 'joy', 'noemo', 'sadness', 'fear']\n",
      "Making arrays\n",
      "checking for save files\n",
      "emotions in make_arrays:  {'anger': 0, 'joy': 1, 'noemo': 2, 'sadness': 3, 'fear': 4}\n",
      "train super raw:  0.824456\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████| 102979/102979 [00:38<00:00, 2681.33it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████| 7102/7102 [00:02<00:00, 2666.90it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_x length  102979\n",
      "train_x dimension of element  5000\n",
      "train_x (text) size RAW: 0.824456 megabytes\n",
      "train_y (labels) size RAW: 0.824456 megabytes\n",
      "test_x (text) size RAW: 0.061424 megabytes\n",
      "test_y (labels) size RAW: 0.061424 megabytes\n",
      "saved test_y\n",
      "train_x Size stays the same False\n",
      "train_y Size stays the same False\n",
      "test_x Size stays the same False\n",
      "test_y Size stays the same False\n",
      "train_xNPSize (text) size: 2059.58 megabytes\n",
      "train_yNPSize (labels) size: 0.411916 megabytes\n",
      "test_xNPSize (text) size: 142.04 megabytes\n",
      "test_yNPSize (labels) size: 0.028408 megabytes\n",
      "train_xNP length  102979\n",
      "train_xNP dimension of element  2\n",
      "train_xNP size  514895000\n",
      "saving NP arrays\n",
      "NP arrays saved\n",
      "Initializing classifier\n",
      "Searching for a  RandomForestClassifier\n",
      "False\n",
      "file not found, creating new classifier\n",
      "this is the classifierName:  RandomForestClassifier\n",
      "Training...\n",
      "train_x (text) size: 2059.58 megabytes\n",
      "train_y (labels) size: 0.411916 megabytes\n",
      "train_x (text) length: 102979\n",
      "train_y (labels) length: 102979\n",
      "[[0 0 1 ... 0 0 0]\n",
      " [1 0 1 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " [1 0 0 ... 0 0 0]\n",
      " [0 1 0 ... 0 0 0]]\n",
      "[2 2 1 2 2]\n",
      "finished training, classifier size: 4.8e-05 megabytes\n",
      "Predicting...\n",
      "Analysing...\n",
      "analyse_results\n",
      "hello\n",
      "Precision\t0.017459870459025625\n",
      "Recall\t0.017459870459025625\n",
      "F1-score\t0.017459870459025625\n",
      "Accuracy\t0.017459870459025625\n",
      "classiferSaveFile:  dailydialog_emointRandomForestClassifier.pkl\n",
      "Saved Successfully\n",
      "Total: 475 GiB\n",
      "Used: 365 GiB\n",
      "Free: 109 GiB\n",
      "-----------------------------------------------------------------------------------------\n",
      "('dailydialog', 'emobank', 'conversations', 'headlines')\n",
      "Getting data\n",
      "get_train_test param:\n",
      "json  unified-dataset.jsonl\n",
      "train  dailydialog\n",
      "test  emobank\n",
      "there were  10062  entries that were in test and  211377 that were not in test and  102979  that were in train\n",
      "test was appended  10062  times\n",
      "single\n",
      "Detected mode: multi...\n",
      "102979 10062\n",
      "Getting wordlist...\n",
      "Getting emotions\n",
      "[]\n",
      "Making arrays\n",
      "checking for save files\n",
      "emotions in make_arrays:  {}\n",
      "train super raw:  0.824456\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████| 102979/102979 [00:39<00:00, 2615.87it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████| 10062/10062 [00:04<00:00, 2156.93it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_x length  102979\n",
      "train_x dimension of element  5000\n",
      "train_x (text) size RAW: 0.824456 megabytes\n",
      "train_y (labels) size RAW: 0.824456 megabytes\n",
      "test_x (text) size RAW: 0.087616 megabytes\n",
      "test_y (labels) size RAW: 0.087616 megabytes\n",
      "saved test_y\n",
      "train_x Size stays the same False\n",
      "train_y Size stays the same False\n",
      "test_x Size stays the same False\n",
      "test_y Size stays the same False\n",
      "train_xNPSize (text) size: 2059.58 megabytes\n",
      "train_yNPSize (labels) size: 0.0 megabytes\n",
      "test_xNPSize (text) size: 201.24 megabytes\n",
      "test_yNPSize (labels) size: 0.0 megabytes\n",
      "train_xNP length  102979\n",
      "train_xNP dimension of element  2\n",
      "train_xNP size  514895000\n",
      "Train or test empty. Did you misspell the dataset name?\n",
      "('dailydialog', 'crowdflower', 'conversations', 'tweets')\n",
      "Getting data\n",
      "get_train_test param:\n",
      "json  unified-dataset.jsonl\n",
      "train  dailydialog\n",
      "test  crowdflower\n",
      "there were  39740  entries that were in test and  181699 that were not in test and  102979  that were in train\n",
      "test was appended  39740  times\n",
      "single\n",
      "oof\n",
      "Detected mode: single...\n",
      "102979 39740\n",
      "Getting wordlist...\n",
      "Getting emotions\n",
      "['noemo', 'surprise', 'disgust', 'anger', 'joy', 'sadness', 'fear']\n",
      "Making arrays\n",
      "checking for save files\n",
      "emotions in make_arrays:  {'noemo': 0, 'surprise': 1, 'disgust': 2, 'anger': 3, 'joy': 4, 'sadness': 5, 'fear': 6}\n",
      "train super raw:  0.824456\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████| 102979/102979 [00:38<00:00, 2694.06it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████| 39740/39740 [00:16<00:00, 2404.03it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_x length  102979\n",
      "train_x dimension of element  5000\n",
      "train_x (text) size RAW: 0.824456 megabytes\n",
      "train_y (labels) size RAW: 0.824456 megabytes\n",
      "test_x (text) size RAW: 0.321096 megabytes\n",
      "test_y (labels) size RAW: 0.321096 megabytes\n",
      "saved test_y\n",
      "train_x Size stays the same False\n",
      "train_y Size stays the same False\n",
      "test_x Size stays the same False\n",
      "test_y Size stays the same False\n",
      "train_xNPSize (text) size: 2059.58 megabytes\n",
      "train_yNPSize (labels) size: 0.411916 megabytes\n",
      "test_xNPSize (text) size: 794.8 megabytes\n",
      "test_yNPSize (labels) size: 0.15896 megabytes\n",
      "train_xNP length  102979\n",
      "train_xNP dimension of element  2\n",
      "train_xNP size  514895000\n",
      "saving NP arrays\n",
      "NP arrays saved\n",
      "Initializing classifier\n",
      "Searching for a  RandomForestClassifier\n",
      "False\n",
      "file not found, creating new classifier\n",
      "this is the classifierName:  RandomForestClassifier\n",
      "Training...\n",
      "train_x (text) size: 2059.58 megabytes\n",
      "train_y (labels) size: 0.411916 megabytes\n",
      "train_x (text) length: 102979\n",
      "train_y (labels) length: 102979\n",
      "[[0 0 1 ... 0 0 0]\n",
      " [1 0 1 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " [1 0 0 ... 0 0 0]\n",
      " [0 1 0 ... 0 0 0]]\n",
      "[2 0 4 2 0]\n",
      "finished training, classifier size: 4.8e-05 megabytes\n",
      "Predicting...\n",
      "Analysing...\n",
      "analyse_results\n",
      "hello\n",
      "Precision\t0.3291897332662305\n",
      "Recall\t0.3291897332662305\n",
      "F1-score\t0.3291897332662305\n",
      "Accuracy\t0.3291897332662305\n",
      "classiferSaveFile:  dailydialog_crowdflowerRandomForestClassifier.pkl\n",
      "Saved Successfully\n",
      "Total: 475 GiB\n",
      "Used: 368 GiB\n",
      "Free: 106 GiB\n",
      "-----------------------------------------------------------------------------------------\n",
      "('dailydialog', 'affectivetext', 'conversations', 'headlines')\n",
      "Getting data\n",
      "get_train_test param:\n",
      "json  unified-dataset.jsonl\n",
      "train  dailydialog\n",
      "test  affectivetext\n",
      "there were  1250  entries that were in test and  220189 that were not in test and  102979  that were in train\n",
      "test was appended  1250  times\n",
      "single\n",
      "Detected mode: multi...\n",
      "102979 1250\n",
      "Getting wordlist...\n",
      "Getting emotions\n",
      "['anger', 'joy', 'surprise', 'disgust', 'sadness', 'fear']\n",
      "Making arrays\n",
      "checking for save files\n",
      "saved train_xNP as dailydialog_affectivetexttrain_xNP.npy\n",
      "saved train_yNP as dailydialog_affectivetexttrain_yNP.npy\n",
      "saved test_xNP as dailydialog_affectivetexttest_xNP.npy\n",
      "saved test_yNP as dailydialog_affectivetexttest_yNP.npy\n",
      "loading from np\n",
      "loaded directly from NP.load\n",
      "train_xNPSize (text) size loaded: 2059.58 megabytes\n",
      "train_yNPSize (labels) size loaded: 2.471496 megabytes\n",
      "test_xNPSize (text) size loaded: 25.0 megabytes\n",
      "test_yNPSize (labels) size loaded: 0.03 megabytes\n",
      "Initializing classifier\n",
      "Searching for a  RandomForestClassifier\n",
      "False\n",
      "file not found, creating new classifier\n",
      "this is the classifierName:  RandomForestClassifier\n",
      "Training...\n",
      "train_x (text) size: 2059.58 megabytes\n",
      "train_y (labels) size: 2.471496 megabytes\n",
      "train_x (text) length: 102979\n",
      "train_y (labels) length: 102979\n",
      "[[0 0 1 ... 0 0 0]\n",
      " [1 0 1 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " [1 0 0 ... 0 0 0]\n",
      " [0 1 0 ... 0 0 0]]\n",
      "[[0 0 0 0 0 1]\n",
      " [0 0 0 0 0 0]\n",
      " [0 0 0 0 1 0]\n",
      " [0 0 0 0 0 1]\n",
      " [0 0 0 0 0 0]]\n",
      "finished training, classifier size: 4.8e-05 megabytes\n",
      "Predicting...\n",
      "Analysing...\n",
      "analyse_results\n",
      "hello\n",
      "Precision\t0.9444444444444444\n",
      "Recall\t0.005279503105590062\n",
      "F1-score\t0.010500308832612723\n",
      "Accuracy\t0.0336\n",
      "classiferSaveFile:  dailydialog_affectivetextRandomForestClassifier.pkl\n",
      "Saved Successfully\n",
      "Total: 475 GiB\n",
      "Used: 369 GiB\n",
      "Free: 105 GiB\n",
      "-----------------------------------------------------------------------------------------\n",
      "('affectivetext', 'affectivetext', 'headlines', 'headlines')\n",
      "Getting data\n",
      "get_train_test param:\n",
      "json  unified-dataset.jsonl\n",
      "train  affectivetext\n",
      "test  affectivetext\n",
      "there were  1250  entries that were in test and  220189 that were not in test and  0  that were in train\n",
      "test was appended  1250  times\n",
      "single\n",
      "Detected mode: multi...\n",
      "0 1250\n",
      "Getting wordlist...\n",
      "Getting emotions\n",
      "[]\n",
      "Making arrays\n",
      "checking for save files\n",
      "emotions in make_arrays:  {}\n",
      "train super raw:  5.6e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████| 1250/1250 [00:00<00:00, 9523.26it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_x length  0\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "list index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-43-13827a3104f6>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m    141\u001b[0m             \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"test_yNPSize (labels) size loaded:\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtest_yNPSize\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m\"megabytes\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    142\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 143\u001b[1;33m             \u001b[0mtrain_x\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrain_y\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtest_x\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtest_y\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msizes\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmake_arrays\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtraining_data\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtesting_data\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mwordlist\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0misAllVS\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    144\u001b[0m             \u001b[0mtrain_xSize\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrain_ySize\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtest_xSize\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtest_ySize\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msizes\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    145\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0many\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;32mnot\u001b[0m \u001b[0mpart\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msize\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mpart\u001b[0m \u001b[1;32min\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mtrain_x\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrain_y\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtest_x\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtest_y\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-29-c98a82651d71>\u001b[0m in \u001b[0;36mmake_arrays\u001b[1;34m(train, test, words, labels, mode, all_vs)\u001b[0m\n\u001b[0;32m     22\u001b[0m \u001b[1;31m#     print(\"train_x item:\", train_x[0])\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     23\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"train_x length \"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain_x\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 24\u001b[1;33m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"train_x dimension of element \"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain_x\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     25\u001b[0m     \u001b[0mtrain_xSize\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msys\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgetsizeof\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain_x\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m/\u001b[0m\u001b[1;36m1000000\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     26\u001b[0m     \u001b[0mtrain_ySize\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msys\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgetsizeof\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain_y\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m/\u001b[0m\u001b[1;36m1000000\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mIndexError\u001b[0m: list index out of range"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    possibleChoices = [('affectivetext','headlines'), ('crowdflower','tweets'), ('dailydialog','conversations'), \n",
    "                       ('emobank','headlines'), ('emoint','tweets'), \n",
    "                       ('emotion-cause','paragraphs'), ('grounded_emotions','tweets'), ('isear','descriptions'),\n",
    "                       ('ssec','tweets'),('tales-emotion','tales'), ('tec','tweets')] \n",
    "                        #('electoraltweets','tweets') <- incompatible due to labelling\n",
    "    #     print(possibleChoices)\n",
    "    permutations = list(getPermutations(possibleChoices))\n",
    "    powerSet = list(getPowerset(possibleChoices))\n",
    "#     print(\"powerset: \", powerSet)\n",
    "    print(\"permutations length: \",len(permutations))\n",
    "#     print(permutations)\n",
    "    corporaSets = []\n",
    "    for choice in permutations:\n",
    "#         print(\"choice \", choice)\n",
    "        if(len(choice) == 2):\n",
    "#             print(\"pair\")\n",
    "            first, second = choice\n",
    "            firstCorpus, domain1 = first\n",
    "            secondCorpus, domain2 = second\n",
    "        corpusPairData = (firstCorpus, secondCorpus, domain1, domain2)\n",
    "        corporaSets.append(corpusPairData)\n",
    "#     print(corporaSets)\n",
    "    #this was added to sort the lists by domain of the first, then by the first corpus name, then the second.\n",
    "    #it is placed in reverse order simply because if it was put in regular order, the largest of the trials would be first\n",
    "    #sorting in reverse will (loosely) make the smaller trials run first, while having no impact on the ability to obtain all results\n",
    "    sortedPermutations = sorted(corporaSets, key = lambda x: (x[2], x[0], x[1]), reverse = True)\n",
    "    \n",
    "    #this for loop adds the trials where the corpus is trained and tested on itself\n",
    "    for entry in possibleChoices:\n",
    "        firstCorpus, domain1 = entry\n",
    "        secondCorpus, domain2 = entry\n",
    "        corpusPairData = (firstCorpus, secondCorpus, domain1, domain2)\n",
    "        sortedPermutations.append(corpusPairData)\n",
    "        \n",
    "    #This loop adds the combinations relating to the ALl-VS trials\n",
    "    for entry in possibleChoices:\n",
    "        firstCorpus, domain1 = (None, None)\n",
    "        secondCorpus, domain2 = entry\n",
    "        corpusPairData = (firstCorpus, secondCorpus, domain1, domain2)\n",
    "        sortedPermutations.append(corpusPairData)\n",
    "    for entry in sortedPermutations:\n",
    "        print(entry)\n",
    "    powerSetCondensedGood = []\n",
    "    powerSetCondensedBad = []\n",
    "    powerSetCondensed = []\n",
    "    for entry in powerSet:\n",
    "#         if len(entry) < 3 and len(entry) > 0:\n",
    "            if len(entry) == 2:\n",
    "                domainMatch = entry[0][1]\n",
    "                appendGood = True\n",
    "                for corpus, domain in entry:\n",
    "                    if domain != domainMatch:\n",
    "                        appendGood = False\n",
    "                if(appendGood):\n",
    "                    print(\"good entry\",entry)\n",
    "                    powerSetCondensedGood.append(entry)\n",
    "                else:\n",
    "                    print(\"bad entry\",entry)\n",
    "                    powerSetCondensedBad.append(entry)\n",
    "            if len(entry) < 3 and len(entry) > 0:\n",
    "                powerSetCondensed.append(entry)\n",
    "    print(\"powerSetCondensed length: \",len(powerSetCondensed))\n",
    "    print(\"powerSetCondensedGood length: \",len(powerSetCondensedGood))\n",
    "    print(\"powerSetCondensedGood: \", powerSetCondensedGood)\n",
    "    print(\"powerSetCondensedBad length: \",len(powerSetCondensedBad))\n",
    "    print(\"powerSetCondensedBad: \", powerSetCondensedBad)\n",
    "    print(powerSetCondensedGood[0])\n",
    "    \n",
    "#     example1 = ('ssec', 'tec', 'tweets', 'tweets')\n",
    "#     example2 = (None, 'affectivetext', None, 'headlines')\n",
    "    for entry in sortedPermutations:\n",
    "        print(entry)\n",
    "        (first, second, domain1, domain2) = entry\n",
    "        print(\"Getting data\")\n",
    "        jsonfile = \"unified-dataset.jsonl\"\n",
    "#         first = example2[0] #use first = None if you want to do ALl vs\n",
    "#         second = example2[1]\n",
    "    #     first = \"isear\" #use first = None if you want to do ALl vs\n",
    "    #     second = \"crowdflower\"\n",
    "\n",
    "        output = \".\"\n",
    "        debug = True\n",
    "        forceMulti = False\n",
    "        isAllVS = False\n",
    "        if first == None:\n",
    "            isAllVS = True\n",
    "\n",
    "        training_data, testing_data = get_train_test(jsonfile, first,second)\n",
    "        firstCLF, secondCLF = ([\"multi\", \"multi\"] if forceMulti else get_clf_mode(training_data, testing_data))\n",
    "        mode = \"multi\" if \"multi\" in [firstCLF, secondCLF] else \"single\"\n",
    "\n",
    "        print(\"Detected mode: {}...\".format(mode))\n",
    "        print(len(training_data), len(testing_data))\n",
    "        print(\"Getting wordlist...\")\n",
    "        if debug:\n",
    "            wordlist = getTop5000Words(training_data)\n",
    "        else:\n",
    "            wordlist = getTop5000Words(training_data)\n",
    "        print(\"Getting emotions\")\n",
    "        labels = get_labels(training_data, testing_data, mode=mode)\n",
    "        print(labels)\n",
    "        print(\"Making arrays\")\n",
    "        print(\"checking for save files\")\n",
    "        if(first == None):\n",
    "            first = \"all-vs\"\n",
    "        train_xNPFileName = first + \"_\" + second + \"train_xNP\" +\".npy\"\n",
    "        train_yNPFileName = first + \"_\" + second + \"train_yNP\" +\".npy\"\n",
    "        test_xNPFileName = first + \"_\" + second + \"test_xNP\" +\".npy\"\n",
    "        test_yNPFileName = first + \"_\" + second + \"test_yNP\" +\".npy\"\n",
    "\n",
    "        if(path.exists(train_xNPFileName) \n",
    "           and path.exists(train_yNPFileName)\n",
    "           and path.exists(test_xNPFileName)\n",
    "           and path.exists(test_yNPFileName)):\n",
    "            print('saved train_xNP as', train_xNPFileName)\n",
    "            print('saved train_yNP as', train_yNPFileName)\n",
    "            print('saved test_xNP as', test_xNPFileName)\n",
    "            print('saved test_yNP as', test_yNPFileName)\n",
    "            print(\"loading from np\")\n",
    "            train_x = np.load(train_xNPFileName)\n",
    "            train_y = np.load(train_yNPFileName)\n",
    "            test_x = np.load(test_xNPFileName)\n",
    "            test_y = np.load(test_yNPFileName)\n",
    "            train_xNPSize = (train_x.nbytes)/1000000\n",
    "            train_yNPSize = (train_y.nbytes)/1000000\n",
    "            test_xNPSize = (test_x.nbytes)/1000000\n",
    "            test_yNPSize = (test_y.nbytes)/1000000\n",
    "            print(\"loaded directly from NP.load\")\n",
    "            print(\"train_xNPSize (text) size loaded:\", train_xNPSize,\"megabytes\")\n",
    "            print(\"train_yNPSize (labels) size loaded:\", train_yNPSize,\"megabytes\")\n",
    "            print(\"test_xNPSize (text) size loaded:\", test_xNPSize,\"megabytes\")\n",
    "            print(\"test_yNPSize (labels) size loaded:\", test_yNPSize,\"megabytes\")\n",
    "        else:\n",
    "            train_x, train_y, test_x, test_y, sizes = make_arrays(training_data, testing_data, wordlist, labels, mode, isAllVS)\n",
    "            train_xSize, train_ySize, test_xSize, test_ySize = sizes\n",
    "            if any(not part.size for part in [train_x, train_y, test_x, test_y]):\n",
    "                print(\"Train or test empty. Did you misspell the dataset name?\")\n",
    "                continue\n",
    "            #             sys.exit(1)\n",
    "            print(\"saving NP arrays\")\n",
    "            np.save(train_xNPFileName, train_x)\n",
    "            np.save(train_yNPFileName, train_y)\n",
    "            np.save(test_xNPFileName, test_x)\n",
    "            np.save(test_yNPFileName, test_y)\n",
    "            print(\"NP arrays saved\")\n",
    "        \n",
    "        print(\"Initializing classifier\")\n",
    "        trainClassifier = True\n",
    "        if debug:\n",
    "            classifierName = \"RandomForestClassifier\"\n",
    "            print(\"Searching for a \", classifierName)\n",
    "            classiferSaveFile = first+\"_\"+second+classifierName+\".pkl\"\n",
    "            print(path.exists(classiferSaveFile))\n",
    "            if(path.exists(classiferSaveFile)):\n",
    "                trainClassifier = False\n",
    "                print(\"Loading classifier from file\")\n",
    "                classifier = joblib.load(classiferSaveFile)\n",
    "                print(\"classifier loaded successfully\")\n",
    "            else:\n",
    "                print(\"file not found, creating new classifier\")\n",
    "                classifier = RandomForestClassifier()\n",
    "        elif mode == \"single\":\n",
    "            classifierName = \"LogisticRegressionCV\"\n",
    "            print(\"Searching for a \", classifierName)\n",
    "            classiferSaveFile = first+\"_\"+second+classifierName+\".pkl\"\n",
    "            print(path.exists(classiferSaveFile))\n",
    "            if(path.exists(classiferSaveFile)):\n",
    "                trainClassifier = False\n",
    "                print(\"Loading classifier from file\")\n",
    "                classifier = joblib.load(classiferSaveFile)\n",
    "                print(\"classifier loaded successfully\")\n",
    "            else:\n",
    "                print(\"file not found, creating new classifier\")\n",
    "                classifier = LogisticRegressionCV(\n",
    "                    cv=10,\n",
    "                    penalty=\"l2\",\n",
    "                    fit_intercept=True,\n",
    "                    solver=\"sag\",\n",
    "                    scoring=\"f1\",\n",
    "                    refit=True,\n",
    "                    # n_jobs=-1,\n",
    "                    class_weight=\"balanced\",\n",
    "                )\n",
    "        else:\n",
    "            classifierName = \"OneVsRestClassifier\"\n",
    "            print(\"Searching for a \", classifierName)\n",
    "            classiferSaveFile = first+\"_\"+second+classifierName+\".pkl\"\n",
    "            print(path.exists(classiferSaveFile))\n",
    "            if(path.exists(classiferSaveFile)):\n",
    "                trainClassifier = False\n",
    "                print(\"Loading classifier from file\")\n",
    "                classifier = joblib.load(classiferSaveFile)\n",
    "                print(\"classifier loaded successfully\")\n",
    "            else:\n",
    "                print(\"file not found, creating new classifier\")\n",
    "                classifier = OneVsRestClassifier(\n",
    "                    LogisticRegressionCV(\n",
    "                        cv=10,\n",
    "                        penalty=\"l2\",\n",
    "                        fit_intercept=True,\n",
    "                        solver=\"sag\",\n",
    "                        scoring=\"f1\",\n",
    "                        refit=True,\n",
    "                        class_weight=\"balanced\",\n",
    "                        tol = 0.1,\n",
    "                    ),\n",
    "                    n_jobs=-1,\n",
    "                )\n",
    "        if(trainClassifier):\n",
    "            print(\"this is the classifierName: \", classifierName)\n",
    "            print(\"Training...\")\n",
    "            print(\"train_x (text) size:\", (train_x.nbytes)/1000000,\"megabytes\")\n",
    "            print(\"train_y (labels) size:\", (train_y.nbytes)/1000000,\"megabytes\")\n",
    "            print(\"train_x (text) length:\", len(train_x))\n",
    "            print(\"train_y (labels) length:\", len(train_y))\n",
    "            print(train_x[:5])\n",
    "            print(train_y[:5])\n",
    "\n",
    "            classifier.fit(train_x, train_y)\n",
    "            print(\"finished training, classifier size:\", sys.getsizeof(classifier)/1000000,\"megabytes\")\n",
    "        print(\"Predicting...\")\n",
    "        if first == \"multi\" and second == \"single\":\n",
    "            predict_y = classifier.predict_proba(test_x)\n",
    "            helper = np.zeros_like(predict_y)\n",
    "            helper[range(len(predict_y)), predict_y.argmax(1)] = 1\n",
    "            predict_y = helper\n",
    "        else:\n",
    "            predict_y = classifier.predict(test_x)\n",
    "\n",
    "        print(\"Analysing...\")\n",
    "\n",
    "        analyse_results(\n",
    "            test_y,\n",
    "            predict_y,\n",
    "            labels,\n",
    "            testing_data,\n",
    "            first,\n",
    "            second,\n",
    "            output,\n",
    "            mode,  # TODO\n",
    "        )\n",
    "        if(path.exists(classiferSaveFile)):\n",
    "            print(\"classifier already saved\")\n",
    "        else:\n",
    "    #         classiferSaveFile = first+\"_\"+second+classifierName+\".pkl\"\n",
    "            print(\"classiferSaveFile: \", classiferSaveFile)\n",
    "            joblib.dump(classifier, classiferSaveFile)\n",
    "            print(\"Saved Successfully\")\n",
    "        total, used, free = getHardDriveSpaceLeft()\n",
    "        if(free < 10):\n",
    "            sys.exit(\"Error: less than 10 gb remaining on disk\")\n",
    "        print(\"-----------------------------------------------------------------------------------------\")\n",
    "print(\"End of program!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "import regex as re\n",
    "import sys\n",
    "import os\n",
    "import json\n",
    "import random\n",
    "import math\n",
    "import operator as op\n",
    "import docopt\n",
    "import numpy as np\n",
    "import os.path\n",
    "import itertools\n",
    "from os import path\n",
    "from tqdm import tqdm\n",
    "from scipy.spatial.distance import jensenshannon, cosine\n",
    "from numpy import asarray\n",
    "import statistics \n",
    "from collections import Counter, defaultdict, namedtuple\n",
    "\n",
    "from sklearn.linear_model import LogisticRegressionCV\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, precision_recall_fscore_support\n",
    "from sklearn.metrics.pairwise import cosine_similarity, chi2_kernel\n",
    "from scipy.spatial import distance\n",
    "import joblib\n",
    "import shutil\n",
    "\n",
    "Report = namedtuple(\"Report\", [\"precision\", \"recall\", \"accuracy\", \"f1\", \"tp\", \"tn\", \"fp\", \"fn\"])\n",
    "JSON = \"unified-dataset.jsonl\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "#this method is used to get the classifier mode and decide whether to single-label or multi-label classification\n",
    "#this method comes from the original authors and is kept to replicate their results\n",
    "def get_clf_mode(train, test):\n",
    "    first = \"single\"\n",
    "    for example in train:\n",
    "        if example.get(\"labeled\", \"multi\") == \"multi\":\n",
    "            first = \"multi\"\n",
    "    print(first)\n",
    "    for example in test:\n",
    "        if example.get(\"labeled\", \"multi\") == \"multi\":\n",
    "            return first, \"multi\"\n",
    "    print(\"oof\")\n",
    "    return first, \"single\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "#This methods is used to extract the training and testing data from the unified corpus json.\n",
    "#The unified corpus json must be produced using the authors original code\n",
    "#this version is only used in getting the benchmarks for the previous paper\n",
    "#this version takes the jsonfile, the name of the train file and the name of the test file as parameters\n",
    "def get_train_test(jsonfile, train, test):\n",
    "    print(\"get_train_test param:\")\n",
    "    print(\"json \", jsonfile)\n",
    "    print(\"train \", train)\n",
    "    print(\"test \", test)\n",
    "    same = test in train.split(\",\") #used if train and test corpus are same\n",
    "    training, testing = [], []\n",
    "    count1 = 0\n",
    "    count2 = 0\n",
    "    count3 = 0\n",
    "    count4 = 0\n",
    "    with open(jsonfile) as f:\n",
    "        for line in f:\n",
    "            data = json.loads(line)\n",
    "            if(data[\"source\"] == test):\n",
    "                count1 += 1\n",
    "            if(data[\"source\"] != test):\n",
    "                count2 += 1\n",
    "            if((train == None or train == \"all-vs\") and data[\"source\"] != test):\n",
    "                count3 += 1\n",
    "                training.append(data)\n",
    "            elif data[\"source\"] == test:\n",
    "                count4 += 1\n",
    "                testing.append(data)\n",
    "            elif(data[\"source\"] in train.split(\",\")):\n",
    "                count3 += 1\n",
    "                training.append(data)\n",
    "    print(\"there were \", count1, \" entries that were in test and \", count2, \"that were not in test\",\n",
    "          \"and \", count3, \" that were in train\")\n",
    "    print(\"test was appended \", count4, \" times\")\n",
    "    if same:\n",
    "        training, testing = hacky_train_test_split(testing, train_size=0.8, first=train, second=test)\n",
    "        print(\"revised\", \"there were \", len(testing), \" entries that were in test and \", len(training), \" that were in train\")\n",
    "    return training, testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "#this method stays as is from the original paper\n",
    "def get_labels(train, test, operation=op.and_, mode=\"multi\"):\n",
    "    \"\"\"Return a list of the emotional intersection of two sources.\"\"\"\n",
    "    emotions = set()\n",
    "    if mode == \"single\":\n",
    "        emotions.add(\"noemo\")\n",
    "    train_emotions = set(\n",
    "        emotion\n",
    "        for data in train\n",
    "        for emotion in data[\"emotions\"]\n",
    "        if data[\"emotions\"][emotion] is not None\n",
    "    )\n",
    "    # print(train_emotions)\n",
    "    test_emotions = set(\n",
    "        emotion\n",
    "        for emotion in test[0][\"emotions\"]\n",
    "        if test[0][\"emotions\"][emotion] is not None\n",
    "    )\n",
    "    # print(test_emotions)\n",
    "    return list(emotions | operation(train_emotions, test_emotions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "#expects corpus list in data form\n",
    "#returns compatible labels\n",
    "def getMatchingLabels(corpora):\n",
    "    emotionSetList = []\n",
    "    for corpus in corpora:\n",
    "        emoSet = set(emotion for data in corpus for emotion in data[\"emotions\"] if data[\"emotions\"][emotion] is not None)\n",
    "        emotionSetList.append(emoSet)\n",
    "    intersectionSet = set.intersection(*emotionSetList)\n",
    "    print(intersectionSet)\n",
    "    return intersectionSet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "#this method stays as is from the original paper\n",
    "def get_emotion(emovals, labels, emotions, mode=\"multi\"):\n",
    "#     print(\"get emotion mode \", mode)\n",
    "#     print(\"emovals \",emovals)\n",
    "#     print(\"labels \",labels)\n",
    "#     print(\"emotions \",emotions)\n",
    "    if mode == \"single\":\n",
    "        truthy = len(list(filter(bool, emovals.values())))\n",
    "        if truthy == 1:\n",
    "            emotion = [v for v in emovals if emovals[v]][0]\n",
    "        elif truthy == 0:\n",
    "            emotion = \"noemo\"\n",
    "        else:\n",
    "            raise ValueError(\"Dataset marked as 'single' contains multiple emotions\")\n",
    "        return emotions.get(emotion, emotions.get(\"noemo\"))\n",
    "    else:\n",
    "        el = [int((emovals[label] or 0) > 0.1) for label in labels]\n",
    "        return np.array(el)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "#this method stays as is from the original paper\n",
    "def get_vector(text, wordlist):\n",
    "    tokens = set(tokenize(text))\n",
    "#     print(tokens)\n",
    "    return [1 if word in tokens else 0 for word in wordlist]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "#The comment below was left by the original authors. As you can see, their results were unable to use the full bag of words\n",
    "# this is bad. memory error for all_vs (too many words...)\n",
    "def get_wordlist(dataset):\n",
    "    \"\"\"Get a bag of words from a dataset.\"\"\"\n",
    "    bag = set()\n",
    "    for data in dataset:\n",
    "        bag.update({token for token in tokenize(data[\"text\"])})\n",
    "    return list(bag)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "#bag of word limit of 5000 is kept from the original authors to match their results\n",
    "def getTop5000Words(dataset):\n",
    "    \"\"\"Get a bag of words from a dataset.\"\"\"\n",
    "    bag = Counter()\n",
    "    for data in dataset:\n",
    "        bag.update({token for token in tokenize(data[\"text\"])})\n",
    "    print(\"bag size\", len(bag))\n",
    "#     print(\"bag\", bag)\n",
    "    out = list(map(op.itemgetter(0), bag.most_common(5000)))\n",
    "#     print(\"this is the output\", out)\n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Taken from my own Ling 413 final project, I was going to run trials with lemmatization and other tokenization\n",
    "#but by the time I was far enough in the project to do this, I didn't have time to run trials with this\n",
    "# def cleanDataLemma(dataset):\n",
    "#     taggedDataset = nltk.pos_tag(dataset)\n",
    "#     filteredString = []\n",
    "#     for token, tag in taggedDataset:\n",
    "#         for char in token:\n",
    "#             if char in string.punctuation:\n",
    "#                 token = token.replace(char,\"\") #remove punctuation\n",
    "#         if (token not in stopWords):\n",
    "#             lemmatizedToken = \"\"\n",
    "#             if tag[0] == 'N':\n",
    "#                 lemmatizedToken = lemmatizer.lemmatize(token, 'n')\n",
    "#             elif tag[0] == 'V':\n",
    "#                 lemmatizedToken = lemmatizer.lemmatize(token, 'v')\n",
    "#             else:\n",
    "#                 lemmatizedToken = token\n",
    "#             if len(lemmatizedToken) > 2:\n",
    "#                 filteredString.append(lemmatizedToken)\n",
    "#     return filteredString"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "#tokenization is kept the same so that performance results match the ones used in the paper as closely as possible\n",
    "#if there is improvement, it should be because of my changes\n",
    "def tokenize(text):\n",
    "    return re.findall(r\"\\p{L}+\", text.lower())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getWordCountsByEmotion(dataset, emotionLabels):\n",
    "    emotionCounts = []\n",
    "    print(\"emotions\")\n",
    "    for emotion in emotionLabels:\n",
    "        emotionDict = Counter()\n",
    "        for data in dataset:\n",
    "#             if data[\"emotions\"][emotion] == 1:\n",
    "#                 print(emotion)\n",
    "#                 print(data)\n",
    "#                 print(data[\"emotions\"][emotion])\n",
    "            emotionDict.update({token for token in tokenize(data[\"text\"]) if data[\"emotions\"][emotion] == 1})\n",
    "        print(len(emotionDict))\n",
    "        emotionCounts.append(emotionDict)\n",
    "    return emotionCounts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getTokenFrequency(dataset):\n",
    "    token2DocFreq = {}\n",
    "    for data in dataset:\n",
    "        tempDict = {}\n",
    "        for word in data:\n",
    "            if word not in tempDict:\n",
    "                tempDict[word] = 1\n",
    "        for key, value in tempDict.items():\n",
    "            if key in token2DocFreq:\n",
    "                token2DocFreq[key] += value\n",
    "            else:\n",
    "                token2DocFreq[key] = value\n",
    "    return token2DocFreq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getTokenizedCorpusTextPair(corpus1, corpus2):\n",
    "    with open(JSON) as f:\n",
    "        for line in f:\n",
    "            data = json.loads(line)\n",
    "            if data[\"source\"] in corporaNameList:\n",
    "                corpus1Text.append(tokenize(data[\"text\"]))\n",
    "                corpus1Data.append(data)\n",
    "            if data[\"source\"] in corporaNameList:\n",
    "                corpus2Text.append(tokenize(data[\"text\"]))\n",
    "                corpus2Data.append(data)\n",
    "    corporaData = [corpus1Data,corpus2Data]\n",
    "    return corpus1Text, corpus2Text, corporaData"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def getNormalizedFreq(tokenFreq):\n",
    "# def getNormalizedFreq(corpus):\n",
    "#     newCorpus = []\n",
    "#     for entry in corpus:\n",
    "#         newCorpus.append(tokenize(entry))\n",
    "#     tokenFreq = getTokenFrequency(newCorpus)\n",
    "#     print(tokenFreq.items())\n",
    "#     print(\"freq values\", tokenFreq)\n",
    "    newTokenFreq = tokenFreq.copy()\n",
    "    for item, freq in newTokenFreq.items():\n",
    "        if(freq == 0):\n",
    "            newTokenFreq[item] = 0\n",
    "        else:\n",
    "            newTokenFreq[item] = 1 + math.log10(freq)\n",
    "#     print(\"log weighted values\", tokenFreq)\n",
    "    docLength = 0\n",
    "    for freq in newTokenFreq.values():\n",
    "        docLength += freq*freq\n",
    "    docLength = math.sqrt(docLength)\n",
    "#     print(\"doclength\", docLength)\n",
    "    for item, freq in newTokenFreq.items():\n",
    "        newTokenFreq[item] = freq/docLength\n",
    "    # logFreq = freq for freq in math.log() \n",
    "#     print(\"normalized\")\n",
    "#     print(tokenFreq)\n",
    "    return newTokenFreq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getCosineSimilarityFromTokenFreq(tokenFreq1, tokenFreq2):\n",
    "    normFreq1 = getNormalizedFreq(tokenFreq1)\n",
    "    normFreq2 = getNormalizedFreq(tokenFreq2)\n",
    "    cosineSum = 0\n",
    "    normFreq1.items()\n",
    "    print(\"length 1\", len(normFreq1))\n",
    "    print(\"length 2\", len(normFreq2))\n",
    "    intersection = normFreq1.keys() & normFreq2.keys()\n",
    "    #only loop intersection because unshared values will be multiplied by 0 anyway\n",
    "    for item in intersection:\n",
    "#         if normFreq1[item] < 0 or normFreq2[item] < 0 :\n",
    "#             print(\"negative?\", item, normFreq1[item],normFreq2[item])\n",
    "#             sys.exit()\n",
    "#         print(item)\n",
    "#         print(normFreq1[item])\n",
    "#         print(normFreq2[item])\n",
    "        x = normFreq1[item] * normFreq2[item]\n",
    "        cosineSum += x\n",
    "    return cosineSum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getCosineSimilarityFromCorpus(corpus1,corpus2):\n",
    "    corpus1Text, corpus2Text, corpus1Data, corpus2Data = getTokenizedCorpusTextPair(corpus1, corpus2)\n",
    "    emotionLabels = getMatchingLabels(corporaData)\n",
    "    tokenFreq1 = getTokenFrequency(corpus1Text)\n",
    "    tokenFreq2 = getTokenFrequency(corpus2Text)\n",
    "    sim = getCosineSimilarityFromTokenFreq(tokenFreq1, tokenFreq2)\n",
    "    return sim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getCosineSimilarityFromCorpusEmotions(corpus1,corpus2):\n",
    "    corpus1Text, corpus2Text, corpus1Data, corpus2Data = getTokenizedCorpusTextPair(corpus1, corpus2)\n",
    "    emotionLabels = getMatchingLabels(corporaData)\n",
    "    emotionDicts1 = getTop5000WordsByEmotion(corpus1Data, words, emotionLabels)\n",
    "    emotionDicts2 = getTop5000WordsByEmotion(corpus2Data, words, emotionLabels)\n",
    "    for emotion in range(len(emotionLabels)):\n",
    "        sim = getCosineSimilarityFromTokenFreq(emotionDicts1[emotion], emotionDicts2[emotion])\n",
    "        print(sim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "#averages the values the come from jensenshannon into a single value\n",
    "def getJensenShannonFromNPArrays(np1,np2):\n",
    "    js_pq = jensenshannon(np1, np2)\n",
    "    print(js_pq)\n",
    "    sumJS = 0\n",
    "    length = len(js_pq)\n",
    "    for x in js_pq:\n",
    "        if math.isnan(x): #assume nan values should be interpretted as 0\n",
    "            sumJS += 0\n",
    "        else:\n",
    "            sumJS += x\n",
    "    js = sumJS/length\n",
    "    return js"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "False\n",
      "False\n",
      "False\n",
      "True\n",
      "False\n",
      "(4868, 5000)\n",
      "(4868, 5000)\n",
      "(4868, 5000)\n",
      "(7666, 5000)\n",
      "(4868, 5000)\n",
      "[0. 0. 0. ... 0. 0. 0.]\n",
      "0.0\n",
      "[0.65300289 0.71217394 0.65470119 ...        nan 0.83255461        nan]\n",
      "0.48101544698034715\n"
     ]
    }
   ],
   "source": [
    "#test code for understanding how NP arrays are distributed\n",
    "arr1 = np.load(\"ssec_emotion-causetrain_xNP.npy\")\n",
    "arr2 = np.load(\"ssec_grounded_emotionstrain_xNP.npy\")\n",
    "arr3 = np.load(\"isear_ssectest_xNP.npy\")\n",
    "arr4 = np.load(\"isear_ssectrain_xNP.npy\")\n",
    "arr5 = np.load(\"ssec_iseartest_xNP.npy\")\n",
    "arr5 = np.load(\"ssec_iseartrain_xNP.npy\")\n",
    "print(np.array_equal(arr1,arr2))\n",
    "print(np.array_equal(arr2,arr3))\n",
    "print(np.array_equal(arr3,arr4))\n",
    "print(np.array_equal(arr4,arr5))\n",
    "print(np.array_equal(arr1,arr5))\n",
    "print(np.array_equal(arr3,arr5))\n",
    "print(arr1.shape)\n",
    "print(arr2.shape)\n",
    "print(arr3.shape)\n",
    "print(arr4.shape)\n",
    "print(arr5.shape)\n",
    "print(getJensenShannonFromNPArrays(arr1,arr2))\n",
    "print(getJensenShannonFromNPArrays(arr2,arr3))\n",
    "# print(getJensenShannonFromNPArrays(arr4,arr5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def getChiSquare(observed,calculated):\n",
    "#     chiSquare = ((observed - calculated)**2)/calculated\n",
    "#     return chiSquare"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Calculates Chi Square, or at least it would have if I had finished implementing\n",
    "#see paper for details on why it was not implemented\n",
    "# def getChiSquareFromTokenFreq(tokenFreq1, tokenFreq2):\n",
    "# columnTotal1 = sum(tokenFreq1.values())\n",
    "# columnTotal2 = sum(tokenFreq2.values())\n",
    "# intersection = tokenFreq1.keys() & tokenFreq2.keys()\n",
    "# rowTotals = {key: tokenFreq1.get(key, 0) + tokenFreq2.get(key, 0)\n",
    "#           for key in set(dict1) | set(dict2)}\n",
    "# grandTotal = columnTotal1 + columnTotal2\n",
    "# chiSquareTotal = 0\n",
    "# calculated1 = []\n",
    "# calculated2 = []\n",
    "# for item, rowTotal in rowTotals.items():\n",
    "#     calculated1[item] = (rowTotal * columnTotal1) / grandTotal\n",
    "#     calculated2[item] = (rowTotal * columnTotal2) / grandTotal\n",
    "# for item, value in calculated.items():\n",
    "#     getChiSquare(observed,calculated[item])\n",
    "#     calculated[item]\n",
    "#     return js"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loaded data\n",
      "bag size 17756\n",
      "{'joy', 'disgust', 'fear', 'sadness', 'anger'}\n",
      "emotions\n",
      "6938\n",
      "7353\n",
      "6707\n",
      "8349\n",
      "8864\n",
      "emotions\n",
      "2527\n",
      "3401\n",
      "3118\n",
      "2523\n",
      "3339\n",
      "length 1 6938\n",
      "length 2 2527\n",
      "joy 0.44398907860576825\n",
      "length 1 7353\n",
      "length 2 3401\n",
      "disgust 0.45165658636487693\n",
      "length 1 6707\n",
      "length 2 3118\n",
      "fear 0.43688992382789676\n",
      "length 1 8349\n",
      "length 2 2523\n",
      "sadness 0.4538342791036568\n",
      "length 1 8864\n",
      "length 2 3339\n",
      "anger 0.46229743778369375\n",
      "length 1 12661\n",
      "length 2 8888\n",
      "length 1 8888\n",
      "length 2 12661\n",
      "0.5107359175632193\n",
      "0.5107359175632193\n"
     ]
    }
   ],
   "source": [
    "#This is a validation of my corpus similarity metrics\n",
    "corpus1 = \"ssec\"\n",
    "corpus1Data = []\n",
    "corpus1Text = []\n",
    "corpus2 = \"isear\"\n",
    "corpus2Data = []\n",
    "corpus2Text = []\n",
    "with open(JSON) as f:\n",
    "    for line in f:\n",
    "        data = json.loads(line)\n",
    "        if data[\"source\"] == corpus1:\n",
    "            corpus1Text.append(tokenize(data[\"text\"]))\n",
    "            corpus1Data.append(data)\n",
    "        if data[\"source\"] == corpus2:\n",
    "            corpus2Text.append(tokenize(data[\"text\"]))\n",
    "            corpus2Data.append(data)\n",
    "print(\"loaded data\")\n",
    "combinedCorpus = corpus1Data + corpus2Data\n",
    "combinedCorpusText = corpus1Text + corpus2Text\n",
    "# tokenFreq = getTokenFrequency(corpus1Text)\n",
    "# print(\"tokenFreq\", tokenFreq)\n",
    "words = getTop5000Words(combinedCorpus)\n",
    "corporaData = [corpus1Data,corpus2Data]\n",
    "emotionLabels = list(getMatchingLabels(corporaData))\n",
    "emotions1 = getWordCountsByEmotion(corpus1Data, emotionLabels)\n",
    "# print(emotions1)\n",
    "emotions2 = getWordCountsByEmotion(corpus2Data, emotionLabels)\n",
    "# print(emotions2)\n",
    "for emotion in range(len(emotionLabels)):\n",
    "    sim = getCosineSimilarityFromTokenFreq(emotions1[emotion], emotions2[emotion])\n",
    "    print(emotionLabels[emotion], sim)\n",
    "fullCorpus1Words = getTokenFrequency(corpus1Text)\n",
    "fullCorpus2Words = getTokenFrequency(corpus2Text)\n",
    "sim1 = getCosineSimilarityFromTokenFreq(fullCorpus1Words, fullCorpus2Words)\n",
    "sim2 = getCosineSimilarityFromTokenFreq(fullCorpus2Words, fullCorpus1Words)\n",
    "print(sim1)\n",
    "print(sim2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# import gensim\n",
    "# import numpy as np\n",
    "# from nltk.tokenize import word_tokenize\n",
    "# print(corpus1Text[:5])\n",
    "# gen_docs = corpus1Text[:5]\n",
    "# dictionary = gensim.corpora.Dictionary(gen_docs)\n",
    "# # print(dictionary.token2id)\n",
    "# corpus = [dictionary.doc2bow(gen_doc) for gen_doc in gen_docs]\n",
    "# tf_idf = gensim.models.TfidfModel(corpus)\n",
    "# for doc in tf_idf [corpus]:\n",
    "#     print([[dictionary[id], np.around(freq, decimals=2)] for id, freq in doc])\n",
    "# sims = gensim.similarities.Similarity(\"../Ling506TermProject/\",tf_idf[corpus],\n",
    "#                                         num_features=len(dictionary))\n",
    "\n",
    "\n",
    "\n",
    "# file2_docs = [\"Mars is the fourth planet in our solar system.\",\n",
    "#         \"It is second-smallest planet in the Solar System after Mercury.\",\n",
    "#         \"Saturn is yellow planet.\"]\n",
    "# tf_idf = gensim.models.TfidfModel(corpus)\n",
    "\n",
    "# print(\"Number of documents:\",len(file2_docs))  \n",
    "# for line in file2_docs:\n",
    "#     query_doc = [w.lower() for w in word_tokenize(line)]\n",
    "#     query_doc_bow = dictionary.doc2bow(query_doc) #update an existing dictionary and create bag of words\n",
    "\n",
    "# # perform a similarity query against the corpus\n",
    "# query_doc_tf_idf = tf_idf[query_doc_bow]\n",
    "# # print(document_number, document_similarity)\n",
    "# print('Comparing Result:', sims[query_doc_tf_idf]) \n",
    "\n",
    "# sum_of_sims =(np.sum(sims[query_doc_tf_idf], dtype=np.float32))\n",
    "# print(sum_of_sims)\n",
    "\n",
    "# avg_sims = [] # array of averages\n",
    "\n",
    "\n",
    "# # for line in query documents\n",
    "# for line in file2_docs:\n",
    "#     # tokenize words\n",
    "#     query_doc = [w.lower() for w in word_tokenize(line)]\n",
    "#     # create bag of words\n",
    "#     query_doc_bow = dictionary.doc2bow(query_doc)\n",
    "#     # find similarity for each document\n",
    "#     query_doc_tf_idf = tf_idf[query_doc_bow]\n",
    "#     # print (document_number, document_similarity)\n",
    "#     print('Comparing Result:', sims[query_doc_tf_idf]) \n",
    "#     # calculate sum of similarities for each query doc\n",
    "#     sum_of_sims =(np.sum(sims[query_doc_tf_idf], dtype=np.float32))\n",
    "#     # calculate average of similarity for each query doc\n",
    "#     avg = sum_of_sims / len(file_docs)\n",
    "#     # print average of similarity for each query doc\n",
    "#     print(f'avg: {sum_of_sims / len(file_docs)}')\n",
    "#     # add average values into array\n",
    "#     avg_sims.append(avg)  \n",
    "# # calculate total average\n",
    "# total_avg = np.sum(avg_sims, dtype=np.float)\n",
    "# # round the value and multiply by 100 to format it as percentage\n",
    "# percentage_of_similarity = round(float(total_avg) * 100)\n",
    "# # if percentage is greater than 100\n",
    "# # that means documents are almost same\n",
    "# if percentage_of_similarity >= 100:\n",
    "#     percentage_of_similarity = 100\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Bad attempt at using prebuilt functions for distancing\n",
    "# arr1 = np.load(\"ssec_emotion-causetrain_xNP.npy\")\n",
    "# arr2 = np.load(\"ssec_grounded_emotionstrain_xNP.npy\")\n",
    "# arr3 = np.load(\"isear_ssectest_xNP.npy\")\n",
    "# corpus1 = \"ssec\"\n",
    "# corpus1Data = []\n",
    "# corpus1Text = []\n",
    "# corpus2 = \"isear\"\n",
    "# corpus2Data = []\n",
    "# corpus2Text = []\n",
    "# with open(JSON) as f:\n",
    "#     for line in f:\n",
    "#         data = json.loads(line)\n",
    "#         if data[\"source\"] == corpus1:\n",
    "#             corpus1Data.append(data)\n",
    "#         if data[\"source\"] == corpus2:\n",
    "#             corpus2Data.append(data)\n",
    "# print(\"loaded data\")\n",
    "# words1 = getTop5000Words(corpus1Data)\n",
    "# print(words1)\n",
    "# words2 = getTop5000Words(corpus2Data)\n",
    "# for data in tqdm(corpus1Data):\n",
    "#     corpus1Text.append(get_vector(data[\"text\"], words1))\n",
    "# for data in tqdm(corpus1Data):\n",
    "#     corpus2Text.append(get_vector(data[\"text\"], words2))\n",
    "# # print(corpus1Text[:30])\n",
    "# print(np.array_equal(arr1,arr2))\n",
    "# print(np.array_equal(arr1,arr3))\n",
    "# print(cosine_similarity(arr1,arr3))\n",
    "# print(chi2_kernel(arr1,arr3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "#this method is modified to track \n",
    "def make_arrays(train, test, words, labels, mode=\"multi\", all_vs=False):\n",
    "    emotions = {label: x for x, label in enumerate(labels)}\n",
    "    print(\"emotions in make_arrays: \", emotions)\n",
    "    train_x, train_y, test_x, test_y = [], [], [], []\n",
    "    \n",
    "    print(\"train raw text: \", sys.getsizeof(train)/1000000)\n",
    "\n",
    "    for data in tqdm(train):\n",
    "        # Discard examples where we don't have all selected emotions\n",
    "        if (mode == \"single\" or all_vs or all(data[\"emotions\"][emo] is not None for emo in labels)):\n",
    "            train_y.append(get_emotion(data[\"emotions\"], labels, emotions, mode))\n",
    "            train_x.append(get_vector(data[\"text\"], words))\n",
    "    for data in tqdm(test):\n",
    "        test_y.append(get_emotion(data[\"emotions\"], labels, emotions, mode))\n",
    "        test_x.append(get_vector(data[\"text\"], words))\n",
    "\n",
    "    print(\"train_x length \", len(train_x))\n",
    "    print(\"train_x dimension of element \", len(train_x[0]))\n",
    "    train_xSize = sys.getsizeof(train_x)/1000000\n",
    "    train_ySize = sys.getsizeof(train_y)/1000000\n",
    "    train_xLength = len(train_x)\n",
    "    train_yLength = len(train_y)\n",
    "    print(\"train_x (text) size RAW:\", train_xSize,\"megabytes\")\n",
    "    print(\"train_y (labels) size RAW:\", train_ySize,\"megabytes\")\n",
    "    test_xSize = sys.getsizeof(test_x)/1000000\n",
    "    test_ySize = sys.getsizeof(test_y)/1000000\n",
    "    test_xLength = len(test_x)\n",
    "    test_yLength = len(test_y)\n",
    "    print(\"test_x (text) size RAW:\", test_xSize,\"megabytes\")\n",
    "    print(\"test_y (labels) size RAW:\", test_ySize,\"megabytes\")\n",
    "\n",
    "    train_x = np.array(train_x)\n",
    "    train_y = np.array(train_y)\n",
    "    test_x = np.array(test_x)\n",
    "    test_y = np.array(test_y)\n",
    "    train_xNPSize = (train_x.nbytes)/1000000\n",
    "    train_yNPSize = (train_y.nbytes)/1000000\n",
    "    test_xNPSize = (test_x.nbytes)/1000000\n",
    "    test_yNPSize = (test_y.nbytes)/1000000\n",
    "    \n",
    "    print(\"saved test_y\")\n",
    "    print(\"train_x Size stays the same\", train_xSize == train_xNPSize)\n",
    "    print(\"train_y Size stays the same\", train_ySize == train_yNPSize)\n",
    "    print(\"test_x Size stays the same\", test_xSize == test_xNPSize)\n",
    "    print(\"test_y Size stays the same\", test_ySize == test_yNPSize)\n",
    "    print(\"train_xNPSize (text) size:\", train_xNPSize,\"megabytes\")\n",
    "    print(\"train_yNPSize (labels) size:\", train_yNPSize,\"megabytes\")\n",
    "    print(\"test_xNPSize (text) size:\", test_xNPSize,\"megabytes\")\n",
    "    print(\"test_yNPSize (labels) size:\", test_yNPSize,\"megabytes\")\n",
    "    print(\"train_xNP length \", len(train_x))\n",
    "    print(\"train_xNP dimension of element \", train_x.ndim)\n",
    "    print(\"train_xNP size \", train_x.size)\n",
    "    sizes = train_xNPSize, train_yNPSize, test_xNPSize, test_yNPSize\n",
    "    return train_x, train_y, test_x, test_y, sizes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "#kept as part of classification definitions, prevents division by 0 errors\n",
    "def cheatydiv(x, y):\n",
    "    return math.nan if y == 0 else x / y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "#classification reporting is kept the same for simplicity (ie, no need to reinvent the wheel)\n",
    "def classification_report_own_single(test_y, predict_y, labels):\n",
    "    reports = {}\n",
    "    num2emo = {i: label for i, label in enumerate(labels)}\n",
    "    decisions = defaultdict(Counter)\n",
    "    for t, p in zip(test_y, predict_y):\n",
    "        decisions[t][p] += 1\n",
    "    for label in decisions:\n",
    "        tp = decisions[label][label]\n",
    "        fp = sum(decisions[x][label] for x in decisions if x != label)\n",
    "        tn = sum(\n",
    "            decisions[x][y]\n",
    "            for x in decisions\n",
    "            for y in decisions[x]\n",
    "            if x != label and y != label\n",
    "        )\n",
    "        fn = sum(decisions[label][y] for y in decisions[label] if y != label)\n",
    "        precision = tp / (tp + fp) if tp + fp else math.nan\n",
    "        recall = tp / (tp + fn) if tp + fn else math.nan\n",
    "        f1 = 2 * cheatydiv((precision * recall), (precision + recall))\n",
    "        accuracy = (tp + tn) / (tp + tn + fp + fn)\n",
    "        reports[num2emo[label]] = Report(precision, recall, accuracy, f1, tp, tn, fp, fn)\n",
    "    return reports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "#classification reporting is kept the same for simplicity (ie, no need to reinvent the wheel)\n",
    "def classification_report_own_multi(test_y, predict_y, labels):\n",
    "    reports = {}\n",
    "    num2emo = {i: label for i, label in enumerate(labels)}\n",
    "    emo2num = {label: i for i, label in enumerate(labels)}\n",
    "    decisions = defaultdict(Counter)\n",
    "    for label in labels:\n",
    "        tp = fp = tn = fn = 0\n",
    "        for t, p in zip(test_y, predict_y):\n",
    "            # decisions[t][p] += 1\n",
    "            tp += bool(t[emo2num[label]] and p[emo2num[label]])\n",
    "            fp += bool(p[emo2num[label]] and not t[emo2num[label]])\n",
    "            fn += bool(t[emo2num[label]] and not p[emo2num[label]])\n",
    "            tn += bool(not t[emo2num[label]] and not p[emo2num[label]])\n",
    "        precision = tp / (tp + fp) if tp + fp else math.nan\n",
    "        recall = tp / (tp + fn) if tp + fn else math.nan\n",
    "        f1 = 2 * cheatydiv((precision * recall), (precision + recall))\n",
    "        accuracy = (tp + tn) / (tp + tn + fp + fn)\n",
    "        reports[label] = Report(precision, recall, accuracy, f1, tp, tn, fp, fn)\n",
    "    return reports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "#classification reporting is kept the same for simplicity (ie, no need to reinvent the wheel)\n",
    "def analyse_results(test_y, predict_y, labels, test, first, second, output, mode):\n",
    "    print(\"analyse_results\")\n",
    "    prefix = f\"{first}_vs_{second}_{mode}\"\n",
    "    fprefix = output + \"/\" + prefix\n",
    "    with open(fprefix + \".txt\", \"w\", encoding=\"utf-8\") as f, open(fprefix + \".json\", \"w\") as g:\n",
    "        print(\"hello\")\n",
    "        prec, reca, f1, supp = precision_recall_fscore_support(\n",
    "            test_y, predict_y, pos_label=None, average=\"micro\"\n",
    "        )\n",
    "        accuracy = accuracy_score(test_y, predict_y)\n",
    "        scoreNameArray = [(prec, \"Precision\"),(reca, \"Recall\"),(f1, \"F1-score\"),(accuracy, \"Accuracy\")]\n",
    "        for score, name in scoreNameArray:\n",
    "            print(name, score, sep=\"\\t\", file=f)\n",
    "            print(name, score, sep=\"\\t\")\n",
    "            \n",
    "        # print(\"real:\", Counter(test_y), file=f)\n",
    "        # print(\"predicted:\", Counter(predict_y), file=f)\n",
    "        \n",
    "        print(test_y[:10], predict_y[:10], file=f)\n",
    "        emotions = {i: label for i, label in enumerate(labels)}\n",
    "        for text, real, predicted, _ in zip(test, test_y, predict_y, range(20)):\n",
    "            if mode == \"multi\" and np.array_equal(real, predicted):\n",
    "                continue\n",
    "            elif mode == \"single\" and real == predicted:\n",
    "                continue\n",
    "            print(text, \"=> predicted:\", predicted, \", truth:\", real, file=f)\n",
    "        if mode == \"multi\":\n",
    "            results = classification_report_own_multi(test_y, predict_y, labels)\n",
    "        elif mode == \"single\":\n",
    "            results = classification_report_own_single(test_y, predict_y, labels)\n",
    "        json.dump(\n",
    "            {\n",
    "                \"precision\": prec,\n",
    "                \"recall\": reca,\n",
    "                \"f1\": f1,\n",
    "                \"accuracy\": accuracy,\n",
    "                \"name\": prefix,\n",
    "                **{\n",
    "                    (emotion + \"_\" + metric): getattr(results[emotion], metric)\n",
    "                    for emotion in results\n",
    "                    for metric in Report._fields\n",
    "                },\n",
    "            },\n",
    "            g,\n",
    "        )\n",
    "        g.write(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "#used for benchmarking/validating the results of the authors, but not in the final version\n",
    "#method is kept here for documentation\n",
    "def hacky_train_test_split(training, train_size=0.8, first=None, second=None):\n",
    "    tra, tes = [], []\n",
    "    for example in training:\n",
    "        if example.get(\"split\") == \"train\" or example[\"source\"] != second:\n",
    "            tra.append(example)\n",
    "        elif example.get(\"split\") == \"test\":\n",
    "            tes.append(example)\n",
    "        else:\n",
    "            # don't try this at home\n",
    "            [tes, tra][random.random()<train_size].append(example)\n",
    "    return tra, tes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "#used for benchmarking/validating the results of the authors, but not in the final version\n",
    "#method is kept here for documentation\n",
    "def splitTrainAndTestData(training, train_size=0.8, first=None, second=None):\n",
    "    tra, tes = [], []\n",
    "    for example in training:\n",
    "        if example.get(\"split\") == \"train\" or example[\"source\"] != second:\n",
    "            tra.append(example)\n",
    "        elif example.get(\"split\") == \"test\":\n",
    "            tes.append(example)\n",
    "        else:\n",
    "            # don't try this at home\n",
    "            [tes, tra][random.random()<train_size].append(example)\n",
    "    return tra, tes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "#this method is used in my testing to generate the combinations that I use in my trials automation\n",
    "def getPowerset(s):\n",
    "    x = len(s)\n",
    "    masks = [1 << i for i in range(x)]\n",
    "    for i in range(1 << x):\n",
    "        yield [ss for mask, ss in zip(masks, s) if i & mask]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "#this method is used in my testing to generate the combinations that I use in my trials automation\n",
    "def getPermutations(s):\n",
    "    subsets = set()\n",
    "    for L in range(2, 3): #this \n",
    "        for subset in itertools.permutations(s, L):\n",
    "            subsets.add(subset)\n",
    "    return subsets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "#this method is simply in place to get a measure of hard drive space left on my computer\n",
    "def getHardDriveSpaceLeft():\n",
    "    total, used, free = shutil.disk_usage(\"/\")\n",
    "    total = (total // (2**30))\n",
    "    used = (used // (2**30))\n",
    "    free = (free // (2**30))\n",
    "    print(\"Total: %d GB\" % total)\n",
    "    print(\"Used: %d GB\" % used)\n",
    "    print(\"Free: %d GB\" % free)\n",
    "    return total, used, free"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getCrossCorpusValuesWithOrder(possibleChoices):\n",
    "    #gets the runtime values for cross corpus trials\n",
    "    #ordering will matter if using the original authors version\n",
    "    permutations = list(getPermutations(possibleChoices))\n",
    "    print(\"permutations length: \",len(permutations))\n",
    "#         print(permutations)\n",
    "    corporaSets = []\n",
    "    for choice in permutations:\n",
    "#         print(\"choice \", choice)\n",
    "        if(len(choice) == 2):\n",
    "#             print(\"pair\")\n",
    "            first, second = choice\n",
    "            firstCorpus, domain1 = first\n",
    "            secondCorpus, domain2 = second\n",
    "        corpusPairData = (firstCorpus, secondCorpus, domain1, domain2)\n",
    "        corporaSets.append(corpusPairData)\n",
    "    return(corporaSets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This method adds the combinations relating to the ALl-VS trials\n",
    "def getAllVsCorpusValues(possibleChoices):\n",
    "    corporaSets = []\n",
    "    for entry in possibleChoices:\n",
    "        firstCorpus, domain1 = (None, None)\n",
    "        secondCorpus, domain2 = entry\n",
    "        corpusPairData = (firstCorpus, secondCorpus, domain1, domain2)\n",
    "        corporaSets.append(corpusPairData)\n",
    "    return corporaSets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Gets the corpora pairs of the same domain\n",
    "#powerSet is specified because it is only used in the case with a powerSet where ordering does not matter\n",
    "#but hypothetically, you could put in any list of possible entries\n",
    "def getCorporaPairsOfSameDomain(powerSet, sizeBoundLower=1, sizeBoundUpper=3):\n",
    "    for entry in powerSet:\n",
    "#       if len(entry) < 3 and len(entry) > 0:\n",
    "        if len(entry) < sizeBoundUpper and len(entry) > sizeBoundLower:\n",
    "            domainMatch = entry[0][1]\n",
    "            shouldAppend = True\n",
    "            for corpus, domain in entry:\n",
    "                if domain != domainMatch:\n",
    "                    shouldAppend = False\n",
    "            if(shouldAppend):\n",
    "                powerSetCondensed.append(entry)\n",
    "    print(\"CorporaPairsOfSameDomain:\",len(powerSetCondensed))\n",
    "    return sameDomainCorporaPairs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "#this method adds the trials where the corpus is trained and tested on itself\n",
    "def getCorporaPairsWithItself(possibleChoices):\n",
    "    corporaSets = []\n",
    "    for entry in possibleChoices:\n",
    "        firstCorpus, domain1 = entry\n",
    "        secondCorpus, domain2 = entry\n",
    "        corpusPairData = (firstCorpus, secondCorpus, domain1, domain2)\n",
    "        corporaSets.append(corpusPairData)\n",
    "    return corporaSets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "def performTrialUsingCorpusPair(corpusPair, verifyResults):\n",
    "    print(\"------------------------------\",corpusPair,\"-------------------------------------------\")\n",
    "    (first, second, domain1, domain2) = corpusPair\n",
    "    print(\"Getting data\")\n",
    "    jsonfile = \"unified-dataset.jsonl\"\n",
    "    output = \".\"\n",
    "    debug = True\n",
    "    forceMulti = False\n",
    "    isAllVS = False\n",
    "    if first == None:\n",
    "        isAllVS = True\n",
    "    \n",
    "    if(verifyResults == False):\n",
    "        if(first == None):\n",
    "            first = \"all-vs\"\n",
    "        train_xNPFileName = first + \"_\" + second + \"train_xNP\" +\".npy\"\n",
    "        train_yNPFileName = first + \"_\" + second + \"train_yNP\" +\".npy\"\n",
    "        test_xNPFileName = first + \"_\" + second + \"test_xNP\" +\".npy\"\n",
    "        test_yNPFileName = first + \"_\" + second + \"test_yNP\" +\".npy\"\n",
    "        classifierName = \"RandomForestClassifier\"\n",
    "        classiferSaveFile = first+\"_\"+second+classifierName+\".pkl\"\n",
    "        filesValid = (path.exists(train_xNPFileName) \n",
    "                       and path.exists(train_yNPFileName)\n",
    "                       and path.exists(test_xNPFileName)\n",
    "                       and path.exists(test_yNPFileName)\n",
    "                       and path.exists(classiferSaveFile))\n",
    "        print(\"do pickle files exist?\", filesValid)\n",
    "        if(filesValid):\n",
    "            print(\"skipping trial\")\n",
    "            return\n",
    "    \n",
    "    \n",
    "    training_data, testing_data = get_train_test(jsonfile, first,second)\n",
    "    firstCLF, secondCLF = ([\"multi\", \"multi\"] if forceMulti else get_clf_mode(training_data, testing_data))\n",
    "    mode = \"multi\" if \"multi\" in [firstCLF, secondCLF] else \"single\"\n",
    "\n",
    "    print(\"Detected mode: {}...\".format(mode))\n",
    "    print(len(training_data), len(testing_data))\n",
    "    print(\"Getting wordlist...\")\n",
    "    if debug:\n",
    "        wordlist = getTop5000Words(training_data)\n",
    "    else:\n",
    "        wordlist = getTop5000Words(training_data)\n",
    "        # wordlist = get_wordlist(training_data)\n",
    "    print(\"Getting emotions\")\n",
    "    labels = get_labels(training_data, testing_data, mode=mode)\n",
    "    print(labels)\n",
    "    print(\"Making arrays\")\n",
    "    print(\"checking for save files\")\n",
    "    if(first == None):\n",
    "        first = \"all-vs\"\n",
    "    train_xNPFileName = first + \"_\" + second + \"train_xNP\" +\".npy\"\n",
    "    train_yNPFileName = first + \"_\" + second + \"train_yNP\" +\".npy\"\n",
    "    test_xNPFileName = first + \"_\" + second + \"test_xNP\" +\".npy\"\n",
    "    test_yNPFileName = first + \"_\" + second + \"test_yNP\" +\".npy\"\n",
    "\n",
    "    if(path.exists(train_xNPFileName) \n",
    "       and path.exists(train_yNPFileName)\n",
    "       and path.exists(test_xNPFileName)\n",
    "       and path.exists(test_yNPFileName)):\n",
    "        print('saved train_xNP as', train_xNPFileName)\n",
    "        print('saved train_yNP as', train_yNPFileName)\n",
    "        print('saved test_xNP as', test_xNPFileName)\n",
    "        print('saved test_yNP as', test_yNPFileName)\n",
    "        print(\"loading from np\")\n",
    "        train_x = np.load(train_xNPFileName)\n",
    "        train_y = np.load(train_yNPFileName)\n",
    "        test_x = np.load(test_xNPFileName)\n",
    "        test_y = np.load(test_yNPFileName)\n",
    "        train_xNPSize = (train_x.nbytes)/1000000\n",
    "        train_yNPSize = (train_y.nbytes)/1000000\n",
    "        test_xNPSize = (test_x.nbytes)/1000000\n",
    "        test_yNPSize = (test_y.nbytes)/1000000\n",
    "        print(\"loaded directly from NP.load\")\n",
    "        print(\"train_xNPSize (text) size loaded:\", train_xNPSize,\"megabytes\")\n",
    "        print(\"train_yNPSize (labels) size loaded:\", train_yNPSize,\"megabytes\")\n",
    "        print(\"test_xNPSize (text) size loaded:\", test_xNPSize,\"megabytes\")\n",
    "        print(\"test_yNPSize (labels) size loaded:\", test_yNPSize,\"megabytes\")\n",
    "    else:\n",
    "#         print(\"training_data\", training_data)\n",
    "#         print(\"testing_data\", testing_data)\n",
    "        train_x, train_y, test_x, test_y, sizes = make_arrays(training_data, testing_data, wordlist, labels, mode, isAllVS)\n",
    "        train_xSize, train_ySize, test_xSize, test_ySize = sizes\n",
    "        if any(not part.size for part in [train_x, train_y, test_x, test_y]):\n",
    "            print(\"Train or test empty. Did you misspell the dataset name?\")\n",
    "            return\n",
    "        #             sys.exit(1)\n",
    "        print(\"saving NP arrays\")\n",
    "        np.save(train_xNPFileName, train_x)\n",
    "        np.save(train_yNPFileName, train_y)\n",
    "        np.save(test_xNPFileName, test_x)\n",
    "        np.save(test_yNPFileName, test_y)\n",
    "        print(\"NP arrays saved\")\n",
    "\n",
    "    print(\"Initializing classifier\")\n",
    "    trainClassifier = True\n",
    "    if debug:\n",
    "        classifierName = \"RandomForestClassifier\"\n",
    "        print(\"Searching for a \", classifierName)\n",
    "        classiferSaveFile = first+\"_\"+second+classifierName+\".pkl\"\n",
    "        print(path.exists(classiferSaveFile))\n",
    "        if(path.exists(classiferSaveFile)):\n",
    "            trainClassifier = False\n",
    "            print(\"Loading classifier from file\")\n",
    "            classifier = joblib.load(classiferSaveFile)\n",
    "            print(\"classifier loaded successfully\")\n",
    "        else:\n",
    "            print(\"file not found, creating new classifier\")\n",
    "            classifier = RandomForestClassifier()\n",
    "    elif mode == \"single\":\n",
    "        classifierName = \"LogisticRegressionCV\"\n",
    "        print(\"Searching for a \", classifierName)\n",
    "        classiferSaveFile = first+\"_\"+second+classifierName+\".pkl\"\n",
    "        print(path.exists(classiferSaveFile))\n",
    "        if(path.exists(classiferSaveFile)):\n",
    "            trainClassifier = False\n",
    "            print(\"Loading classifier from file\")\n",
    "            classifier = joblib.load(classiferSaveFile)\n",
    "            print(\"classifier loaded successfully\")\n",
    "        else:\n",
    "            print(\"file not found, creating new classifier\")\n",
    "            classifier = LogisticRegressionCV(\n",
    "                cv=10,\n",
    "                penalty=\"l2\",\n",
    "                fit_intercept=True,\n",
    "                solver=\"sag\",\n",
    "                scoring=\"f1\",\n",
    "                refit=True,\n",
    "                # n_jobs=-1,\n",
    "                class_weight=\"balanced\",\n",
    "            )\n",
    "    else:\n",
    "        classifierName = \"OneVsRestClassifier\"\n",
    "        print(\"Searching for a \", classifierName)\n",
    "        classiferSaveFile = first+\"_\"+second+classifierName+\".pkl\"\n",
    "        print(path.exists(classiferSaveFile))\n",
    "        if(path.exists(classiferSaveFile)):\n",
    "            trainClassifier = False\n",
    "            print(\"Loading classifier from file\")\n",
    "            classifier = joblib.load(classiferSaveFile)\n",
    "            print(\"classifier loaded successfully\")\n",
    "        else:\n",
    "            print(\"file not found, creating new classifier\")\n",
    "            classifier = OneVsRestClassifier(\n",
    "                LogisticRegressionCV(\n",
    "                    cv=10,\n",
    "                    penalty=\"l2\",\n",
    "                    fit_intercept=True,\n",
    "                    solver=\"sag\",\n",
    "                    scoring=\"f1\",\n",
    "                    refit=True,\n",
    "                    class_weight=\"balanced\",\n",
    "                    tol = 0.1,\n",
    "                ),\n",
    "                n_jobs=-1,\n",
    "            )\n",
    "    if(trainClassifier):\n",
    "        print(\"this is the classifierName: \", classifierName)\n",
    "        print(\"Training...\")\n",
    "        print(\"train_x (text) size:\", (train_x.nbytes)/1000000,\"megabytes\")\n",
    "        print(\"train_y (labels) size:\", (train_y.nbytes)/1000000,\"megabytes\")\n",
    "        print(\"train_x (text) length:\", len(train_x))\n",
    "        print(\"train_y (labels) length:\", len(train_y))\n",
    "        print(train_x[:5])\n",
    "        print(train_y[:5])\n",
    "\n",
    "        classifier.fit(train_x, train_y)\n",
    "        print(\"finished training, classifier size:\", sys.getsizeof(classifier)/1000000,\"megabytes\")\n",
    "    print(\"Predicting...\")\n",
    "    if first == \"multi\" and second == \"single\":\n",
    "        predict_y = classifier.predict_proba(test_x)\n",
    "        helper = np.zeros_like(predict_y)\n",
    "        helper[range(len(predict_y)), predict_y.argmax(1)] = 1\n",
    "        predict_y = helper\n",
    "    else:\n",
    "        predict_y = classifier.predict(test_x)\n",
    "\n",
    "    print(\"Analysing...\")\n",
    "\n",
    "    analyse_results(\n",
    "        test_y,\n",
    "        predict_y,\n",
    "        labels,\n",
    "        testing_data,\n",
    "        first,\n",
    "        second,\n",
    "        output,\n",
    "        mode,  # TODO\n",
    "    )\n",
    "    if(path.exists(classiferSaveFile)):\n",
    "        print(\"classifier already saved\")\n",
    "    else:\n",
    "#         classiferSaveFile = first+\"_\"+second+classifierName+\".pkl\"\n",
    "        print(\"classiferSaveFile: \", classiferSaveFile)\n",
    "        joblib.dump(classifier, classiferSaveFile)\n",
    "        print(\"Saved Successfully\")\n",
    "    total, used, free = getHardDriveSpaceLeft()\n",
    "    if(free < 10):\n",
    "        sys.exit(\"Error: less than 10 gb remaining on disk\")\n",
    "    print(\"-----------------------------------------------------------------------------------------\")\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "def runTrials(version, verifyResults, crossCorpus=True, sameCorpus=True, allVs=False):\n",
    "    possibleChoices = [('affectivetext','headlines'), ('crowdflower','tweets'), ('dailydialog','conversations'), \n",
    "                       ('emoint','tweets'), ('emotion-cause','paragraphs'), ('grounded_emotions','tweets'), \n",
    "                       ('isear','descriptions'), ('ssec','tweets'),('tales-emotion','tales'), ('tec','tweets')]\n",
    "                        #excluded ('emobank','headlines') because it is isn't emotion annotated\n",
    "                        #and ('electoraltweets','tweets') because it has incompatible annotation\n",
    "                        #and  ('fb-valence-arousal-anon','tweets') because it isn't emotion annotated\n",
    "    corporaSets = []\n",
    "    if version == \"previous\":\n",
    "        corporaSets = (getCrossCorpusValuesWithOrder(possibleChoices))\n",
    "        #this was added to sort the lists by domain of the first, then by the first corpus name, then the second.\n",
    "        #it is placed in reverse order simply because if it was put in regular order, the largest of the trials would be first\n",
    "        #sorting in reverse will (loosely) make the smaller trials run first, while having no impact on the ability to obtain all results\n",
    "        sortedPermutations = sorted(corporaSets, key = lambda x: (x[2], x[0], x[1]), reverse = True)\n",
    "        sortedPermutations += (getCorporaPairsWithItself(possibleChoices))\n",
    "        sortedPermutations += (getAllVsCorpusValues(possibleChoices))\n",
    "        for corpusPair in sortedPermutations:\n",
    "            performTrialUsingCorpusPair(corpusPair, verifyResults)\n",
    "    else: #version == \"myTrials\"\n",
    "        powerSet = list(getPowerset(possibleChoices))\n",
    "    \n",
    "    print(\"End of program!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "permutations length:  90\n",
      "------------------------------ ('tec', 'tales-emotion', 'tweets', 'tales') -------------------------------------------\n",
      "Getting data\n",
      "do pickle files exist? True\n",
      "skipping trial\n",
      "------------------------------ ('tec', 'ssec', 'tweets', 'tweets') -------------------------------------------\n",
      "Getting data\n",
      "do pickle files exist? True\n",
      "skipping trial\n",
      "------------------------------ ('tec', 'isear', 'tweets', 'descriptions') -------------------------------------------\n",
      "Getting data\n",
      "do pickle files exist? True\n",
      "skipping trial\n",
      "------------------------------ ('tec', 'grounded_emotions', 'tweets', 'tweets') -------------------------------------------\n",
      "Getting data\n",
      "do pickle files exist? True\n",
      "skipping trial\n",
      "------------------------------ ('tec', 'emotion-cause', 'tweets', 'paragraphs') -------------------------------------------\n",
      "Getting data\n",
      "do pickle files exist? True\n",
      "skipping trial\n",
      "------------------------------ ('tec', 'emoint', 'tweets', 'tweets') -------------------------------------------\n",
      "Getting data\n",
      "do pickle files exist? True\n",
      "skipping trial\n",
      "------------------------------ ('tec', 'dailydialog', 'tweets', 'conversations') -------------------------------------------\n",
      "Getting data\n",
      "do pickle files exist? True\n",
      "skipping trial\n",
      "------------------------------ ('tec', 'crowdflower', 'tweets', 'tweets') -------------------------------------------\n",
      "Getting data\n",
      "do pickle files exist? True\n",
      "skipping trial\n",
      "------------------------------ ('tec', 'affectivetext', 'tweets', 'headlines') -------------------------------------------\n",
      "Getting data\n",
      "do pickle files exist? True\n",
      "skipping trial\n",
      "------------------------------ ('ssec', 'tec', 'tweets', 'tweets') -------------------------------------------\n",
      "Getting data\n",
      "do pickle files exist? True\n",
      "skipping trial\n",
      "------------------------------ ('ssec', 'tales-emotion', 'tweets', 'tales') -------------------------------------------\n",
      "Getting data\n",
      "do pickle files exist? True\n",
      "skipping trial\n",
      "------------------------------ ('ssec', 'isear', 'tweets', 'descriptions') -------------------------------------------\n",
      "Getting data\n",
      "do pickle files exist? True\n",
      "skipping trial\n",
      "------------------------------ ('ssec', 'grounded_emotions', 'tweets', 'tweets') -------------------------------------------\n",
      "Getting data\n",
      "do pickle files exist? True\n",
      "skipping trial\n",
      "------------------------------ ('ssec', 'emotion-cause', 'tweets', 'paragraphs') -------------------------------------------\n",
      "Getting data\n",
      "do pickle files exist? True\n",
      "skipping trial\n",
      "------------------------------ ('ssec', 'emoint', 'tweets', 'tweets') -------------------------------------------\n",
      "Getting data\n",
      "do pickle files exist? True\n",
      "skipping trial\n",
      "------------------------------ ('ssec', 'dailydialog', 'tweets', 'conversations') -------------------------------------------\n",
      "Getting data\n",
      "do pickle files exist? True\n",
      "skipping trial\n",
      "------------------------------ ('ssec', 'crowdflower', 'tweets', 'tweets') -------------------------------------------\n",
      "Getting data\n",
      "do pickle files exist? True\n",
      "skipping trial\n",
      "------------------------------ ('ssec', 'affectivetext', 'tweets', 'headlines') -------------------------------------------\n",
      "Getting data\n",
      "do pickle files exist? True\n",
      "skipping trial\n",
      "------------------------------ ('grounded_emotions', 'tec', 'tweets', 'tweets') -------------------------------------------\n",
      "Getting data\n",
      "do pickle files exist? True\n",
      "skipping trial\n",
      "------------------------------ ('grounded_emotions', 'tales-emotion', 'tweets', 'tales') -------------------------------------------\n",
      "Getting data\n",
      "do pickle files exist? True\n",
      "skipping trial\n",
      "------------------------------ ('grounded_emotions', 'ssec', 'tweets', 'tweets') -------------------------------------------\n",
      "Getting data\n",
      "do pickle files exist? True\n",
      "skipping trial\n",
      "------------------------------ ('grounded_emotions', 'isear', 'tweets', 'descriptions') -------------------------------------------\n",
      "Getting data\n",
      "do pickle files exist? True\n",
      "skipping trial\n",
      "------------------------------ ('grounded_emotions', 'emotion-cause', 'tweets', 'paragraphs') -------------------------------------------\n",
      "Getting data\n",
      "do pickle files exist? True\n",
      "skipping trial\n",
      "------------------------------ ('grounded_emotions', 'emoint', 'tweets', 'tweets') -------------------------------------------\n",
      "Getting data\n",
      "do pickle files exist? True\n",
      "skipping trial\n",
      "------------------------------ ('grounded_emotions', 'dailydialog', 'tweets', 'conversations') -------------------------------------------\n",
      "Getting data\n",
      "do pickle files exist? True\n",
      "skipping trial\n",
      "------------------------------ ('grounded_emotions', 'crowdflower', 'tweets', 'tweets') -------------------------------------------\n",
      "Getting data\n",
      "do pickle files exist? True\n",
      "skipping trial\n",
      "------------------------------ ('grounded_emotions', 'affectivetext', 'tweets', 'headlines') -------------------------------------------\n",
      "Getting data\n",
      "do pickle files exist? True\n",
      "skipping trial\n",
      "------------------------------ ('emoint', 'tec', 'tweets', 'tweets') -------------------------------------------\n",
      "Getting data\n",
      "do pickle files exist? True\n",
      "skipping trial\n",
      "------------------------------ ('emoint', 'tales-emotion', 'tweets', 'tales') -------------------------------------------\n",
      "Getting data\n",
      "do pickle files exist? True\n",
      "skipping trial\n",
      "------------------------------ ('emoint', 'ssec', 'tweets', 'tweets') -------------------------------------------\n",
      "Getting data\n",
      "do pickle files exist? True\n",
      "skipping trial\n",
      "------------------------------ ('emoint', 'isear', 'tweets', 'descriptions') -------------------------------------------\n",
      "Getting data\n",
      "do pickle files exist? True\n",
      "skipping trial\n",
      "------------------------------ ('emoint', 'grounded_emotions', 'tweets', 'tweets') -------------------------------------------\n",
      "Getting data\n",
      "do pickle files exist? True\n",
      "skipping trial\n",
      "------------------------------ ('emoint', 'emotion-cause', 'tweets', 'paragraphs') -------------------------------------------\n",
      "Getting data\n",
      "do pickle files exist? True\n",
      "skipping trial\n",
      "------------------------------ ('emoint', 'dailydialog', 'tweets', 'conversations') -------------------------------------------\n",
      "Getting data\n",
      "do pickle files exist? True\n",
      "skipping trial\n",
      "------------------------------ ('emoint', 'crowdflower', 'tweets', 'tweets') -------------------------------------------\n",
      "Getting data\n",
      "do pickle files exist? True\n",
      "skipping trial\n",
      "------------------------------ ('emoint', 'affectivetext', 'tweets', 'headlines') -------------------------------------------\n",
      "Getting data\n",
      "do pickle files exist? True\n",
      "skipping trial\n",
      "------------------------------ ('crowdflower', 'tec', 'tweets', 'tweets') -------------------------------------------\n",
      "Getting data\n",
      "do pickle files exist? True\n",
      "skipping trial\n",
      "------------------------------ ('crowdflower', 'tales-emotion', 'tweets', 'tales') -------------------------------------------\n",
      "Getting data\n",
      "do pickle files exist? True\n",
      "skipping trial\n",
      "------------------------------ ('crowdflower', 'ssec', 'tweets', 'tweets') -------------------------------------------\n",
      "Getting data\n",
      "do pickle files exist? True\n",
      "skipping trial\n",
      "------------------------------ ('crowdflower', 'isear', 'tweets', 'descriptions') -------------------------------------------\n",
      "Getting data\n",
      "do pickle files exist? True\n",
      "skipping trial\n",
      "------------------------------ ('crowdflower', 'grounded_emotions', 'tweets', 'tweets') -------------------------------------------\n",
      "Getting data\n",
      "do pickle files exist? True\n",
      "skipping trial\n",
      "------------------------------ ('crowdflower', 'emotion-cause', 'tweets', 'paragraphs') -------------------------------------------\n",
      "Getting data\n",
      "do pickle files exist? True\n",
      "skipping trial\n",
      "------------------------------ ('crowdflower', 'emoint', 'tweets', 'tweets') -------------------------------------------\n",
      "Getting data\n",
      "do pickle files exist? True\n",
      "skipping trial\n",
      "------------------------------ ('crowdflower', 'dailydialog', 'tweets', 'conversations') -------------------------------------------\n",
      "Getting data\n",
      "do pickle files exist? True\n",
      "skipping trial\n",
      "------------------------------ ('crowdflower', 'affectivetext', 'tweets', 'headlines') -------------------------------------------\n",
      "Getting data\n",
      "do pickle files exist? True\n",
      "skipping trial\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------ ('tales-emotion', 'tec', 'tales', 'tweets') -------------------------------------------\n",
      "Getting data\n",
      "do pickle files exist? True\n",
      "skipping trial\n",
      "------------------------------ ('tales-emotion', 'ssec', 'tales', 'tweets') -------------------------------------------\n",
      "Getting data\n",
      "do pickle files exist? True\n",
      "skipping trial\n",
      "------------------------------ ('tales-emotion', 'isear', 'tales', 'descriptions') -------------------------------------------\n",
      "Getting data\n",
      "do pickle files exist? True\n",
      "skipping trial\n",
      "------------------------------ ('tales-emotion', 'grounded_emotions', 'tales', 'tweets') -------------------------------------------\n",
      "Getting data\n",
      "do pickle files exist? True\n",
      "skipping trial\n",
      "------------------------------ ('tales-emotion', 'emotion-cause', 'tales', 'paragraphs') -------------------------------------------\n",
      "Getting data\n",
      "do pickle files exist? True\n",
      "skipping trial\n",
      "------------------------------ ('tales-emotion', 'emoint', 'tales', 'tweets') -------------------------------------------\n",
      "Getting data\n",
      "do pickle files exist? True\n",
      "skipping trial\n",
      "------------------------------ ('tales-emotion', 'dailydialog', 'tales', 'conversations') -------------------------------------------\n",
      "Getting data\n",
      "do pickle files exist? True\n",
      "skipping trial\n",
      "------------------------------ ('tales-emotion', 'crowdflower', 'tales', 'tweets') -------------------------------------------\n",
      "Getting data\n",
      "do pickle files exist? True\n",
      "skipping trial\n",
      "------------------------------ ('tales-emotion', 'affectivetext', 'tales', 'headlines') -------------------------------------------\n",
      "Getting data\n",
      "do pickle files exist? True\n",
      "skipping trial\n",
      "------------------------------ ('emotion-cause', 'tec', 'paragraphs', 'tweets') -------------------------------------------\n",
      "Getting data\n",
      "do pickle files exist? True\n",
      "skipping trial\n",
      "------------------------------ ('emotion-cause', 'tales-emotion', 'paragraphs', 'tales') -------------------------------------------\n",
      "Getting data\n",
      "do pickle files exist? True\n",
      "skipping trial\n",
      "------------------------------ ('emotion-cause', 'ssec', 'paragraphs', 'tweets') -------------------------------------------\n",
      "Getting data\n",
      "do pickle files exist? True\n",
      "skipping trial\n",
      "------------------------------ ('emotion-cause', 'isear', 'paragraphs', 'descriptions') -------------------------------------------\n",
      "Getting data\n",
      "do pickle files exist? True\n",
      "skipping trial\n",
      "------------------------------ ('emotion-cause', 'grounded_emotions', 'paragraphs', 'tweets') -------------------------------------------\n",
      "Getting data\n",
      "do pickle files exist? True\n",
      "skipping trial\n",
      "------------------------------ ('emotion-cause', 'emoint', 'paragraphs', 'tweets') -------------------------------------------\n",
      "Getting data\n",
      "do pickle files exist? True\n",
      "skipping trial\n",
      "------------------------------ ('emotion-cause', 'dailydialog', 'paragraphs', 'conversations') -------------------------------------------\n",
      "Getting data\n",
      "do pickle files exist? True\n",
      "skipping trial\n",
      "------------------------------ ('emotion-cause', 'crowdflower', 'paragraphs', 'tweets') -------------------------------------------\n",
      "Getting data\n",
      "do pickle files exist? True\n",
      "skipping trial\n",
      "------------------------------ ('emotion-cause', 'affectivetext', 'paragraphs', 'headlines') -------------------------------------------\n",
      "Getting data\n",
      "do pickle files exist? True\n",
      "skipping trial\n",
      "------------------------------ ('affectivetext', 'tec', 'headlines', 'tweets') -------------------------------------------\n",
      "Getting data\n",
      "do pickle files exist? True\n",
      "skipping trial\n",
      "------------------------------ ('affectivetext', 'tales-emotion', 'headlines', 'tales') -------------------------------------------\n",
      "Getting data\n",
      "do pickle files exist? True\n",
      "skipping trial\n",
      "------------------------------ ('affectivetext', 'ssec', 'headlines', 'tweets') -------------------------------------------\n",
      "Getting data\n",
      "do pickle files exist? True\n",
      "skipping trial\n",
      "------------------------------ ('affectivetext', 'isear', 'headlines', 'descriptions') -------------------------------------------\n",
      "Getting data\n",
      "do pickle files exist? True\n",
      "skipping trial\n",
      "------------------------------ ('affectivetext', 'grounded_emotions', 'headlines', 'tweets') -------------------------------------------\n",
      "Getting data\n",
      "do pickle files exist? True\n",
      "skipping trial\n",
      "------------------------------ ('affectivetext', 'emotion-cause', 'headlines', 'paragraphs') -------------------------------------------\n",
      "Getting data\n",
      "do pickle files exist? True\n",
      "skipping trial\n",
      "------------------------------ ('affectivetext', 'emoint', 'headlines', 'tweets') -------------------------------------------\n",
      "Getting data\n",
      "do pickle files exist? True\n",
      "skipping trial\n",
      "------------------------------ ('affectivetext', 'dailydialog', 'headlines', 'conversations') -------------------------------------------\n",
      "Getting data\n",
      "do pickle files exist? True\n",
      "skipping trial\n",
      "------------------------------ ('affectivetext', 'crowdflower', 'headlines', 'tweets') -------------------------------------------\n",
      "Getting data\n",
      "do pickle files exist? True\n",
      "skipping trial\n",
      "------------------------------ ('isear', 'tec', 'descriptions', 'tweets') -------------------------------------------\n",
      "Getting data\n",
      "do pickle files exist? True\n",
      "skipping trial\n",
      "------------------------------ ('isear', 'tales-emotion', 'descriptions', 'tales') -------------------------------------------\n",
      "Getting data\n",
      "do pickle files exist? True\n",
      "skipping trial\n",
      "------------------------------ ('isear', 'ssec', 'descriptions', 'tweets') -------------------------------------------\n",
      "Getting data\n",
      "do pickle files exist? True\n",
      "skipping trial\n",
      "------------------------------ ('isear', 'grounded_emotions', 'descriptions', 'tweets') -------------------------------------------\n",
      "Getting data\n",
      "do pickle files exist? True\n",
      "skipping trial\n",
      "------------------------------ ('isear', 'emotion-cause', 'descriptions', 'paragraphs') -------------------------------------------\n",
      "Getting data\n",
      "do pickle files exist? True\n",
      "skipping trial\n",
      "------------------------------ ('isear', 'emoint', 'descriptions', 'tweets') -------------------------------------------\n",
      "Getting data\n",
      "do pickle files exist? True\n",
      "skipping trial\n",
      "------------------------------ ('isear', 'dailydialog', 'descriptions', 'conversations') -------------------------------------------\n",
      "Getting data\n",
      "do pickle files exist? True\n",
      "skipping trial\n",
      "------------------------------ ('isear', 'crowdflower', 'descriptions', 'tweets') -------------------------------------------\n",
      "Getting data\n",
      "do pickle files exist? True\n",
      "skipping trial\n",
      "------------------------------ ('isear', 'affectivetext', 'descriptions', 'headlines') -------------------------------------------\n",
      "Getting data\n",
      "do pickle files exist? True\n",
      "skipping trial\n",
      "------------------------------ ('dailydialog', 'tec', 'conversations', 'tweets') -------------------------------------------\n",
      "Getting data\n",
      "do pickle files exist? True\n",
      "skipping trial\n",
      "------------------------------ ('dailydialog', 'tales-emotion', 'conversations', 'tales') -------------------------------------------\n",
      "Getting data\n",
      "do pickle files exist? True\n",
      "skipping trial\n",
      "------------------------------ ('dailydialog', 'ssec', 'conversations', 'tweets') -------------------------------------------\n",
      "Getting data\n",
      "do pickle files exist? True\n",
      "skipping trial\n",
      "------------------------------ ('dailydialog', 'isear', 'conversations', 'descriptions') -------------------------------------------\n",
      "Getting data\n",
      "do pickle files exist? True\n",
      "skipping trial\n",
      "------------------------------ ('dailydialog', 'grounded_emotions', 'conversations', 'tweets') -------------------------------------------\n",
      "Getting data\n",
      "do pickle files exist? True\n",
      "skipping trial\n",
      "------------------------------ ('dailydialog', 'emotion-cause', 'conversations', 'paragraphs') -------------------------------------------\n",
      "Getting data\n",
      "do pickle files exist? True\n",
      "skipping trial\n",
      "------------------------------ ('dailydialog', 'emoint', 'conversations', 'tweets') -------------------------------------------\n",
      "Getting data\n",
      "do pickle files exist? True\n",
      "skipping trial\n",
      "------------------------------ ('dailydialog', 'crowdflower', 'conversations', 'tweets') -------------------------------------------\n",
      "Getting data\n",
      "do pickle files exist? True\n",
      "skipping trial\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------ ('dailydialog', 'affectivetext', 'conversations', 'headlines') -------------------------------------------\n",
      "Getting data\n",
      "do pickle files exist? True\n",
      "skipping trial\n",
      "------------------------------ ('affectivetext', 'affectivetext', 'headlines', 'headlines') -------------------------------------------\n",
      "Getting data\n",
      "do pickle files exist? True\n",
      "skipping trial\n",
      "------------------------------ ('crowdflower', 'crowdflower', 'tweets', 'tweets') -------------------------------------------\n",
      "Getting data\n",
      "do pickle files exist? True\n",
      "skipping trial\n",
      "------------------------------ ('dailydialog', 'dailydialog', 'conversations', 'conversations') -------------------------------------------\n",
      "Getting data\n",
      "do pickle files exist? True\n",
      "skipping trial\n",
      "------------------------------ ('emoint', 'emoint', 'tweets', 'tweets') -------------------------------------------\n",
      "Getting data\n",
      "do pickle files exist? True\n",
      "skipping trial\n",
      "------------------------------ ('emotion-cause', 'emotion-cause', 'paragraphs', 'paragraphs') -------------------------------------------\n",
      "Getting data\n",
      "do pickle files exist? True\n",
      "skipping trial\n",
      "------------------------------ ('grounded_emotions', 'grounded_emotions', 'tweets', 'tweets') -------------------------------------------\n",
      "Getting data\n",
      "do pickle files exist? True\n",
      "skipping trial\n",
      "------------------------------ ('isear', 'isear', 'descriptions', 'descriptions') -------------------------------------------\n",
      "Getting data\n",
      "do pickle files exist? True\n",
      "skipping trial\n",
      "------------------------------ ('ssec', 'ssec', 'tweets', 'tweets') -------------------------------------------\n",
      "Getting data\n",
      "do pickle files exist? True\n",
      "skipping trial\n",
      "------------------------------ ('tales-emotion', 'tales-emotion', 'tales', 'tales') -------------------------------------------\n",
      "Getting data\n",
      "do pickle files exist? True\n",
      "skipping trial\n",
      "------------------------------ ('tec', 'tec', 'tweets', 'tweets') -------------------------------------------\n",
      "Getting data\n",
      "do pickle files exist? True\n",
      "skipping trial\n",
      "------------------------------ (None, 'affectivetext', None, 'headlines') -------------------------------------------\n",
      "Getting data\n",
      "do pickle files exist? False\n",
      "get_train_test param:\n",
      "json  unified-dataset.jsonl\n",
      "train  all-vs\n",
      "test  affectivetext\n",
      "there were  1250  entries that were in test and  220189 that were not in test and  220189  that were in train\n",
      "test was appended  1250  times\n",
      "multi\n",
      "Detected mode: multi...\n",
      "220189 1250\n",
      "Getting wordlist...\n",
      "bag size 95336\n",
      "Getting emotions\n",
      "['anger', 'sadness', 'disgust', 'joy', 'surprise', 'fear']\n",
      "Making arrays\n",
      "checking for save files\n",
      "saved train_xNP as all-vs_affectivetexttrain_xNP.npy\n",
      "saved train_yNP as all-vs_affectivetexttrain_yNP.npy\n",
      "saved test_xNP as all-vs_affectivetexttest_xNP.npy\n",
      "saved test_yNP as all-vs_affectivetexttest_yNP.npy\n",
      "loading from np\n",
      "loaded directly from NP.load\n",
      "train_xNPSize (text) size loaded: 4403.78 megabytes\n",
      "train_yNPSize (labels) size loaded: 5.284536 megabytes\n",
      "test_xNPSize (text) size loaded: 25.0 megabytes\n",
      "test_yNPSize (labels) size loaded: 0.03 megabytes\n",
      "Initializing classifier\n",
      "Searching for a  RandomForestClassifier\n",
      "False\n",
      "file not found, creating new classifier\n",
      "this is the classifierName:  RandomForestClassifier\n",
      "Training...\n",
      "train_x (text) size: 4403.78 megabytes\n",
      "train_y (labels) size: 5.284536 megabytes\n",
      "train_x (text) length: 220189\n",
      "train_y (labels) length: 220189\n",
      "[[0 0 0 ... 0 0 0]\n",
      " [1 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 1 0 ... 0 0 0]]\n",
      "[[0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0]]\n",
      "finished training, classifier size: 4.8e-05 megabytes\n",
      "Predicting...\n",
      "Analysing...\n",
      "analyse_results\n",
      "hello\n",
      "Precision\t1.0\n",
      "Recall\t0.0012422360248447205\n",
      "F1-score\t0.0024813895781637717\n",
      "Accuracy\t0.032\n",
      "classiferSaveFile:  all-vs_affectivetextRandomForestClassifier.pkl\n",
      "Saved Successfully\n",
      "Total: 475 GB\n",
      "Used: 397 GB\n",
      "Free: 77 GB\n",
      "-----------------------------------------------------------------------------------------\n",
      "------------------------------ (None, 'crowdflower', None, 'tweets') -------------------------------------------\n",
      "Getting data\n",
      "do pickle files exist? False\n",
      "get_train_test param:\n",
      "json  unified-dataset.jsonl\n",
      "train  all-vs\n",
      "test  crowdflower\n",
      "there were  39740  entries that were in test and  181699 that were not in test and  181699  that were in train\n",
      "test was appended  39740  times\n",
      "multi\n",
      "oof\n",
      "Detected mode: multi...\n",
      "181699 39740\n",
      "Getting wordlist...\n",
      "bag size 67658\n",
      "Getting emotions\n",
      "['anger', 'sadness', 'disgust', 'noemo', 'joy', 'surprise', 'fear']\n",
      "Making arrays\n",
      "checking for save files\n",
      "emotions in make_arrays:  {'anger': 0, 'sadness': 1, 'disgust': 2, 'noemo': 3, 'joy': 4, 'surprise': 5, 'fear': 6}\n",
      "train raw text:  1.485992\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 181699/181699 [01:20<00:00, 2255.41it/s]\n",
      "100%|| 39740/39740 [00:15<00:00, 2557.75it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_x length  181699\n",
      "train_x dimension of element  5000\n",
      "train_x (text) size RAW: 1.485992 megabytes\n",
      "train_y (labels) size RAW: 1.485992 megabytes\n",
      "test_x (text) size RAW: 0.321096 megabytes\n",
      "test_y (labels) size RAW: 0.321096 megabytes\n",
      "saved test_y\n",
      "train_x Size stays the same False\n",
      "train_y Size stays the same False\n",
      "test_x Size stays the same False\n",
      "test_y Size stays the same False\n",
      "train_xNPSize (text) size: 3633.98 megabytes\n",
      "train_yNPSize (labels) size: 5.087572 megabytes\n",
      "test_xNPSize (text) size: 794.8 megabytes\n",
      "test_yNPSize (labels) size: 1.11272 megabytes\n",
      "train_xNP length  181699\n",
      "train_xNP dimension of element  2\n",
      "train_xNP size  908495000\n",
      "saving NP arrays\n",
      "NP arrays saved\n",
      "Initializing classifier\n",
      "Searching for a  RandomForestClassifier\n",
      "False\n",
      "file not found, creating new classifier\n",
      "this is the classifierName:  RandomForestClassifier\n",
      "Training...\n",
      "train_x (text) size: 3633.98 megabytes\n",
      "train_y (labels) size: 5.087572 megabytes\n",
      "train_x (text) length: 181699\n",
      "train_y (labels) length: 181699\n",
      "[[0 0 0 ... 0 0 0]\n",
      " [1 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 1 0 ... 0 0 0]]\n",
      "[[0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0]]\n",
      "finished training, classifier size: 4.8e-05 megabytes\n",
      "Predicting...\n",
      "Analysing...\n",
      "analyse_results\n",
      "hello\n",
      "Precision\t0.3019865992711884\n",
      "Recall\t0.1430400890868597\n",
      "F1-score\t0.19412853742396188\n",
      "Accuracy\t0.18877705083039759\n",
      "classiferSaveFile:  all-vs_crowdflowerRandomForestClassifier.pkl\n",
      "Saved Successfully\n",
      "Total: 475 GB\n",
      "Used: 398 GB\n",
      "Free: 76 GB\n",
      "-----------------------------------------------------------------------------------------\n",
      "------------------------------ (None, 'dailydialog', None, 'conversations') -------------------------------------------\n",
      "Getting data\n",
      "do pickle files exist? False\n",
      "get_train_test param:\n",
      "json  unified-dataset.jsonl\n",
      "train  all-vs\n",
      "test  dailydialog\n",
      "there were  102979  entries that were in test and  118460 that were not in test and  118460  that were in train\n",
      "test was appended  102979  times\n",
      "multi\n",
      "oof\n",
      "Detected mode: multi...\n",
      "118460 102979\n",
      "Getting wordlist...\n",
      "bag size 92064\n",
      "Getting emotions\n",
      "['anger', 'sadness', 'disgust', 'noemo', 'joy', 'surprise', 'fear']\n",
      "Making arrays\n",
      "checking for save files\n",
      "emotions in make_arrays:  {'anger': 0, 'sadness': 1, 'disgust': 2, 'noemo': 3, 'joy': 4, 'surprise': 5, 'fear': 6}\n",
      "train raw text:  1.043552\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 118460/118460 [00:57<00:00, 2069.16it/s]\n",
      "100%|| 102979/102979 [00:50<00:00, 2042.40it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_x length  118460\n",
      "train_x dimension of element  5000\n",
      "train_x (text) size RAW: 1.043552 megabytes\n",
      "train_y (labels) size RAW: 1.043552 megabytes\n",
      "test_x (text) size RAW: 0.824456 megabytes\n",
      "test_y (labels) size RAW: 0.824456 megabytes\n",
      "saved test_y\n",
      "train_x Size stays the same False\n",
      "train_y Size stays the same False\n",
      "test_x Size stays the same False\n",
      "test_y Size stays the same False\n",
      "train_xNPSize (text) size: 2369.2 megabytes\n",
      "train_yNPSize (labels) size: 3.31688 megabytes\n",
      "test_xNPSize (text) size: 2059.58 megabytes\n",
      "test_yNPSize (labels) size: 2.883412 megabytes\n",
      "train_xNP length  118460\n",
      "train_xNP dimension of element  2\n",
      "train_xNP size  592300000\n",
      "saving NP arrays\n",
      "NP arrays saved\n",
      "Initializing classifier\n",
      "Searching for a  RandomForestClassifier\n",
      "False\n",
      "file not found, creating new classifier\n",
      "this is the classifierName:  RandomForestClassifier\n",
      "Training...\n",
      "train_x (text) size: 2369.2 megabytes\n",
      "train_y (labels) size: 3.31688 megabytes\n",
      "train_x (text) length: 118460\n",
      "train_y (labels) length: 118460\n",
      "[[0 0 0 ... 0 0 0]\n",
      " [0 1 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " [1 0 0 ... 0 0 0]]\n",
      "[[0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0]]\n",
      "finished training, classifier size: 4.8e-05 megabytes\n",
      "Predicting...\n",
      "Analysing...\n",
      "analyse_results\n",
      "hello\n",
      "Precision\t0.5787214294001625\n",
      "Recall\t0.04843705998310335\n",
      "F1-score\t0.08939228301582466\n",
      "Accuracy\t0.04843705998310335\n",
      "classiferSaveFile:  all-vs_dailydialogRandomForestClassifier.pkl\n",
      "Saved Successfully\n",
      "Total: 475 GB\n",
      "Used: 408 GB\n",
      "Free: 66 GB\n",
      "-----------------------------------------------------------------------------------------\n",
      "------------------------------ (None, 'emoint', None, 'tweets') -------------------------------------------\n",
      "Getting data\n",
      "do pickle files exist? False\n",
      "get_train_test param:\n",
      "json  unified-dataset.jsonl\n",
      "train  all-vs\n",
      "test  emoint\n",
      "there were  7102  entries that were in test and  214337 that were not in test and  214337  that were in train\n",
      "test was appended  7102  times\n",
      "multi\n",
      "oof\n",
      "Detected mode: multi...\n",
      "214337 7102\n",
      "Getting wordlist...\n",
      "bag size 89592\n",
      "Getting emotions\n",
      "['anger', 'joy', 'sadness', 'fear']\n",
      "Making arrays\n",
      "checking for save files\n",
      "emotions in make_arrays:  {'anger': 0, 'joy': 1, 'sadness': 2, 'fear': 3}\n",
      "train raw text:  1.8808\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 214337/214337 [01:36<00:00, 2223.07it/s]\n",
      "100%|| 7102/7102 [00:03<00:00, 2329.44it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_x length  214337\n",
      "train_x dimension of element  5000\n",
      "train_x (text) size RAW: 1.8808 megabytes\n",
      "train_y (labels) size RAW: 1.8808 megabytes\n",
      "test_x (text) size RAW: 0.061424 megabytes\n",
      "test_y (labels) size RAW: 0.061424 megabytes\n",
      "saved test_y\n",
      "train_x Size stays the same False\n",
      "train_y Size stays the same False\n",
      "test_x Size stays the same False\n",
      "test_y Size stays the same False\n",
      "train_xNPSize (text) size: 4286.74 megabytes\n",
      "train_yNPSize (labels) size: 3.429392 megabytes\n",
      "test_xNPSize (text) size: 142.04 megabytes\n",
      "test_yNPSize (labels) size: 0.113632 megabytes\n",
      "train_xNP length  214337\n",
      "train_xNP dimension of element  2\n",
      "train_xNP size  1071685000\n",
      "saving NP arrays\n",
      "NP arrays saved\n",
      "Initializing classifier\n",
      "Searching for a  RandomForestClassifier\n",
      "False\n",
      "file not found, creating new classifier\n",
      "this is the classifierName:  RandomForestClassifier\n",
      "Training...\n",
      "train_x (text) size: 4286.74 megabytes\n",
      "train_y (labels) size: 3.429392 megabytes\n",
      "train_x (text) length: 214337\n",
      "train_y (labels) length: 214337\n",
      "[[0 0 0 ... 0 0 0]\n",
      " [1 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 1 0 ... 0 0 0]]\n",
      "[[0 0 0 0]\n",
      " [0 0 0 0]\n",
      " [0 0 0 0]\n",
      " [0 0 0 0]\n",
      " [0 0 0 0]]\n",
      "finished training, classifier size: 4.8e-05 megabytes\n",
      "Predicting...\n",
      "Analysing...\n",
      "analyse_results\n",
      "hello\n",
      "Precision\t0.6773675762439807\n",
      "Recall\t0.05941988172345818\n",
      "F1-score\t0.10925566343042073\n",
      "Accuracy\t0.05941988172345818\n",
      "classiferSaveFile:  all-vs_emointRandomForestClassifier.pkl\n",
      "Saved Successfully\n",
      "Total: 475 GB\n",
      "Used: 411 GB\n",
      "Free: 63 GB\n",
      "-----------------------------------------------------------------------------------------\n",
      "------------------------------ (None, 'emotion-cause', None, 'paragraphs') -------------------------------------------\n",
      "Getting data\n",
      "do pickle files exist? False\n",
      "get_train_test param:\n",
      "json  unified-dataset.jsonl\n",
      "train  all-vs\n",
      "test  emotion-cause\n",
      "there were  2414  entries that were in test and  219025 that were not in test and  219025  that were in train\n",
      "test was appended  2414  times\n",
      "multi\n",
      "oof\n",
      "Detected mode: multi...\n",
      "219025 2414\n",
      "Getting wordlist...\n",
      "bag size 94288\n",
      "Getting emotions\n",
      "['anger', 'sadness', 'disgust', 'joy', 'surprise', 'fear']\n",
      "Making arrays\n",
      "checking for save files\n",
      "emotions in make_arrays:  {'anger': 0, 'sadness': 1, 'disgust': 2, 'joy': 3, 'surprise': 4, 'fear': 5}\n",
      "train raw text:  1.8808\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 219025/219025 [01:37<00:00, 2247.74it/s]\n",
      "100%|| 2414/2414 [00:01<00:00, 2391.62it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_x length  219025\n",
      "train_x dimension of element  5000\n",
      "train_x (text) size RAW: 1.8808 megabytes\n",
      "train_y (labels) size RAW: 1.8808 megabytes\n",
      "test_x (text) size RAW: 0.02104 megabytes\n",
      "test_y (labels) size RAW: 0.02104 megabytes\n",
      "saved test_y\n",
      "train_x Size stays the same False\n",
      "train_y Size stays the same False\n",
      "test_x Size stays the same False\n",
      "test_y Size stays the same False\n",
      "train_xNPSize (text) size: 4380.5 megabytes\n",
      "train_yNPSize (labels) size: 5.2566 megabytes\n",
      "test_xNPSize (text) size: 48.28 megabytes\n",
      "test_yNPSize (labels) size: 0.057936 megabytes\n",
      "train_xNP length  219025\n",
      "train_xNP dimension of element  2\n",
      "train_xNP size  1095125000\n",
      "saving NP arrays\n",
      "NP arrays saved\n",
      "Initializing classifier\n",
      "Searching for a  RandomForestClassifier\n",
      "False\n",
      "file not found, creating new classifier\n",
      "this is the classifierName:  RandomForestClassifier\n",
      "Training...\n",
      "train_x (text) size: 4380.5 megabytes\n",
      "train_y (labels) size: 5.2566 megabytes\n",
      "train_x (text) length: 219025\n",
      "train_y (labels) length: 219025\n",
      "[[0 0 0 ... 0 0 0]\n",
      " [1 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 1 0 ... 0 0 0]]\n",
      "[[0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0]]\n",
      "finished training, classifier size: 4.8e-05 megabytes\n",
      "Predicting...\n",
      "Analysing...\n",
      "analyse_results\n",
      "hello\n",
      "Precision\t0.8073089700996677\n",
      "Recall\t0.10714285714285714\n",
      "F1-score\t0.18917866874270145\n",
      "Accuracy\t0.15741507870753935\n",
      "classiferSaveFile:  all-vs_emotion-causeRandomForestClassifier.pkl\n",
      "Saved Successfully\n",
      "Total: 475 GB\n",
      "Used: 420 GB\n",
      "Free: 54 GB\n",
      "-----------------------------------------------------------------------------------------\n",
      "------------------------------ (None, 'grounded_emotions', None, 'tweets') -------------------------------------------\n",
      "Getting data\n",
      "do pickle files exist? False\n",
      "get_train_test param:\n",
      "json  unified-dataset.jsonl\n",
      "train  all-vs\n",
      "test  grounded_emotions\n",
      "there were  2585  entries that were in test and  218854 that were not in test and  218854  that were in train\n",
      "test was appended  2585  times\n",
      "multi\n",
      "oof\n",
      "Detected mode: multi...\n",
      "218854 2585\n",
      "Getting wordlist...\n",
      "bag size 91377\n",
      "Getting emotions\n",
      "['joy', 'sadness']\n",
      "Making arrays\n",
      "checking for save files\n",
      "emotions in make_arrays:  {'joy': 0, 'sadness': 1}\n",
      "train raw text:  1.8808\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 218854/218854 [01:35<00:00, 2301.26it/s]\n",
      "100%|| 2585/2585 [00:01<00:00, 2381.76it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_x length  218854\n",
      "train_x dimension of element  5000\n",
      "train_x (text) size RAW: 1.8808 megabytes\n",
      "train_y (labels) size RAW: 1.8808 megabytes\n",
      "test_x (text) size RAW: 0.02104 megabytes\n",
      "test_y (labels) size RAW: 0.02104 megabytes\n",
      "saved test_y\n",
      "train_x Size stays the same False\n",
      "train_y Size stays the same False\n",
      "test_x Size stays the same False\n",
      "test_y Size stays the same False\n",
      "train_xNPSize (text) size: 4377.08 megabytes\n",
      "train_yNPSize (labels) size: 1.750832 megabytes\n",
      "test_xNPSize (text) size: 51.7 megabytes\n",
      "test_yNPSize (labels) size: 0.02068 megabytes\n",
      "train_xNP length  218854\n",
      "train_xNP dimension of element  2\n",
      "train_xNP size  1094270000\n",
      "saving NP arrays\n",
      "NP arrays saved\n",
      "Initializing classifier\n",
      "Searching for a  RandomForestClassifier\n",
      "False\n",
      "file not found, creating new classifier\n",
      "this is the classifierName:  RandomForestClassifier\n",
      "Training...\n",
      "train_x (text) size: 4377.08 megabytes\n",
      "train_y (labels) size: 1.750832 megabytes\n",
      "train_x (text) length: 218854\n",
      "train_y (labels) length: 218854\n",
      "[[0 0 0 ... 0 0 0]\n",
      " [1 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 1 0 ... 0 0 0]]\n",
      "[[0 0]\n",
      " [0 0]\n",
      " [0 0]\n",
      " [0 0]\n",
      " [0 0]]\n",
      "finished training, classifier size: 4.8e-05 megabytes\n",
      "Predicting...\n",
      "Analysing...\n",
      "analyse_results\n",
      "hello\n",
      "Precision\t0.5625\n",
      "Recall\t0.027852998065764023\n",
      "F1-score\t0.05307777368227055\n",
      "Accuracy\t0.027852998065764023\n",
      "classiferSaveFile:  all-vs_grounded_emotionsRandomForestClassifier.pkl\n",
      "Saved Successfully\n",
      "Total: 475 GB\n",
      "Used: 425 GB\n",
      "Free: 49 GB\n",
      "-----------------------------------------------------------------------------------------\n",
      "------------------------------ (None, 'isear', None, 'descriptions') -------------------------------------------\n",
      "Getting data\n",
      "do pickle files exist? False\n",
      "get_train_test param:\n",
      "json  unified-dataset.jsonl\n",
      "train  all-vs\n",
      "test  isear\n",
      "there were  7666  entries that were in test and  213773 that were not in test and  213773  that were in train\n",
      "test was appended  7666  times\n",
      "multi\n",
      "oof\n",
      "Detected mode: multi...\n",
      "213773 7666\n",
      "Getting wordlist...\n",
      "bag size 93927\n",
      "Getting emotions\n",
      "['anger', 'sadness', 'joy', 'disgust', 'fear']\n",
      "Making arrays\n",
      "checking for save files\n",
      "emotions in make_arrays:  {'anger': 0, 'sadness': 1, 'joy': 2, 'disgust': 3, 'fear': 4}\n",
      "train raw text:  1.8808\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 213773/213773 [01:44<00:00, 2052.87it/s]\n",
      "100%|| 7666/7666 [00:17<00:00, 441.28it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_x length  213773\n",
      "train_x dimension of element  5000\n",
      "train_x (text) size RAW: 1.8808 megabytes\n",
      "train_y (labels) size RAW: 1.8808 megabytes\n",
      "test_x (text) size RAW: 0.061424 megabytes\n",
      "test_y (labels) size RAW: 0.061424 megabytes\n",
      "saved test_y\n",
      "train_x Size stays the same False\n",
      "train_y Size stays the same False\n",
      "test_x Size stays the same False\n",
      "test_y Size stays the same False\n",
      "train_xNPSize (text) size: 4275.46 megabytes\n",
      "train_yNPSize (labels) size: 4.27546 megabytes\n",
      "test_xNPSize (text) size: 153.32 megabytes\n",
      "test_yNPSize (labels) size: 0.15332 megabytes\n",
      "train_xNP length  213773\n",
      "train_xNP dimension of element  2\n",
      "train_xNP size  1068865000\n",
      "saving NP arrays\n",
      "NP arrays saved\n",
      "Initializing classifier\n",
      "Searching for a  RandomForestClassifier\n",
      "False\n",
      "file not found, creating new classifier\n",
      "this is the classifierName:  RandomForestClassifier\n",
      "Training...\n",
      "train_x (text) size: 4275.46 megabytes\n",
      "train_y (labels) size: 4.27546 megabytes\n",
      "train_x (text) length: 213773\n",
      "train_y (labels) length: 213773\n",
      "[[0 0 0 ... 0 0 0]\n",
      " [1 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 1 0 ... 0 0 0]]\n",
      "[[0 0 0 0 0]\n",
      " [0 0 0 0 0]\n",
      " [0 0 0 0 0]\n",
      " [0 0 0 0 0]\n",
      " [0 0 0 0 0]]\n",
      "finished training, classifier size: 4.8e-05 megabytes\n",
      "Predicting...\n",
      "Analysing...\n",
      "analyse_results\n",
      "hello\n",
      "Precision\t0.8438661710037175\n",
      "Recall\t0.08289209421215994\n",
      "F1-score\t0.15095594347464672\n",
      "Accuracy\t0.34007304983042\n",
      "classiferSaveFile:  all-vs_isearRandomForestClassifier.pkl\n",
      "Saved Successfully\n",
      "Total: 475 GB\n",
      "Used: 436 GB\n",
      "Free: 38 GB\n",
      "-----------------------------------------------------------------------------------------\n",
      "------------------------------ (None, 'ssec', None, 'tweets') -------------------------------------------\n",
      "Getting data\n",
      "do pickle files exist? False\n",
      "get_train_test param:\n",
      "json  unified-dataset.jsonl\n",
      "train  all-vs\n",
      "test  ssec\n",
      "there were  4868  entries that were in test and  216571 that were not in test and  216571  that were in train\n",
      "test was appended  4868  times\n",
      "multi\n",
      "Detected mode: multi...\n",
      "216571 4868\n",
      "Getting wordlist...\n",
      "bag size 90840\n",
      "Getting emotions\n",
      "['anger', 'sadness', 'disgust', 'trust', 'joy', 'surprise', 'fear']\n",
      "Making arrays\n",
      "checking for save files\n",
      "emotions in make_arrays:  {'anger': 0, 'sadness': 1, 'disgust': 2, 'trust': 3, 'joy': 4, 'surprise': 5, 'fear': 6}\n",
      "train raw text:  1.8808\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 216571/216571 [02:14<00:00, 1609.92it/s]\n",
      "100%|| 4868/4868 [00:08<00:00, 604.70it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_x length  216571\n",
      "train_x dimension of element  5000\n",
      "train_x (text) size RAW: 1.8808 megabytes\n",
      "train_y (labels) size RAW: 1.8808 megabytes\n",
      "test_x (text) size RAW: 0.043032 megabytes\n",
      "test_y (labels) size RAW: 0.043032 megabytes\n",
      "saved test_y\n",
      "train_x Size stays the same False\n",
      "train_y Size stays the same False\n",
      "test_x Size stays the same False\n",
      "test_y Size stays the same False\n",
      "train_xNPSize (text) size: 4331.42 megabytes\n",
      "train_yNPSize (labels) size: 6.063988 megabytes\n",
      "test_xNPSize (text) size: 97.36 megabytes\n",
      "test_yNPSize (labels) size: 0.136304 megabytes\n",
      "train_xNP length  216571\n",
      "train_xNP dimension of element  2\n",
      "train_xNP size  1082855000\n",
      "saving NP arrays\n",
      "NP arrays saved\n",
      "Initializing classifier\n",
      "Searching for a  RandomForestClassifier\n",
      "False\n",
      "file not found, creating new classifier\n",
      "this is the classifierName:  RandomForestClassifier\n",
      "Training...\n",
      "train_x (text) size: 4331.42 megabytes\n",
      "train_y (labels) size: 6.063988 megabytes\n",
      "train_x (text) length: 216571\n",
      "train_y (labels) length: 216571\n",
      "[[0 0 0 ... 0 0 0]\n",
      " [1 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 1 0 ... 0 0 0]]\n",
      "[[0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0]]\n",
      "finished training, classifier size: 4.8e-05 megabytes\n",
      "Predicting...\n",
      "Analysing...\n",
      "analyse_results\n",
      "hello\n",
      "Precision\t0.7756653992395437\n",
      "Recall\t0.01320901320901321\n",
      "F1-score\t0.025975679633284524\n",
      "Accuracy\t0.02732128184059162\n",
      "classiferSaveFile:  all-vs_ssecRandomForestClassifier.pkl\n",
      "Saved Successfully\n",
      "Total: 475 GB\n",
      "Used: 448 GB\n",
      "Free: 26 GB\n",
      "-----------------------------------------------------------------------------------------\n",
      "------------------------------ (None, 'tales-emotion', None, 'tales') -------------------------------------------\n",
      "Getting data\n",
      "do pickle files exist? False\n",
      "get_train_test param:\n",
      "json  unified-dataset.jsonl\n",
      "train  all-vs\n",
      "test  tales-emotion\n",
      "there were  14771  entries that were in test and  206668 that were not in test and  206668  that were in train\n",
      "test was appended  14771  times\n",
      "multi\n",
      "oof\n",
      "Detected mode: multi...\n",
      "206668 14771\n",
      "Getting wordlist...\n",
      "bag size 93151\n",
      "Getting emotions\n",
      "['anger', 'sadness', 'disgust', 'noemo', 'joy', 'surprise', 'fear']\n",
      "Making arrays\n",
      "checking for save files\n",
      "emotions in make_arrays:  {'anger': 0, 'sadness': 1, 'disgust': 2, 'noemo': 3, 'joy': 4, 'surprise': 5, 'fear': 6}\n",
      "train raw text:  1.671784\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 206668/206668 [02:02<00:00, 1680.29it/s]\n",
      "100%|| 14771/14771 [00:08<00:00, 1830.05it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_x length  206668\n",
      "train_x dimension of element  5000\n",
      "train_x (text) size RAW: 1.671784 megabytes\n",
      "train_y (labels) size RAW: 1.671784 megabytes\n",
      "test_x (text) size RAW: 0.124912 megabytes\n",
      "test_y (labels) size RAW: 0.124912 megabytes\n",
      "saved test_y\n",
      "train_x Size stays the same False\n",
      "train_y Size stays the same False\n",
      "test_x Size stays the same False\n",
      "test_y Size stays the same False\n",
      "train_xNPSize (text) size: 4133.36 megabytes\n",
      "train_yNPSize (labels) size: 5.786704 megabytes\n",
      "test_xNPSize (text) size: 295.42 megabytes\n",
      "test_yNPSize (labels) size: 0.413588 megabytes\n",
      "train_xNP length  206668\n",
      "train_xNP dimension of element  2\n",
      "train_xNP size  1033340000\n",
      "saving NP arrays\n",
      "NP arrays saved\n",
      "Initializing classifier\n",
      "Searching for a  RandomForestClassifier\n",
      "False\n",
      "file not found, creating new classifier\n",
      "this is the classifierName:  RandomForestClassifier\n",
      "Training...\n",
      "train_x (text) size: 4133.36 megabytes\n",
      "train_y (labels) size: 5.786704 megabytes\n",
      "train_x (text) length: 206668\n",
      "train_y (labels) length: 206668\n",
      "[[0 0 0 ... 0 0 0]\n",
      " [1 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 1 0 ... 0 0 0]]\n",
      "[[0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0]]\n",
      "finished training, classifier size: 4.8e-05 megabytes\n",
      "Predicting...\n",
      "Analysing...\n",
      "analyse_results\n",
      "hello\n",
      "Precision\t0.6194029850746269\n",
      "Recall\t0.1573353192065534\n",
      "F1-score\t0.2509312746315392\n",
      "Accuracy\t0.1573353192065534\n",
      "classiferSaveFile:  all-vs_tales-emotionRandomForestClassifier.pkl\n",
      "Saved Successfully\n",
      "Total: 475 GB\n",
      "Used: 455 GB\n",
      "Free: 19 GB\n",
      "-----------------------------------------------------------------------------------------\n",
      "------------------------------ (None, 'tec', None, 'tweets') -------------------------------------------\n",
      "Getting data\n",
      "do pickle files exist? False\n",
      "get_train_test param:\n",
      "json  unified-dataset.jsonl\n",
      "train  all-vs\n",
      "test  tec\n",
      "there were  21051  entries that were in test and  200388 that were not in test and  200388  that were in train\n",
      "test was appended  21051  times\n",
      "multi\n",
      "oof\n",
      "Detected mode: multi...\n",
      "200388 21051\n",
      "Getting wordlist...\n",
      "bag size 80772\n",
      "Getting emotions\n",
      "['anger', 'sadness', 'disgust', 'joy', 'surprise', 'fear']\n",
      "Making arrays\n",
      "checking for save files\n",
      "emotions in make_arrays:  {'anger': 0, 'sadness': 1, 'disgust': 2, 'joy': 3, 'surprise': 4, 'fear': 5}\n",
      "train raw text:  1.671784\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 200388/200388 [01:40<00:00, 1987.63it/s]\n",
      "100%|| 21051/21051 [00:11<00:00, 1869.24it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_x length  200388\n",
      "train_x dimension of element  5000\n",
      "train_x (text) size RAW: 1.671784 megabytes\n",
      "train_y (labels) size RAW: 1.671784 megabytes\n",
      "test_x (text) size RAW: 0.178016 megabytes\n",
      "test_y (labels) size RAW: 0.178016 megabytes\n",
      "saved test_y\n",
      "train_x Size stays the same False\n",
      "train_y Size stays the same False\n",
      "test_x Size stays the same False\n",
      "test_y Size stays the same False\n",
      "train_xNPSize (text) size: 4007.76 megabytes\n",
      "train_yNPSize (labels) size: 4.809312 megabytes\n",
      "test_xNPSize (text) size: 421.02 megabytes\n",
      "test_yNPSize (labels) size: 0.505224 megabytes\n",
      "train_xNP length  200388\n",
      "train_xNP dimension of element  2\n",
      "train_xNP size  1001940000\n",
      "saving NP arrays\n",
      "NP arrays saved\n",
      "Initializing classifier\n",
      "Searching for a  RandomForestClassifier\n",
      "False\n",
      "file not found, creating new classifier\n",
      "this is the classifierName:  RandomForestClassifier\n",
      "Training...\n",
      "train_x (text) size: 4007.76 megabytes\n",
      "train_y (labels) size: 4.809312 megabytes\n",
      "train_x (text) length: 200388\n",
      "train_y (labels) length: 200388\n",
      "[[0 0 0 ... 0 0 0]\n",
      " [1 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 1 0 ... 0 0 0]]\n",
      "[[0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0]]\n",
      "finished training, classifier size: 4.8e-05 megabytes\n",
      "Predicting...\n",
      "Analysing...\n",
      "analyse_results\n",
      "hello\n",
      "Precision\t0.5476923076923077\n",
      "Recall\t0.042284302546560244\n",
      "F1-score\t0.07850747585233539\n",
      "Accuracy\t0.04223077288489858\n",
      "classiferSaveFile:  all-vs_tecRandomForestClassifier.pkl\n",
      "Saved Successfully\n",
      "Total: 475 GB\n",
      "Used: 463 GB\n",
      "Free: 11 GB\n",
      "-----------------------------------------------------------------------------------------\n",
      "End of program!\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    version = \"previous\"\n",
    "#     version = \"myTrials\"\n",
    "    crossCorpus = True\n",
    "    sameCorpus = False\n",
    "    allVs = False\n",
    "    verifyResults = False\n",
    "    runTrials(version, verifyResults, crossCorpus, sameCorpus, allVs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
